<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
<head><title>AARON SLOMAN's DOINGS</title>
<meta content="text/html; charset=iso-8859-1" http-equiv="Content-Type">
</head>
<body vlink="#000080" alink="#0000ff" link="#000080" text="black">
<div style="margin-left:10px; margin-top:0px; margin-bottom:0px; width:690px">

<center>
    <img alt="School of Computer Science"
    height="75" border="1"
    src="http://www.cs.bham.ac.uk/~axs/fig/cs-ghost.jpg"
<br>

<h2><b>
Please see:
<br>
<a href="http://www.cs.bham.ac.uk/~axs">http://www.cs.bham.ac.uk/~axs</a>
<br>
(Updated much more often than this document)
</b></h2>
<P>
<H4><B>
AARON'S DOINGS
<small>
<br/>
(In need of total re-organisation.)
</small>
</B></H4>
</center>
<hr>
<h2><b>
<small>
<br/>
Revised: 6 Oct 2013
</small>
</b></h2>
<b>Added 24 Mar 2013: Meta-Morphogenesis</b>
<br>
In 2010 I was invited to contribute to a volume on Alan Turing, eventually published
(over a year late) as <a href="http://store.elsevier.com/Alan-Turing-His-Work-and-Impact/isbn-9780123869807/">Alan Turing: His Work and Impact</a>,
with detailed contents listed <a href="http://www.cs.bham.ac.uk/~axs/amtbook">here.</a>
The book won several of the "PROSE" awards for 2013, including the prestigious
<a href="http://www.proseawards.com/current-winners.html"><i>R.R. Hawkins Award</i></a>.
<p>
I had an interesting misunderstanding with the editors, that led to my contributing a
paper for section IV which was not originally planned. In preparation for that I read
Turing's 1952 paper on Morphogenesis (around September 2011). That gave me a new idea
for organising most of the work I had been doing linking Philosophy, AI/Robotics,
Cognitive Science, and Biology over half a century. I used the label "Meta-Morphogenesis"
as a name for the over-arching research programme, not knowing that it had previously
been used without the hyphen as the name of an album produced by the band <a href="http://en.wikipedia.org/wiki/Esoteric_%28band%29">Esoteric</a>).
<p>
The high level goal of the project was to identify the major transitions in
biological information-processing of all sorts since the earliest organisms or
proto-organisms (as opposed to transitions in genome, morphology, behaviour, or
habitat, which were already widely studied).
<p>
I chose the label "Meta-Morphogenesis" because some of the most important
changes in biological information-processing produced by the mechanisms of
change altered those mechanisms so as to extend their powers of change, over
evolutionary, developmental, individual learning, or cultural time-scales.
<p>
In part this was achieved by evolving new biological construction-kits of many
sorts, including construction-kits for creating new construction-kits, i.e.
derived construction kits.
<p>
The concept of information that is central to all this is not Shannon's concept,
but Jane Austen's concept, shared by many people in many cultures long before
Shannon. The differences are summarised here:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/austen-info.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/austen-info.html</a>
<br>
Shannon understood the difference, but many of his admirers were misled by his
choice of the label "information" for his new concept (mainly concerned with
syntactic structure, not semantic content).
<p>
One of the most important, and largely unnoticed, products of evolution is
accumulation and use of increasingly complex mathematical knowledge, mostly used
unwittingly until recently. (Evolution: the blind mathematician)
<p>
Much of the generality and power of evolved construction kits depended on their
use of powerful mathematical abstractions that could be instantiated in
different ways in different contexts, the most dramatic example being the common
mathematical structures underlying a huge variety of different human languages
with different phonology, morphology, syntax, semantics, pragmatics, etc.
<p>
But similar points can be made about biological control systems (e.g. use of
negative feedback in  homeostatic mechanisms) and use of geometrical and
topological abstractions in spatial perception and selection and control of
physical actions.
<p>
Although much of my previous work was a contribution to this project, that connection was
only implicit. There's a growing collection of papers, PDF presentations, and video
tutorials and discussions, explaining the long term goals, giving examples of partial
results, and linking the ideas to work by others, e.g. Annette Karmiloff-Smith's
1992 book <b>Beyond Modularity</b>.
<p>
Here are some of them, most still "Work-In-Progress", which is why there are few
dates, and why most published versions have been, or are being, superseded.
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html</a>
<br>
A high level overview of the project.
<li>
<b>Added: 2 Feb 2015</b>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/construction-kits.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/construction-kits.html</a>
<div style="margin-left:20px; margin-top:5px; margin-bottom:0px; width:650px">
Construction kits required for biological evolution
<br>
(Including evolution of minds and mathematical abilities.)
<br>
The scientific explanatory role of construction kits
</div>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html</a>
<br>
Examples of "toddler theorems" and their significance for the project.
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/beyond-modularity.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/beyond-modularity.html</a>
Personal and incomplete review of work by Annette Karmiloff-Smith which I think is highly
relevant to this project.
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/evolution-info-transitions.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/evolution-info-transitions.html</a>
<br>
Draft list of types of transitions in biological information-processing, or
Varieties of Evolved (Developed, Learnt, ....) Biological Computation.
<li>
<b>Added: 2 Feb 2015</b>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/construction-kits">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/construction-kits</a>
<br>
Varieties of construction kits, including many used in evolution, including
Fundamental Construction Kit (FCT), Derived Construction Kits (DCT). There are
also distinctions between <b>concrete</b> construction kits, whose components exist and
interact in space and time, and <b>abstract</b> construction kits, including
grammars, musical notations, formal systems, programming languages, etc.
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/bio-math-phil.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/bio-math-phil.html</a>
<br>
Biology, Mathematics, Philosophy, and Evolution of Information Processing
<small>
<pre>
   "For mathematics is after all an anthropological phenomenon."
   (Wittgenstein, Remarks on the Foundations of Mathematics)
   No, though it is partly a biological phenomenon.
</pre>
</small>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#agitut">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#agitut</a>
<br/>
PDF tutorial presentation on Meta-Morphogenesis at AGI 2012, Oxford.
<br/>
A video recording of the tutorial produced by Adam Ford is available on Youtube <a href="http://www.youtube.com/watch?v=BNul52kFI74">here</a>,
<b>(Video)</b>
with a local version
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/#m-m-tut">here.</a>
<li>
<a href="http://www.youtube.com/watch?v=iuH8dC7Snno">http://www.youtube.com/watch?v=iuH8dC7Snno</a>
<b>(Video)</b>
<br/>
<i>Aaron Sloman Artificial Intelligence - Psychology - Oxford Interview</i>
<br/>
Interviewed on video, by Adam Ford, in a fairly wide-ranging discussion, at AGI 2012
in Oxford. Dylan Holmes produced a transcript of the interview which was then revised
and edited <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/transcript-interview.html">here.</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/triangle-theorem.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/triangle-theorem.html</a>
<br/>
Hidden Depths of Triangle Qualia -- explaining some connections between biological
<br/>
abilities concerned with perception of and reasoning about possibilities (offline
<br/>
intelligence) and the origins of mathematics, e.g. precursors to Euclid's Elements.
<br/>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/architecture-based-motivation.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/architecture-based-motivation.html</a>
<br/>
Architecture-based motivation vs Reward-based motivation
<br/>
(Compare the ideas of R.W. White, in "Motivation reconsidered: The concept of competence",
<br/>
Psych. Review, 1959.)
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/autism.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/autism.html</a>
<br/>
Autism: A Different Sort of Information-Processing
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/vm-functionalism.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/vm-functionalism.html</a>
<br/>
Virtual Machine Functionalism
<br/>
(The only form of functionalism worth taking seriously in Philosophy of Mind)
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/unconscious-seeing.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/unconscious-seeing.html</a>
<br/>
A demonstration of what could be called "Unconscious seeing".
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/piaget-possibility-necessity.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/piaget-possibility-necessity.html</a>
<br/>
Discussion of some themes in Piaget's two (posthumous) books on Possibility and Necessity
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/11.html#1106d">http://www.cs.bham.ac.uk/research/projects/cogaff/11.html#1106d</a>
<br/>
Virtual Machinery and Evolution of Mind (Part 3)
<br/>
Meta-Morphogenesis: Evolution of Information-Processing Machinery
<br/>
Preprint for: Alan Turing - His Work and Impact
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/two-faces.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/two-faces.html</a>
<br/>
Two faces -- a new illusion? (Demonstration of the need for perception mechanisms to
be closely linked to meta-semantic competences)
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/austen-info.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/austen-info.html</a>
<br/>
Jane Austen's implicit theory of information (in "Pride and Prejudice") contrasted
with Shannon's theory.
</ul>
<p>
<hr>
<b>
CONJECTURE: HOW TO VIEW NATURE-NURTURE COLLABORATION
</b>
<div style="margin-left:15px; margin-top:15px; margin-bottom:0px;">
Alongside the innate physical sucking reflex for obtaining milk, which is then digested,
decomposed and used all over the body for growth, repair, and energy, there is a
genetically determined information-sucking reflex, which seeks out, sucks in, and
decomposes information, which is later recombined in many ways, growing the
information-processing architecture and many diverse recombinable competences. Over time,
late developing <i>physiological</i> mechanisms become able to consume and use new forms
of physical fuel, decomposed and re-used in new ways. Likewise, over time, innate,
late-developing <i>information-processing</i> mechanisms cause the architecture to extend
itself, adding new layers containing new forms of competence that are based partly on what
has developed earlier and partly on what is encountered in the environment.
The resulting growth of young minds, based on a mixture of biological bootstrapping
mechanisms and information acquired from the physical and social environment, includes
construction of increasingly complex <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#wpe08"> <i>virtual machines</i></a>, and follows
far more diverse trajectories than the results of growth of bodies built on acquired
chemicals.
<p>
For more on this see:
<div style="margin-left:-15px; margin-top:0px; margin-bottom:0px;">
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/evolution-life-mind.html">Evolution, Life and Mind: Some Startling Facts</a>
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/12.html#1203">Meta-morphogenesis and the Creativity of Evolution</a>
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">
The Meta-Morphogenesis (MM) Project (or Meta-Project?)
<br/>
Or:
Evolution As A Theorem Prover --
</a>
<br/>
<small>
&nbsp;&nbsp;
Proving many theorems in parallel --
<br/>
&nbsp;&nbsp;
   Sharing partial results among proofs --
<br/>
&nbsp;&nbsp;
   Proving theorems about what is possible--
<br/>
&nbsp;&nbsp;
   Delegating some theorems to toddlers
</small>
<br/>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/gentoa">
How can a genome specify information processing architectures that
grow themselves, partly on the basis of interaction with
environment.
</a>
<br/>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#babystuff">
Ontologies for baby animals and robots
  From "baby stuff" to the world of adult science: Developmental AI
from a Kantian viewpoint.
</a>
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#toddler">
Why (and how) did biological evolution produce
mathematicians?
<br/>
  Alternative title: A New Approach to Philosophy of Mathematics:
  Design a young explorer, able to discover "toddler theorems"
</a>
<br>
(If learning mathematics requires a teacher, who taught the first
teachers?)
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/cogaff/05.html#200502">
The Altricial-Precocial Spectrum for Robots,</a> in proceedings
IJCAI, 2005.
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0603">member's poster presentation at AAAI06</a>
in Boston, July 2006
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0609">Natural
and artificial meta-configured altricial information-processing
systems</a>
<br>
IJUC, 2007
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#cogsci09">
What Cognitive Scientists Need to Know about Virtual Machines.</a>
<br> OR
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#mos09">the
(newer) version for philosophers</a>
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#glang">Evolution
of minds and languages.
<small>
  What evolved first and develops first in children: Languages for
communicating, or
  languages for thinking (Generalised Languages: GLs)?
</small>
</a>
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#toddlers">A
New Approach to Philosophy of Mathematics: Design a young explorer,
able to discover "toddler theorems"
</a>
<br>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/03.html#200307">
Progress report on the Cognition and Affect project (2003)</a>
<br/>
(The first and third are joint papers with Jackie Chappell. Others
have involved collaboration with many students and colleagues.)
</ul>
</div>
</div>

<hr>
<h3><b>
<a href="#contents">Jump to Table of Contents</a>
</b></h3>
<hr>
<a name="start"></a>
<h3><b>
STARTING POINTS
</b></h3>

This document attempts to provide pointers to work done since
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/sloman-1962/">
1962</a> relating to the above conjecture. Most of the work is now
online, but badly in need of reorganising. The items listed (rather
messily below) can be reached from
<ul>
<li>
<b>Begun 1st Jan 2010:</b>
<br/>
I am trying to collect all my papers into a
single file (in reverse chronological order)
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/papers.html">here,</a>
starting from the bottom (1962) and working upwards.
<br/>
Improving the structure will take much longer.
<p>
<li>
<a href="http://www.cs.bham.ac.uk/~axs/my-doings.html">This page</a>
<li>
<a href="http://www.cs.bham.ac.uk/~axs">My home page</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/">The Cognition and Affect web site</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/">My talks web site</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/">The CoSy project web site</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/freepoplog.html">The Free Poplog web site</a>
especially <a href="http://www.cs.bham.ac.uk/research/projects/poplog/packages/simagent.html">the SimAgent toolkit</a>
the overview of
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/examples">teaching materials.</a>
<li>
<a
href="http://www.cs.bham.ac.uk/research/projects/poplog/cas-ai">How
to get AI programming into schools, including some tutorial videos.
</a>
<b>(Videos)</b>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/">My 'misc' site for odds and ends and new ideas</a>
and
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/AREADME.html">Partial list of contents.</a>
<li>
<a href="#contents">CONTENTS LIST FOR THIS FILE</a>
<li>
<a href="http://philpapers.org/profile/265">Profile on the Philpapers web site</a>
<br/>
(Automatically generated: needs some editing when I get time.)
<br/>
<a href="http://philpapers.org/s/Aaron%20Sloman">Main Philpapers page</a>
<br/>
(Incomplete: also needs some editing when I get time.)
</ul>


<hr>
<p>
<a name="updates"></a>
<h3><b>
Updates:
</b></h3>
Look for sections labelled
<b>2011</b>,
<b>2012</b>,
<b>2013</b>,
<b>2014</b>,
<b>2015</b>
<p>
<b>December 2011</b>
<blockquote>
1. One of the developments in 2011 was actually giving an invited
talk
at a philosophy conference in Nancy France
(normally philosophers are not
interested):
<br/>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/11.html#1103">
Evolution of mind as a feat of computer systems engineering: Lessons
from decades of
   development of self-monitoring virtual machinery.
</a>
<p>
2. I finally read Annette Karmiloff-Smith's
<b>Beyond Modularity</b> (1992) and realised there were deep
connections with things I had been doing about philosophy of
mathematics and transitions in understanding the environment from
empirical to non-empirical in toddlers and possibly other animals.
<br/>
(Part of the evolutionary background to human mathematical
competences.)
<br/>
My incomplete online
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/beyond-modularity.html">review of her book</a>
is now part of a collection of discussion papers related to what I
call
'Meta-Morphogenesis' (MM):
<br/>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html</a>
<p>
I have at last learnt how to make video podcasts and have started producing tutorials
on AI and programming mainly for potential school teachers and their pupils, and
uploading them to youtube:
<br/>
A list is
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/cas-ai/video-tutorials.html">online
here.</a>
<b>(Video)</b>
<p>
3. In 2009 I started interacting with the
<a href="http://www.computingatschool.org.uk/">Computing At School</a>
mailing list, including trying to get more attention paid to AI, and
also trying to make people understand that computing is important
when trying to understand the world (because so much of it is
natural information processing machinery), not only when trying to
improve the world. (So far my efforts have had no impact.)
See
<small>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/cas-ai">http://www.cs.bham.ac.uk/research/projects/poplog/cas-ai</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/examples">http://www.cs.bham.ac.uk/research/projects/poplog/examples</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/ova">http://www.cs.bham.ac.uk/research/projects/poplog/ova</a>
</ul>
</small>
</blockquote>
<b>September 2011</b>
<blockquote>
Jeremy Wyatt and David Hogg very kindly organised a symposium close
to my 75th Birthday.
<br/>
<b>
From Animals to Robots and Back:
<br/>
reflections on hard problems in the study of cognition
</b>
<br>
<a href="http://www.cs.bham.ac.uk/~jlw/symposium_2011.html">http://www.cs.bham.ac.uk/~jlw/symposium_2011.html</a>
</blockquote>
<b>September 2010</b>
<blockquote>
1. Started discussions with various people on the problem:
<br/>
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/gentoa/">
How can a genome specify an architecture that grows itself partly
under the influence of the environment?
</a>
<p>
2. Soon realised that a good way to communicate the ideas about that
and a lot of other things I have been trying (and mostly failing) to
communicate about may be to extend the ideas of
Maynard Smith and Szathmary in their book proposing that there
are eight major transitions in evolution, summarised here:
<a href="http://en.wikipedia.org/wiki/The_Major_Transitions_in_Evolution">http://en.wikipedia.org/wiki/The_Major_Transitions_in_Evolution</a>
<p>
By extending the enquiry, and especially focusing on transitions in
information processing in natural and artificial systems, we can
find principles for
seeking out additional transitions that need to be understood as
achievements of evolution, which added extra complexity to the
capabilities of organisms, and in many cases extra complexity to the
relationship between genome and individual organism.
<p>
E.g. We can identify many discontinuities in information-processing
<b>functions</b>
and discontinuities of <b>designs</b> (or implementations) for
achieving those functions among biological organisms. Some of those
discontinuities occur in evolutionary trajectories and some in
development of individuals. Perhaps some occur in both.
<p>
Studying those discontinuities, and, where appropriate, sequences of
small changes that produce large qualitative differences in function
or in design,
may help us to understand better what relationships can
hold between a genome, a developmental context, and the information
processing architectures in individuals with the genome.
<br/>
(In 2011 re-labelled this the study of meta-morphogenesis, mentioned
above.)
<p>
Many of those differences will relate to differences between
environments in which organisms live, which can include results of
previous evolutionary or developmental changes. So we need to study
environments and the information processing problems they pose.
<p>
(Often AI research, or experiments on animals or humans, abstract
away from most of the complexities of the environment, leading to
discrepancies between claims and actual achievements.)
<br/>
(Slides enlarging on this are in preparation and will go into my
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/">Talks
directory.</a>
)
</blockquote>
<b>December 2009:</b>
<blockquote>
<a href="#cons09">
Papers and presentations on
consciousness.</a>
<p>
Quite a lot of changes to the online information on Poplog,
especially concerned with
<a href="#teaching">teaching,</a>
including <a href="http://www.cs.bham.ac.uk/research/projects/poplog/examples">
an overview of Pop-11 based teaching materials for AI, Cognitive
Science, etc.</a>
</blockquote>
<p>
<b>October 2009</b>
<blockquote>
<a name="mos09"></a>
<b>More on Virtual Machines</b>
<br/>
Yet another version of my attempt to explain what virtual machines
are and why they are important and have a variety of features
whose significance has not been widely appreciated:
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#mos09">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#mos09</a>
<br>
Virtual Machines and the Metaphysics of
Science
<br/>
Expanded version of presentation at:
    <a href="http://www.bristol.ac.uk/metaphysicsofscience/MoS_09/MoS_09_Programme.htm">Metaphysics of
Science'09</a> (September 12-14, 2009).
<br/>
It is hard to get philosophers to pay attention. For some reason
even while they are writing papers on the puzzling relations between
minds and brains they fail to ask themselves how a spelling checker,
or email program, or word processor can be running in the computer
they are using, which is just made of lots of electronic devices.
</blockquote>
<p>
Helping, with Jackie Chappell, Susannah Thorpe and Nick Hawes to
organise the first ever (?) symposium on
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/aiib/">AI-Inspired
Biology (AIIB)
</a> to be held at AISB'10 just before Easter 2010.
</blockquote>
<b>May 2009</b>
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/architecture-based-motivation.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/architecture-based-motivation.html</a>
<br/>
Architecture-based vs reward-based motivation and learning.
<br/>
Argues that it is possible to have motives whose creation is
triggered by biological mechanisms or other mechanisms without being
selected because they contribute to achieving positive rewards or
avoiding negative rewards. It's an anti-utilitarian view
of motivation. Of course, the biological mechanisms may have been
selected by evolution because they  have tend to aid survival and
reproductive success: but the evidence for that need not be
available to individuals who have the mechanisms. They just have
them and use them, because that's how they work.
<p>
A modified version of this will be published in the
<a href="http://www.apaonline.org/publications/newsletters/computers.aspx">Newsletter on Philosophy and Computers</a>
of the American Philosophical Association (APA), along with a paper
on using AI to teach philosophy. (Fall 2009).
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#vms">http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#vms</a>
<br/>
What Cognitive Scientists Need to Know about Virtual Machines
<br/>
Paper for CogSci'09 (Needs expanding). Superseded by
<a href="#mos09">the version for Metaphysics of Science, 2009</a>.
</blockquote>
<p>
<b>Jan-April 2009</b>

<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/language-universals.html">
A Better Idea than Language Universals</a>
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/vision-requirements.html">
Vision and action:
requirements for seeing the real world
</a>
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/opensource-and-public-funds.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/opensource-and-public-funds.html</a>

</blockquote>
<p>
<b>December 2008</b>
<blockquote>
<a href="#toddlers">Work on 'Toddler theorems':</a> about ways in
which a child, or adult, or animal, or future robot, can first
discover something empirically, e.g. by playing, then later realise
it's a theorem, e.g. of topology, geometry, arithmetic. There are
also intermediate reinterpretations. Expands the work on
<a href="#kant-robots">Kantian philosophy of mathematics and robots
</a>
<br/>
A new area of developmental
psychology?
</blockquote>
<p>
<b>November 2008</b>
<blockquote>
Restructured and extended
<a href="#ontology"> the section on ontology, representations and
metaphysics,
</a>
including adding a section on
<a href="#descriptive">descriptive metaphysics for babies</a>, with
a presentation on possibly innate mechanisms for
perceiving and learning about bits of stuff and bits of process.
</blockquote>
<p>
<b>May/June 2008</b>
<blockquote>
<a href="#kant-robots">
Kantian Philosophy of Mathematics and Young Robots</a>
<p>

<a href="#embodiment">
Issues concerning embodiment
<a/>
<p>
<a href="#teaching">Improving teaching computing in schools: teach AI/Cognitive Science.</a>
</blockquote>

<p>
<b>8 Mar 2008</b>
<blockquote>
New work on
<a href="http:#philmath">connection between robotics, vision,
and philosophy of mathematics.
</a>
<br>
New paper on architectural requirements for a human-like visual
system added to section on <a href="#vision">vision, below.</a>
<p>
(Also some rewriting of several sections.)
</blockquote>
<p>
<b>23 Dec 2007</b>
<blockquote>
Digitised my 1965 paper 'Functions and Rogators'. Now installed at
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#rog">http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#rog</a>
<br>
In PDF and HTML formats.
</blockquote>
<p>
<b>14 Dec 2007</b>
<blockquote>
Produced a draft paper answering five "interview" questions
from Luciano Floridi
about how I got into AI, etc.
<br/>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/sloman-floridi.pdf">http://www.cs.bham.ac.uk/research/projects/cogaff/sloman-floridi.pdf</a>
<br/>
How a Philosopher Became an Information-Scientist
<br/>
Somewhat to my surprise, this was included, with very little
editing, in his book
L. Floridi, (Ed.)
<i>Philosophy of Computing and Information: 5 Questions,</i>
Automatic Press / VIP,
2008,
<a href="http://www.amazon.com/Philosophy-Computing-Information-5-Questions/dp/8792130097">http://www.amazon.com/Philosophy-Computing-Information-5-Questions/dp/8792130097</a>
</blockquote>
<b>4 Dec 2007</b>
<blockquote>
Managed to scan in and install
my 1968 paper on
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#712">Explaining Logical Necessity.</a>
</blockquote>
<b>30 Nov 2007</b>
<blockquote>
Inspired by problems in making the
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/">CoSy
PlayMate</a> robot perform reliably, and by other things, I have
begun to develop some theoretical ideas about the importance of the
ability to predict and explain
<i>changes in affordances</i>, including changes in physical
affordances and in epistemic affordances. See
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0702">
this discussion paper. (HTML)</a>
</blockquote>
<p>
<b>19 Oct 2007</b>
<blockquote>
Several new talks here:
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/</a>
<p>
Two new invited talks for AAAI Fall Symposium 2007
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0704">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0704</a>
<br>
Diversity of Developmental Trajectories in Natural and
        Artificial Intelligence
<p>
<a
href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0705">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0705</a>
<br>
        Why Some Machines May Need Qualia and How They Can Have Them:
        <br/>Including a Demanding New Turing Test for Robot Philosophers
</blockquote>

</blockquote>
<p>
<b>5 Oct 2007</b>
<blockquote>
<blockquote>
Added
<a href="#pride">reference to interview and notes on pride.</a>
</blockquote>

<b>23 July 2007
</b>
<blockquote>
Invited talk "Machines in the ghost" for
<a href="http://www.indin2007.org/enf/">ENF'07 (Vienna, July 2007)</a>
to discuss AI and psychoanalysis
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#enf07">PDF Slides</a>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/sloman-enf07.pdf">
Full paper</a>
</blockquote>
<b>1-3 July</b>
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#pac07">
Consciousness in a Multi-layered
Multi-functional Labyrinthine Mind
</a>
Poster presentation at
<a href="http://www.bris.ac.uk/philosophy/department/events/PAC_conference/index.html/Conference.htm">PAC-07 Conference, 1-3 July 2007, Bristol.</a>

</blockquote>
<b>24-6 Jun 2007</b>
<blockquote>
Joint presentations with Jackie Chappell at
<a href="http://www.cs.arizona.edu/projects/wonac/">International
Workshop on Natural and Artificial Cognition</a> (Oxford 24-26 June
2007) on
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/wonac">
Causal competences in animals and machines
</a>
(Kantian and Humean Causation and the Altricial/Precocial
distinction)
</blockquote>
<b>14th June 2007</b>
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#cospal07">
Some requirements for human-like visual systems, including seeing processes,
structures, possibilities, affordances, causation and impossible objects.
</a>
Invited talk at
<a href="http://www.cospal.org/Workshop.htm">COSPAL Workshop,</a>
Aalborg, June 2007
</blockquote>
<p>
<b>31st May-1st June 2007</b>
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#compmod07">
Architectural and representational requirements for seeing processes
and affordances.
</a>
Invited talk at
<a href="http://comp-psych.bham.ac.uk/workshop.htm"> BBSRC funded
Workshop on
</a>
"Closing the gap between neurophysiology and behaviour:
A computational modelling approach."
</blockquote>

<b>26 March 2007</b>
<blockquote>
Short commentary with Jackie Chappell on the book by Jablonka and
Lamb, <i>Evolution in Four Dimensions</i>, for BBS:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0307">Computational Cognitive Epigenetics</a>
to appear in
<i>Behavioral and Brain Sciences</i> 2007.
</blockquote>
<b>20 Mar 2007</b>
<br>
Added link to <a href="#evolang">talk on language and its evolution.</a>
<p>
<b>25 Feb 2007</b>
<br>
Expanded section on consciousness: added
<a href="#stapp">links to Henry Stapp's discussions</a>
of our interactions about consciousness and quantum
mechanics.
<p>
<b>22 Feb 2007</b>
<br>
<small>
Expanded <a href="#altricial">section 8a</a>.
</small>
<p>
<b>22 Oct 2006</b>
<br>
<small>
(Added
<a href="#softeng">
section on software engineering and government policy.</a>)
</small>
</blockquote>

<P>

<b>18 Apr 2006:</b>
A brief explanation of why I now attach greater importance
 to putting research papers (including discussion notes, presentations,
 etc.) on the web than getting them into journals and conference
 proceedings can be found
 <a href="open-publishing.html">here</a>.

</blockquote>
<HR>
<a name="contents"></a>
<P>
<FONT SIZE="+2"><B>
CONTENTS
</B></FONT><BR>
<h2 style="background-color: rgb(255, 255, 0);"><b>
What have I done?
</b></h2>

<UL>
<LI>
<a href="#start">STARTING POINTS</a>
<LI>
<a href="#updates">UPDATES</a>
<LI>
<a href="invited-talks.html">
Chronological list of talks and presentations since 2001</a>
<br/>
<small>
A more comprehensive and messy list of presentations, going back
earlier, can be found
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/">here</a>
</small>
<LI>
<a href="#intro">INTRODUCTION</a>
<LI>
<a href="#admin">
ADMIN
</a>
<ul>
<li>
<a href="#admin">
Academic admin</b>
</a>
<li>
<a href="#optimistic">
Optimistic admin:
Helping the community understand what AI is and what it can aim for,
</a>
<li>
<a href="#pessimistic">
Pessimistic admin?
Helping the AI community understand what may be harder than they
think!
</a>
</ul>
<LI>
<a href="#software">
SOFTWARE
</a>
<LI>
<a href="#teaching">
TEACHING: MATERIALS, TOOLS AND EDUCATIONAL IDEAS
</a>
<LI>
<a href="#philmind">
PHILOSOPHY OF MIND
</a>
<LI>
<a href="#upset">
UPSETTING VICE-CHANCELLORS AND OTHER 'SUPERIOR BEINGS'
</a>
<LI>
<a href="#ideas">
OTHER PHILOSOPHICAL AND SCIENTIFIC IDEAS:
</a>
<LI>
<a href="#diagrams">
1. Diagrammatic/visual reasoning
</a>
<LI>
<a href="#architectures">
2. Architectures and requirements (Designs and Niches)
</a>
<ul>
<li>
<a href="#designspace">Design space and niche space (the space of sets of requirements)</a>
<UL>
<LI>
<a href="#cogaff">
CogAff: towards an Ontology for complete architectures
</a>
<LI>
<a href="#hcogaff">
The H-CogAff architecture
</a>
</ul>
<LI>
<a href="#fullydel">
The spectrum of deliberation: from proto-deliberative to
fully-deliberative systems.
</a>
<li>
<a href="#sensorimotor">
Somatic/multi-modal/sensorimotor vs Exosomatic/amodal/objective
</a>
<li>
<a href="#dynamical">
Self-extending networks of multi-stable dynamical systems
</a>
</UL>
<LI>
<a href="#emotions">
3. Emotions -- a special case of Affect
</a>
<LI>
<a href="#virtual">
4. Virtual machines and causation
</a>
<LI>
<a href="#consciousness">
5. Consciousness and virtual machines
</a>
<a name="visioncontents"></a>
<LI>
<a href="#vision">
6. Work on vision, visual architectures and affordances
</a>
<ul>
<li>
<a href="#startvision">
6.a How my work on vision started</a>
<li>
<a href="#cosyvision">
6.b The influence of the CoSy robotic project
</a>
<li>
<a href="#morevision">
6.c Ongoing work on vision related to other things</a>
</ul>
<LI>
<a href="#meaning">
7a.
Work on meaning, the nature of representations, and attacks on symbol
grounding theory
<LI>
</a>
<a href="#information">
7b. What is information?
</a>
<LI>
<a href="#altricial">
8.a. The altricial-precocial spectrum in animals and robots
</a>
<LI>
<a href="#devel">
8.b. Learning and development in some 'altricial' animals
</a>
<LI>
<a href="#gc5">
9. The Grand Challenge 5: The architecture of brain and mind
</a>
<LI>
<a href="#ontology">
10. Incomplete work on an ontology for a simple (or not so
simple) agent
<br>(with links to
perception, learning, problem-solving and causation)
</a>
<LI>
<a href="#robotics">
11. Robotics and The CoSy project.
</a>
<ul>
<li>
<a href="#embodiment">
Issues concerning embodiment
</a>
</ul>

<LI>
<a href="#defragment">
12. Ideas for de-fragmenting AI: at the IJCAI 2005 Tutorial and elsewhere
</a>
<LI>
<a href="#freewill">
13. Free will
</a>
<LI>
<a href="#philsci">
14. Contributions to philosophy of science
</a>
<LI>
<a href="#philmath">
15. Contributions to philosophy of mathematics and philosophy of
logic
</a>
<ul>
<li>
<a href="#earlystuff">
D.Phil Thesis (defending Kantian philosophy of mathematics) and
some early papers
</a>
<li>
<a href="#philmathbirm">
Philosophy of mathematics after coming to Birmingham
</a>
<li>
<a href="#toddlers">
Work on 'Toddler theorems' and how biological competences feed into
mathematical competences.
</a>
</ul>
<LI>
<a href="#antiai">
16. Critiques of people attacking AI (Searle, penrose)
</a>
<LI>
<a href="#irrelevance">
17. Irrelevance of Turing machines to AI
</a>
<LI>
<a href="#better">
18. Contributions to meta-ethics: Work
on the logic of 'better' and 'ought'
</a>
<LI>
<a href="#involuntary">
20. Why some mental states must be expressed involuntarily
</a>
<LI>
<a href="#scenario">
21. Scenario based methodology for AI
</a>
<LI>
<a href="#whyId">
22. Why 'intelligent design' theory should be taught to science
students.
</a>
<LI>
<a href="#philwork">
23. How has the study of philosophy distinguished your work or point of
view?
</a>
<ul>
<li>
<a href="#otherphil">
Other philosophical connections
</a>
</ul>
<li>
<a href="#softeng">
24. Implications of constraints on software engineering for government policies.
</a>
<LI>
<a href="#spread">
25. Generalising Spreadsheets to non-numerical data
</a>
<LI>
<a href="#othertopics">
OTHER TOPICS TO ADD, WHEN I GET TIME.
</a>
<LI>
<a href="#mytalks">
Lots of slides (pdf mainly) prepared for talks in various places
</a>
<LI>
<a href="#workmilitary">
Accused of working for 'the military' ?
</a>
<LI>
<a href="shortcv.html">Shortish CV (separate html file)</a>
</UL>
<P>
<HR>
<P>
<a name="intro"></a>
<p>

<h3><b>
INTRODUCTION
</b></h3>
<blockquote>
In June 2005, Linda World, Senior Editor
IEEE Computer Society, was planning an article for the July/August issue
of
<a href="http://www.computer.org/intelligent/index.htm">IEEE Intelligent Systems</a>
and invited me to list my contributions to 'the field'. This was
flattering but also felt a bit like being asked to write my obituary.
(<a
href="http://www.cs.bham.ac.uk/research/cogaff/misc/linda-world-ieee-0508.pdf">Her
article</a> appeared in the 'Histories and Futures' section of the
journal, including a picture of my attempt to juggle with one of Richard
Dearden's fake weapons.)
<P>
I tried to help her, by producing a patchy list of my doings, and then
realised that I had not previously produced such a list. So, mainly for
my own benefit, I thought I should try to expand it a little and update
it from time to time -- assuming that my ability to do things has not
come to an end just because I passed the UK University retirement age of 65
in 2001.
<P>
So here is the list, warts and all, which has been slowly growing since
then, but is still incomplete and unpolished.
<P>
I'll try to improve and tidy this up from time to time. Some readers
trying to decide what, if anything, to look at may be helped if I can
get this document to supplement the mainly chronological list of papers
in the
<a href="http://www.cs.bham.ac.uk/research/cogaff/">Cognition and Affect</a>
directory by grouping things by topic instead.
<P>
Much of this work is a result of work by others, e.g.
people whose books and papers I read, such as Immanuel Kant, Gottlob
Frege, Gilbert Ryle, Peter Strawson, Karl Popper, Imre Lakatos,
<a href="http://www-formal.stanford.edu/jmc/">John McCarthy</a>,
<a href="http://web.media.mit.edu/~minsky/">Marvin Minsky</a>;
colleagues with whom I worked over many years at Sussex and Birmingham,
including Margaret Boden,
<a href="http://www.cs.bham.ac.uk/research/cogaff/sloman-clowestribute.html">Max Clowes</a>, John Gibson,
David Young, the Poplog team,
Christopher Longuet-Higgins and Ben du Boulay;
Luc Beaudoin and
<a href="http://www.cs.bham.ac.uk/research/cogaff/phd-theses.html">other PhD
students</a> in Birmingham, and more recent close collaborators,
including Catriona Kennedy, Brian Logan, Matthias Scheutz, Manfred
Kerber, Ron Chrisley, Jeremy Wyatt, Jackie Chappell, Push Singh (who
unfortunately died in Feb 2006),
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/">the CoSy team</a>
and
others I've
(temporarily) forgotten. There are many more people I've met at
conferences, visits to other universities, etc. who have taught me
important things, especially people who were in Edinburgh in 1972-3,
when Bernard Meltzer obtained a grant from the SRC to enable me to be
re-born as an AI-informed philosopher. Gerry Martin played a
particularly important role in my education (see below).
<P>
I've often noticed that PhD students find it hard to distinguish their
own ideas from those of their supervisors, and I am sure I have had the
same problem in relation to people from whom I have learnt, especially
when I don't understand something I read, and then 'invent' it later.
</blockquote>

<P>
<HR>
<p>
<a name="admin"></a>
<h3><B>
ADMIN? Or is this Public Service?
</B></h3>
<b>Academic admin</b>
<blockquote>
Building up two AI departments, first at Sussex university between
1973 and 1991, then at Birmingham university 1991- now.
Of course, both involved teamwork: nobody can ever do anything alone,
and I have been very lucky in having extremely able and willing
colleagues (most of the time!)
<P>
</blockquote>
<a name="optimistic"></a>
<b>Optimistic admin</b>
<blockquote>
Helping the community understand what AI is and what it can aim for,
e.g.

<small>
<UL>
<LI>
    <a href="http://www.cs.bham.ac.uk/~axs/courses/ai.html">Overview of AI for UK Quality Assurance Agency, CS Benchmarking panel.</a>
<LI>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/misc/aiforschools.html">Overview for schoolteachers and careers advisers</a>
<LI>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/misc/cs-research.pdf">Varieties of research in CS, AI and software engineering</a>
<LI>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/index.php#tr0503">
AI in a New Millennium: Obstacles & Opportunities
</a>
<LI>
helping to shape shape and promote
<a href="http://www.cs.bham.ac.uk/research/cogaff/gc/">Grand Challenge 5 (GC5) on
'Architecture of Brain and Mind'</a> as part of the UKCRC Computing
Research Grand Challenge initiative.
</UL>
</small>
<p>
</blockquote>
<a name="pessimistic"></a>
<b>Pessimistic admin?</b>
<blockquote>
Helping the AI community understand what may be harder than they
think!
<small>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#711">
Requirements for Digital Companions: It's harder than you think
</a>
<br/>
Position Paper for Workshop on Artificial Companions in Society,
Oxford, October 2006. I tried to present some of the requirements
for a truly helpful, as opposed to merely engaging (or annoying)
artificial companion, with arguments as to why meeting those
requirements is way beyond the current state of the art in AI
(e.g. because current systems know so little about the physical
environment we live in, and how we interact with it, and how things
can go wrong, and what can or should (or should not!) be done about
it.
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#oii">Workshop presentation (PDF)</a>
<p>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#talk58">
What designers of artificial companions need to understand about
biological ones
</a>
<p>
Invited talk at AISB'08, Aberdeen.
<p>
<li>
<a href="#embodiment">
Why the recent emphasis on embodiment has held up progress
</a>
</ul>
</small>
<P>
I have also been on some editorial boards,
(e.g.
<a href="http://www.elsevier.com/wps/find/journaldescription.cws_home/505601/description">AIJ 1997-2005</a>
trying, without success, to get everything freely available online),
and have helped to organise various
workshops, conferences and tutorials, e.g.
<small>
<ul>
<li>
helping to
organise the memorable 1974 first SSAISB conference at Sussex
University,
<li>
organising
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#42">
The IJCAI-95 'Philosophical encounter' session</a> (with McCarthy and
Minsky),
<li>
presenting, with Matthias Scheutz
<a href="http://www.cs.bham.ac.uk/~axs/ijcai01/">a tutorial on
philosophical foundations of AI</a> at IJCAI'01,
<li>
organising the
<a href="http://www.cs.bham.ac.uk/research/cogaff/dam00">DAM (Designing
a Mind) Symposium</a>
at AISB'2000,
<li>
helping to organise
<a href="http://cogvis.fri.uni-lj.si/events/CogSysKickOff/">The EC Cognitive Systems 'kickoff' meeting in Bled, October 2004</a>
<li>
helping to organise
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/conferences/edinburgh-05.html">
a two-day interdisciplinary tutorial at IJCAI'05
</a>
in Edinburgh,
<li>
<a href="http://www.cs.bham.ac.uk/research/cogaff/gc/aisb06">a two day symposium at AISB'06</a>
in Bristol April 2006
</ul>
</small>
</blockquote>
<P>
<HR>
<a name="software"></a>
<h3><B>
SOFTWARE
</B></h3>
<blockquote>
Managed development of the Poplog multi-language AI development system
between about 1980 and 1991 at sussex, then since 1989 have managed
the free open source version when it stopped being a commercial product
    <a href="http://www.cs.bham.ac.uk/research/poplog/freepoplog.html">http://www.cs.bham.ac.uk/research/poplog/freepoplog.html</a>
<P>
Designed and built (with help from users) a powerful toolkit (SimAgent)
used by students and collaborators in attempting to implement some of
our ideas
    <a href="http://www.cs.bham.ac.uk/research/poplog/packages/simagent.html">http://www.cs.bham.ac.uk/research/poplog/packages/simagent.html</a>
</blockquote>
<P>
<a name="teaching"></a>
<HR>
<h3><B>
TEACHING: MATERIALS, TOOLS AND EDUCATIONAL IDEAS
</B></h3>
<blockquote>
<b>March 2007: new syllabus proposal for schools</b>
<blockquote>
In response to debates about why bright school children were turned
off computing and did not wish to do it as a university subject
(e.g. many regard computers simply as rather boring tools that that
you have to learn to use with very little intellectual interest
involved), I developed a draft (overview) syllabus for a two year
interdisciplinary introduction to AI/Cognitive for A-level and
AS-level students (final two years of school in the UK).<br/>
<a href="http://www.cs.bham.ac.uk/~axs/courses/alevel-ai.html">http://www.cs.bham.ac.uk/~axs/courses/alevel-ai.html</a>

<blockquote>
<b>Revised version July 2009</b>
<br/>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#apa">Teaching AI and Philosophy at School?</a>
<br/>
In American Philosophical Association,  Philosophy and
Computers
<a
href="http://www.apaonline.org/publications/newsletters/computers.aspx">newsletter.</a>
<small>
<pre>
    Revised version of <a href="http://www.cs.bham.ac.uk/~axs/courses/ai-syllabus.pdf">http://www.cs.bham.ac.uk/~axs/courses/ai-syllabus.pdf</a>
</pre>
</small>
</blockquote>
</blockquote>
<b>July 2009: </b>
<b>Online teaching materials:</b>
<br/>
Contributed to a lot of teaching materials on AI as part of the Poplog system and the SimAgent toolkit, e.g.
<UL>
<LI>
During July/August 2009 made changes to the Poplog system,
to make it more widely available, and updated information about
teaching materials included and online:
<br/>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/examples/">http://www.cs.bham.ac.uk/research/projects/poplog/examples/</a>
<br/>
This is partly a result of my getting involved with
<a href="http://www.computingatschool.org.uk/">The Computing at School Working Group</a>
<p>
<LI>
    <a href="http://www.cs.bham.ac.uk/research/poplog/teach/grammar">http://www.cs.bham.ac.uk/research/poplog/teach/grammar</a>
<p>
<LI>
    <a href="http://www.cs.bham.ac.uk/research/poplog/teach/storygrammar">http://www.cs.bham.ac.uk/research/poplog/teach/storygrammar</a>
<p>
<LI>
and many other things here
<br>
<a href="http://www.cs.bham.ac.uk/research/poplog/teach/">http://www.cs.bham.ac.uk/research/poplog/teach/</a>
<P>
<LI>
And some slide presentations for teaching here
<br/>
<a href="http://www.cs.bham.ac.uk/research/cogaff/talks/">http://www.cs.bham.ac.uk/research/cogaff/talks/</a>
</UL>
<P>
Also produced notes on AI to feed into the UK Quality Assurance Agency
Benchmarking Panel's deliberations:
<a href="http://www.cs.bham.ac.uk/~axs/courses/ai.html">http://www.cs.bham.ac.uk/~axs/courses/ai.html</a>
<P>
And some notes to help Careers Advisers in schools understand why they
should advise gifted and adventurous students to study AI
<a href="http://www.cs.bham.ac.uk/research/cogaff/misc/whatsai.html">http://www.cs.bham.ac.uk/research/cogaff/misc/whatsai.html</a>
<P>
Co-authored the out of print (mainly tutorial) book
<I>
POP-11 A Practical Language for Artificial Intelligence
</I>
Ellis Horwood, 1985.
With: Ros Barrett and Allan Ramsay. This is <I>partly</I> replaced by
the (more up to date) online primer for Pop11.
<a href="http://www.cs.bham.ac.uk/research/poplog/freepoplog.html#primer">http://www.cs.bham.ac.uk/research/poplog/freepoplog.html#primer</a>
<P>
I think that around 1978 I first introduced TEACH files into the pop11
system which then ran on a PDP11-40 computer under Unix, and was used in
quite a lot of universities, and one school, for teaching and research
in AI. (Imagine living with a 32K address space of 16-bit words). The
idea was to provide text that explained things interspersed with bits of
code that students could select and run, or edit and run in
order to explore and learn in some depth. The earliest version of the
Pop-11
<a href="http://www.cs.bham.ac.uk/research/poplog/teach/grammar">TEACH GRAMMAR file</a>
was developed in this context, with the help of Steve Hardy and other
colleagues.
<p>
In August 2006 I was invited to produce more detailed documentation of
the development of e-learning techniques at Sussex University in the
1970s and 1980s as part of a campaign against a 'moronic' US patent
recently granted. So I wrote
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/poplog-learning-environment.html">this hasty
history</a>. (Also referenced under 1976 in
<a href="http://en.wikipedia.org/wiki/History_of_virtual_learning_environments">this wikipedia history</a>
of e-learning environments.)
<p>
Some related comments about our educational dreams in the 1970s and why
they failed because of bad decisions made by politicians,
educationalists, teachers, parents and others can be found in the third
section of an expanded version of my
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/dsc.html">acceptance speech</a>
for a DSc given to me by Sussex University in July 2006.
<P>
Some of my ideas about education (influenced in part by John Holt,
Seymour Papert, and Ivan Illich) including the profound new
opportunities offered by the use of computers (unfortunately still not
really taken up by the education world as a whole) were
presented in the
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/">The Computer Revolution in Philosophy</a>
and more recently in a paper contributed to the UKCRC initiative on
Grand challenges in Computer Education for the March 2004 conference,
available online
http://www.cs.bham.ac.uk/research/projects/cogaff/misc/gc-ed.html">in PDF and HTML formats</a>.
This was included in the
UKCRC booklet on educational grand challenges available on
their
<a href="http://www.ukcrc.org.uk/grand_challenges/index.cfm">'Grand Challenges' web page.</a>
<blockquote>
<small>
I recently recently discovered that many of the points were made
quite
effectively in
Jeannette Wing: 'Computational Thinking', <i>CACM</i>
vol. 49, no. 3, March 2006, pp.
33-35, available online
<a
href="http://www.cs.cmu.edu/afs/cs/usr/wing/www/publications/Wing06.pdf">here
(PDF)</a> (with
<a href="http://www.cs.cmu.edu/afs/cs/usr/wing/www/ct-slides.pdf">accompanying
slides</a>).
</small>
</blockquote>
<P>
<H3><B>
<a href="gov">How to organise higher education more sensibly</a>
</B></H3>
Including a letter to my MP about why both people arguing for and people
arguing against top up fees made serious mistakes.
</blockquote>
<P>
<a name="philmind"></a>
<HR>

<h3><b>
PHILOSOPHY OF MIND
<br>
<small>
(Added Feb 2006)
</small>
</b></h3>
<blockquote>
Much of my work fits into the part of philosophy labelled `Philosophy of
Mind' which seeks (among other things)
<ul>
<small>
<li>
to analyse many of the concepts we use in talking and thinking about
minds, mental states, and mental processes; for example, concepts
like:
'perceive',
'learn',
'believe',
'want',
'enjoy',
'desire',
'intention',
'puzzlement',
'attention',
'notice',
'wonder about',
'forget',
'deliberate',
'react involuntarily',
'decide',
'aware',
'mean',
'refer',
'understand',
'grasp a concept',
and many others.
(See, for example,
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap4.html">
chapter 4 of the Computer Revolution in Philosophy (1978)</a>)
<li>
to explain the relation between mental and physical phenomena and in
particular to explain how physical phenomena can produce mental
phenomena and how mental events can cause physical events and processes.
(See, for example,
<a href="http://www.cs.bham.ac.uk/research/cogaff/talks/#inf">this talk</a>
on information processing in virtual
machines).
<li>
to explain how we can know anything about minds, whether other minds or
our own minds (which I think is just a special case of the question how
we can know what's going on in virtual machines).
</small>
</ul>
Starting with my 1978 book I have been trying to extend traditional
philosophy by pressing for a 'design-based approach', summarised
<a href="http://www.cs.bham.ac.uk/~axs/#designbased">here</a>, which
contrasts with (among other things) the 'intentional stance' recommended
by Dan Dennett and what Alan Newell called 'the knowledge level'
(both mentioned <a href="#intentional">below</a>). More recently I've
expanded that approach to philosophy of mind to
include considerations of evolution and development, and location of
humans in a much larger space of designs and requirements
discussed <a href="#designspace">here.</a>
<p>
In the January 2006 (fiftieth anniversary) edition of
<a href="http://www.ainewsletter.com/newsletters/aix_0601.htm">AI Expert Newsletter</a>
(assembled by Jocelyn Paine), I found a quotation from the online
version of
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/"> The Computer
Revolution in Philosophy</a> that I think sums up my approach to
philosophy of mind. So I'll quote it here:
<blockquote>
<small>
<i>
Some parts of the book are dated whereas others are still relevant both
to the scientific study of mind and to philosophical questions about
the aims of science, the nature of theories and explanations, varieties
of concept formation, and to questions about the nature of mind.
<P>
In particular,
<a href="chap2.html">Chapter 2</a>
analyses the variety of scientific advances
ranging from shallow discoveries of new laws and correlations to deep
science which extends our ontology, i.e. our understanding of what is
possible, rather than just our understanding of what happens when.
<P>
Insofar as AI explores designs for possible mental mechanisms, possible
mental architectures, and possible minds using those mechanisms and
architectures, it is primarily a contribution to deep science, in
contrast with most empirical psychology which is shallow science,
exploring correlations.
<P>
<a name="intentional"></a>
This "design stance" approach to the study of mind was very different
from the "intentional stance" being developed by Dan Dennett at the same
time, expounded in his 1978 book </I>Brainstorms<I>, and later
partly re-invented by Alan Newell as the study of "The knowledge Level"
(see his 1990 book </I>Unified Theories of Cognition<I>). Both Dennett
and Newell based their methodologies on a presumption of rationality,
whereas the design-stance considers functionality, which is possible
without rationality. as insects and microbes demonstrate well.
Functional mechanisms may provide limited rationality, as Herb Simon
noted in his 1969 book </I>The Sciences of the Artificial<I>.
</i>
</small>
</blockquote>

Some of that thinking arose from learning to program and from reading AI
(especially Minsky's work, e.g. 'Steps towards Artificial
Intelligence' (1963) and his 1968 collection
<i>Semantic Information Processing</i>),
while some of it was inspired by Chomsky's attack on Skinner's
behaviourism, and his ideas about the difference between
characterising/explaining 'competence' and 'performance'.
(Chomsky applied those ideas only to syntactic competence, but the
competence/performance distinction was clearly far more general.
My most recent use of Chomsky's ideas was in a paper
<a href="#irrelevance">[listed below]</a>
explaining why the finiteness of physical brains or
computers does not prevent them implementing infinite
virtual machines.)
<p>
I have recently tried to show that Gilbert Ryle's notion of
doing conceptual analysis as studying 'logical geography' can be
enriched by basing it on a more fundamental analysis of 'logical
topography' which reveals the possibility of alternative logical
geographies in the same portion of reality. More details are
<a href="#topography">below.</a>
<p>
<b>
Multi-disciplinarity
</b>
<blockquote>
<small>
Over the years I have gained an increasing appreciation of the
importance of placing philosophy of mind in a multi-disciplinary
context, which means that doing it really well requires the equivalent
of getting degrees in more disciplines than most people have any hope of
achieving in their lifetime (especially in current academic climate
which applies so much pressure to specialise, in order to get
publications in recognised journals, etc.). I attempted to summarise the
arguments in a posting to the psyche-b email list in 2003, now available
online here

<blockquote>
From Aaron Sloman Fri Jan 17 03:47:20 GMT 2003
<br>
Subject: pre-requisites for discussing consciousness
<br>
<a href="http://www.cs.bham.ac.uk/research/cogaff/misc/consciousness-requirements">http://www.cs.bham.ac.uk/research/cogaff/misc/consciousness-requirements</a>
</blockquote>


</small>
</blockquote>
</blockquote>

<HR>
<a name="upset"></a>
<P>
<h3><B>
UPSETTING VICE-CHANCELLORS AND OTHER 'SUPERIOR BEINGS'
</B></h3>
<blockquote>
I'll try to complete this section one day. I seem to have done a lot of
upsetting in my time because I do or say what I think is right (though I
am also willing to apologise when proved wrong, unlike some of the
people I have upset).
<P>
Here are some examples: failing lots of mathematics students in a logic
exam in my first job (because nobody had told me that it was traditional
in that university for the logic course to be a 'soft' option for
mathematicians), telling a Vice Chancellor in the same university that
ensuring clean cutlery in the student canteen was more important than
ensuring purity of language in student newspapers (he had recently
banned the student newspaper because it used some words he did not
like), objecting to vastly expensive speeding up of landscaping in
another university, just because the Queen was to visit, challenging a
Dean who refused to allow a proposal to go in to meet a deadline, on the
grounds that the committee responsible for discussing such things was
not due to meet until after the deadline (fortunately, an intelligent
Pro-Vice-Chancellor half his size over-ruled him), writing to the prime
minister (then Margaret Thatcher) complaining
about how high level decisions of the Alvey Directors
and Science & Engineering Research Council had been
distorted by pressures from a UK computer company, and
explaining why a 'Buy British' policy for research equipment
could produce an under-resourced and unnecessarily ignorant
research community
(to my amazement the letter
had some effect), objecting to a Dean (in one of my former universities)
who broke an informal promise to some colleagues who had joined us,
objecting to a Vice Chancellor's notion of how we should run our school,
.... and then there's <a href="branding.html">re-branding</a>. My aim is
not to upset, but to raise standards, but too many people don't like
having their mistakes criticised. As for me: that's how I have learnt!
<p>
People should always be ready to learn.
<P>
In compensation for the above, I have tried to teach people
<a href="http://www.cs.bham.ac.uk/~axs/univ/academic.management">how to be good managers</a>
(e.g. when selecting staff always try to make sure that
you appoint people who are better than you are), and several of my
former students and colleagues are now
in senior posts (including one who has been a Pro Vice Chancellor).
<P>
If I have learnt anything about good management, my most important
mentor was Gerry Martin, founder of Eurotherm and other companies, a
very gentle man who showed me many things that universities (at least in
the UK) do wrong. Alas, he died in 2004. Alan Macfarlane has written
much about him and collected some of Gerry's writings
<a href="http://www.alanmacfarlane.com/FILES/gerry.html">here</a>.
Patrick Reader wrote
<a href="http://www.findarticles.com/p/articles/mi_qn4158/is_20040122/ai_n9688922#">an obituary in The
Independent</a>.
<P>
One of the most important things I learnt from Gerry is that
UK universities generally fail to provide recruitment
processes with the effort they deserve: he and I were
allowed to do the preliminary selection of a potential chief
executive of a technology transfer company for AI at Sussex
University. We had about 90 applicants. He insisted that we
interview about 20 of them, and insisted that each interview
last at least half a day. I then learnt why UK universities
make so many inadequate appointments and often suffer the
consequences for many years thereafter. In my current
university that has got worse because of all sorts of
pressures from personnel staff who do not understand what
selection of teachers and researchers means, and so much
pressure on the time of academics that they simply cannot
afford to risk damaging their own careers by putting in the
effort that staff-selection really requires. How sad for
universities and for future students. (American universities
seem to do a far more thorough job).
</blockquote>
<P>
<HR>

<a name="ideas"></a>
<h3><B>
OTHER PHILOSOPHICAL AND SCIENTIFIC IDEAS:
</B></h3>
Not yet in any meaningful order -- just the order in which I thought of
them when composing the list, and then mangled during updates.
<P>
<a name="diagrams"></a>
<H3><B>
1. Diagrammatic/visual reasoning
</B></H3>
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/sloman-1962/">DPhil thesis Oxford 1962</a>
<br>
Title: Knowing and Understanding:
<blockquote>
    Relations between meaning and truth, meaning and necessary truth,
    meaning and synthetic necessary truth
</blockquote>
Trying to understand and defend Kant's claim that there is something
about mathematical discovery that is not just logical deduction from
definitions, especially in geometrical reasoning. This was extended
in various papers, including
my 1968 paper on
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#712">Explaining
Logical Necessity.</a>
(I am still working on this general topic.)
<P>
At IJCAI in 1971 presented
<a href="http://www.cs.bham.ac.uk/research/cogaff/04.html#analogical">a paper</a>
discussing a distinction between 'analogical' and 'Fregean'
representations, and attacking
<a href="http://www-formal.stanford.edu/jmc/mcchay69.html">a very influential 1969 paper</a>
by McCarthy & Hayes.
<P>
I argued that their logicist approach to AI was not wrong in itself, but
needed to be extended to include (among other things) reasoning with
diagrams, which I generalised to 'analogical' representations that use
relations and properties to represent relations and properties, instead
of using only Fregean representations (named after the great logician
<a href="http://plato.stanford.edu/entries/frege/">Gottlob Frege</a>)
in which explicit symbols are used to represent relations, as in algebra
and logic. I gave some examples, and some reasons why the notion of
rigorous reasoning could include diagram manipulation. The paper was
reprinted in the AI Journal, in a Book on representations, and in a
modified form as
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap7.html">Chapter 7</a>
of
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp">The Computer Revolution in Philosophy.</a>
<BR>
In the paper I also explained why 'analogical' representations should
not be defined as isomorphic with what they represent -- a common error
among the many people who have rediscovered the importance of
diagrammatic/spatial reasoning.
<P>
Quite a lot of people have referred to the 1971 paper (and its
successors.) I was not the first to make these points, of course. E.g.
see
<a
href="http://www-groups.dcs.st-and.ac.uk/~history/Mathematicians/Poincare.html">Poincare's</a>
idea's about mathematical intuition, a century ago, also summarised
<a href="http://www.utm.edu/research/iep/p/poincare.htm#H3">here</a>.
<P>
I wrote several sequels to the paper, qualifying some points and
developing the ideas, including
<a href="http://www.cs.bham.ac.uk/research/cogaff/05.html#200501">the 1975 Afterthoughts paper</a>,
some further developments regarding ontologies and criteria for adequacy
in a paper on
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#3">
why we need many knowledge
representation formalisms
</a>
(presented in 1984, published 1985), a
general overview published in 1996
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#31">Towards
a general theory of representations</a>
and several other papers.
<P>
Some recent work expanding on this is in papers on diagrams in the
Cogaff directory, e.g.
    <a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#58">Title: Diagrams in the Mind?</a>
<P>
and this talk

    <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/talks/#vis">Requirements for visual/spatial reasoning</a>
<P>
I also have
<a href="http://www.cs.bham.ac.uk/research/cogaff/sloman-vis-affordances.pdf">
an incomplete draft paper
</a>
linking various kinds of information processing, including perception of
affordances, to the ability to do reasoning with diagrams.
<P>
The most advanced working implementation of this idea that I know of is
a recent PhD thesis in
Edinburgh by
<a href="http://bigred.homelinux.org/~danielw/academic/thesis/proofReaders.htm">Daniel Winterstein</a>
But the task has not yet been completed.
<P>
I am still working on the ideas partly in the context of work on
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0505">vision, and affordances</a>
and in attempting explain some aspects of
<a
href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0506"> how children learn about causation.</a>
<P>
<a name="affordances1"></a>
<b>Diagrammatic reasoning about affordances</b>
<br/>
Inspired partly by problems in making the
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/">CoSy
PlayMate</a> robot perform reliably, and by other things, I began in
November 2007 to
begun to develop some theoretical ideas about the importance of the
ability to predict and explain
<i>changes in affordances</i>, including changes in physical
affordances and in epistemic affordances. See
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0702">
this discussion paper. (HTML)</a>
<p>
There is more about affordances
<a href="#affordances2">below in connection with vision.</a>
<p>
See also work on
<a href="#philmath">Philosophy of Mathematics, below.</a>
<p>
<a name="architectures"></a>
</blockquote>
<HR>
<H3><B>
2. Architectures and requirements (Designs and Niches)
</B></H3>
<blockquote>
<b>
Early ideas about architectures
</b>
<blockquote>
<small>
After I learnt about AI it soon became clear to me that an intelligent
system would need an <i>architecture</i> combining multiple interacting
components performing different tasks, including internal
self-observation. I first wrote about this in memo 59 in the Edinburgh
University Department of Computational Logic, while I was visiting
Edinburgh in 1972-3. It was slightly revised for the <i>AISB
Newsletter</i> in 1973. (I can't find copies of either of those. Memo
59 was probably destroyed in the fire in Edinburgh 2002.)
<p>
The ideas were further developed in
    <a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap6.html">chapter 6 of 'The Computer Revolution In Philosophy'</a>
and
    <a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap9.html">chapter 9</a>
(on the architecture of a simple vision system).
<P>
With
<a href="http://www.cs.bham.ac.uk/research/cogaff/phd-theses.html"> PhD
students
</a>
(e.g. Luc Beaudoin, Ian Wright, Tim Read, Steve Allen, Catriona Kennedy,
Dean Petters), and other colleagues mentioned above, I have been
developing these ideas ever since.
</small>
</blockquote>
<P>
<a name="designspace"></a>
<hr>
<b>
Design space and niche space (the space of sets of requirements)
</b>
<blockquote>
<small>
It soon became clear to me that there was not just one 'right' kind of
architecture, but a wide variety of architectures, including many
produced at different times and in different environments by evolution,
and also different architectures in different stages of development of
the same species, e.g. human infants, toddlers, children, teenagers,
professors...
<p>
So unlike many AI researchers who tried to recommend
<i>one </i> architecture for intelligent systems (ACT, ACT-R, SOAR, PRS,
PRODIGY, CLARION, THEO, Contention scheduling, and many more)
I stressed the importance of exploring both <i>design space</i>
(the space of possible architectures) and
<i>niche space</i>
(the space of sets of requirements -- though biologists use 'niche
space' to refer to something different) and their relationships. The
idea that there were interacting trajectories in both spaces is, as far
as I know original, and still requires to be developed.
<p>
The ideas developed gradually
during the last 30 years. One of the check-points was an invited
talk in Norway:
    <a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#41">Exploring design space and niche space (1995)</a>
<P>
Another was the introduction to a workshop on Designing a Mind
organised in 2000
    <a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#56">Models of models of mind</a>
which explored dimensions in which architectures could vary.
<P>
The work split into two streams fairly early on, summarised briefly in a
PDF presentation on
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/talks/#humarch">'Architectures for human-like machines'</a>
<blockquote>
<a name="cogaff"></a>
<B>
CogAff: towards an Ontology for complete architectures
</B>
<br>
Trying to devise an ontology for describing complete architectures
to help the research community compare and contrast rival proposals: The
CogAff schema described in several papers, based on a three-fold
distinction between reactive mechanisms, deliberative mechanisms, and
meta-management mechanisms with meta-semantic competence, and an
orthogonal three-fold distinction between perceptual, 'central' and
action mechanisms, produced a nine-fold collection of component types.
But this is clearly a crude and inadequate ontology and work still
progresses on intermediate cases (e.g. proto-deliberative mechanisms)
and on filling in the details of the various categories.
<P>
One unusual aspect of this work is its emphasis on architectural layers
in the <i>perceptual</i> and <i>action</i> subsystems which are conjectured to have
evolved in parallel with central layers. In contrast, most people working
on architectures have only 'central' layers, and their relations to
perception and action are unclear. (In the more detailed work I have
used the labels 'peephole' vs 'multi-window' for perceptual and motor
subsystems that are single-layered vs multi-layered (using different levels
of abstraction).
<p>
<b>Added 2 Feb 2015</b>
<br>
The original depiction of the CogAff schema was as a 3x3 grid, with three
horizontal "layers" corresponding to stages of evolution (oldest,
<font color="blue">purely reactive,</font>
at the bottom, with newer <font color="blue">deliberative</font> layer above that, and the
newest <font color="blue">Meta-management</font> layer at the top, superimposed
on three columns: perceptual mechanisms, central mechanisms, and action
mechanisms. But that did not do justice to the actual overlaps, e.g. subsystems
integrating perception with action (such as saccadic eye movements, use of hand
motion to sense type of surface, etc. That led (after prompts and help from Dean
Petters) to this diagram of three overlapping vertical cylinders sliced
horizontally:
<p>
<img alt="newcogaff" border="1" width="500" src="http://www.cs.bham.ac.uk/~axs/fig/new-cogaff.jpg"/>
<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<b>Revised Cogaff Schema</b>

<P>
<a name="hcogaff"></a>
<B>
The H-CogAff architecture
</B>
<br>
Trying to construct and elaborate a hypothetical architecture
H-CogAff, an instance of <a href="#cogaff">CogAff,</a>
rich enough to explain many aspects
of human minds, including the ability of human architectures to grow
themselves. See
    <a href="http://www.cs.bham.ac.uk/~axs/fig/your.mind.jpg">http://www.cs.bham.ac.uk/~axs/fig/your.mind.jpg</a>
<p>
The H-CogAff (schematic) architecture was an enriched version of the CogAff
architecture schema
<p>

Some time during the course of this work
<a href="http://web.media.mit.edu/~minsky/">Marvin Minsky</a>
and I discovered
that we were developing related ideas, but with different emphases and
some different terminology
<blockquote>
e.g. I think he is more concerned with a focus on
human-like systems and I am more concerned with trying to understand the
space of possibilities; also he makes more fine-grained distinctions
between architectural levels and therefore comes up with more levels.
This is in his draft book, <i>The Emotion Machine,</i> on his web site.
(Later published in 2006)
</blockquote>
<P>
(Some of the overlap must be a result of the deep impact some of his
earlier writings had had on me in the early 1970s, including 'Steps
Towards Artificial Intelligence' the introduction to the 1968 book
<I>
Semantic Information Processing
</I>
and his paper 'Matter mind and models', on his web site.)
<p>
<b>2 Feb 2015: Dynamical systems</b>
<br>
The above diagrams did not give any indication of how acquired knowledge and
skills were implemented in the various layers and columns of the architecture.
A paper written around 2007 presented some ideas about multiple layers of linked
dynamical systems, with different subsystems concerned with different domains,
and with excitatory and inhibitory links both within and across subsystems, as
depicted in the diagram on in the section on dynamical systems
<a href="#dynamical">below
</a>.
</blockquote>
</small>
</blockquote>

<P>
<a name="fullydel"></a>
<hr>
<b>
The spectrum of deliberation: from proto-deliberative to fully-deliberative systems.
</b>
<blockquote>
<small>
I have gradually come to realise that what people mean by 'deliberative'
varies so much that it is almost useless as a technical term. This HTML
web site is an attempt to redress this:
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0604">
COSY-DP-0604: Requirements for a Fully Deliberative Architecture
</a>
</small>
</blockquote>

<p>
<a name="sensorimotor"></a>
<hr>
<b>
Somatic/multi-modal/sensorimotor vs Exosomatic/amodal/objective
</b>
<blockquote>
<small>
One of the issues regarding architectures that is not often acknowledged
explicitly is that different architectures, and different parts of the
same architecture may use different <i>ontologies</i>. I.e. they refer
to, get information about, use information about, different
sorts of things in the world. It has become clear in recent years that
many researchers in AI, philosophy, neuroscience, and psychology have
implicitly assumed that a sensorimotor ontology will suffice for all
organisms and robots, i.e. an ontology concerned with patterns,
associations, probability distributions within sensory signals and motor
signals, at various levels of abstraction. We could refer to this as a
'somatic' ontology ('soma' = 'body' in ancient Greek).
<br>
[Earlier I called this 'intra-somatic' in contrast with 'extra-somatic'
(with or without the hyphens), till another pendant reminded me that
while 'soma' is Greek, 'intra' and 'extra' come from Latin. So I have
switched to using 'somatic' and 'exosomatic'.]
<p>
In contrast much work is concerned with what the animal or machine
knows about objects, relations, processes and states of affairs in
the environment, independently of how that information is acquired
or how used in actions. We could refer to this as an 'exosomatic'
ontology. I believe there is much confusion about this, which in its
simplest forms amounts to simply focusing attention on the somatic
and ignoring the exosomatic entities, an attitude encouraged by the
fact that at first sight the brain has <i>only</i> somatic
information to operate on. A web site developed during the CoSy
project, to try to get clear about these issues is
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0603">COSY-DP-0603: Sensorimotor vs objective contingencies (HTML)</a>
</blockquote>
<p>
This is linked to confusions about
<a href="#meaning">'symbol-grounding'</a> discussed elsewhere.
</small>
<hr/>
</blockquote>
<p>
<a name="dynamical"></a>
<b>Self-extending networks of multi-stable dynamical systems</b>
<blockquote>
<small>
Reflections on requirements for vision, including the speed
requirement illustrated
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/multipic-challenge.pdf">in
this PDF presentation</a>, led me during 2007 to start thinking
about complex networks multi-stable multiply-connected dynamical
systems most of which are dormant at any time but through which
activation and suppression signals could propagate at high speed
turning subnets on or off under the control of a mixture of
bottom-up, top-down, middle-out and sideways constraints. A few
sketchy ideas about this were presented in the paper on
Architectures written for a workshop in 2007
<a href="#compmod07">
summarised below.</a>
</small>
</blockquote>
</blockquote>

<P>
<a name="emotions"></a>
<HR>
<H3><B>
3. Emotions -- a special case of Affect
</B></H3>
<blockquote>
I am not particularly interested in Emotions except as a subset of
the broader class of affective phenomena (including pleasure, pain,
desires, preferences, attitudes, moods, values, ideals, motivations,
etc.) that need to be explained within the framework of the
architectures proposed. (I had a few comments on that in
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/">my 1978
book</a>). All of these, in turn, are special cases of or products of biological
control mechanisms, whose variety and depth go unnoticed by many who study
emotions.
<br>
An incomplete list of publications related to the work in this area here can be
found in
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/emotions-affect.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/emotions-affect.html</a>
<br>
THE COGAFF PROJECT: Papers in the Birmingham Cognition and Affect project.
(Still being assembled.)
<br>
I don't work on what is now referred to as
<a href="http://en.wikipedia.org/wiki/Affective_computing">"Affective
computing"</a>, which mostly seems to involve producing machines
that attempt to recognize emotional or other affective states in
humans or which attempt to simulate such states by means of such
things as changes in facial expression, tone of voice, and gestures.
Much of that work ignores the deeper issues about architectures that
need to be addressed in order to understand how affective states and
processes relate to all the other aspects of a human mind.
<p>
In 1997, I wrote a partly critical partly complimentary review of
Rosalind Picard's pioneering book <i>Affective Computing</i>. My
review is available
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/96-99.html#40">here</a>
with a link to her response. Both were published in
<i>The AI Magazine</i>, though errors by the copy-editor which I
failed to spot were in the printed version of my review, so use only
my online version.
<br/>
<p>
Some people seem to think I am specially interested in emotions
and/or affective computing because I wrote a paper with Monica
Croucher, presented at IJCAI in 1981, entitled 'Why robots will have
emotions', which they have misread or misremembered as 'Why robots
should have emotions'.
<small>
(The paper is online here:
    <a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#36">Why robots will have
emotions.</a>)
</small>

<P>
Another paper with Monica Croucher proved to be unpublishable, but
was a Sussex University Technical report in 1981, and has been cited
by others:
<blockquote>
<small>
<a href="http://www.cs.bham.ac.uk/research/cogaff/05.html#200505">
You don't need a soft skin to have a warm heart: Towards a
computational analysis of motives and emotions.
</a>
    (Originally a Cognitive Science Research Paper at Sussex University:
CSRP 004, 1981.)
</small>
</blockquote>
<p>

I later wrote a few other papers on emotions including
these:

<blockquote>
<b>Anger and other emotions:</b>
<br>
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#46">Towards a grammar of
emotions (1982),</a>
taking anger as a special case.
<blockquote>
<small>
NB: this is not a paper about how we <i>talk</i> about emotions, as the
title might suggest, but about the structural diversity of emotions
and the processes involved in their growth and decay.
</small>
</blockquote>
<P>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#6">Motives Mechanisms and Emotions</a>
(<small>in Volume 1 of the journal Cognition and Emotion,
1987.
Reprinted in M.A. Boden (ed),
<i>
The Philosophy of Artificial Intelligence,
</i> OUP 1990</small>)

<P>
<a name="grief"></a>
<b>Grief:</b>
<br>
    <a
href="http://www.cs.bham.ac.uk/research/cogaff/96-99.html#2">Towards a
Design-Based Analysis of Emotional Episodes</a>
        <br> with Ian Wright and Luc Beaudoin.
<blockquote>
<small>
The paper explored in some detail the phenomena reported by someone
recently recently bereaved on the 'alt.grief' internet news group, and
attempted to show how many of the details might be explained within the
framework of our proposed (but very sketchy) architecture -- a precursor
of H-CogAff. The paper was published, (with commentaries) in <b>
Philosophy Psychiatry and Psychology</b>, vol 3 no 2, 1996, pp 101--126.
A html version of the paper, including the commentaries, by
<UL>
<LI>
Dan Lloyd,
<LI>
Cristiano Castelfranchi and
Maria Miceli
<LI>
Margaret Boden
</UL>
 is available
 <a
href="http://muse.jhu.edu/journals/philosophy_psychiatry_and_psychology/toc/ppp3.2.html">
at the Journal's web site
</a> followed by a reply by the authors.
</small>
</blockquote>
</blockquote>

Emotions recently started becoming a fashionable subject of
study partly for bad and confused reasons (including a
fallacious argument presented in Damasio's 1994 book), so I
started trying to write papers and give presentations
explaining the confusions.
<blockquote>
A presentation for a popular
audience is here:
    <a href="http://www.cs.bham.ac.uk/research/cogaff/talks/#cafe04">
Talk 28: Do
machines, natural or artificial, really need emotions?
(2004)</a>
<P>
<small>
One of the things I tried to do was explain how shallow theories of
emotions failed to account for the full variety of types of cases. So
whereas other people distinguished primary and secondary emotions, I
showed how in the framework of the H-Cogaff architecture we could also
distinguish tertiary emotions (involving the meta-management layer). But
there are actually far more subdivisions to be made. People who design
AI architectures with a box labelled 'emotion' have failed to understand
the richness of the phenomena.
</small>
<P>
More recently, with Matthias Scheutz and Ron Chrisley I have tried
to produce a theoretical framework for studying varieties of affect
in organisms (from primitive organisms to humans) and
machines, including emotions as a special case of affect:
<blockquote>
<small>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/03.html#200305">The Architectural Basis of Affective States and Processes</a>
    (Just published in a chapter of a book:
        Who Needs Emotions?: The Brain Meets the Robot, OUP
    in which the copy-editor mangled our paper.)
</small>
</blockquote>
<P>
Although I don't claim to be an emotion-researcher, I sometimes join in
discussions
of the email list of ISRE (International Society for Research
on Emotions). An example (July 2005) is
<a
href="http://www.cs.bham.ac.uk/research/cogaff/misc/messages-to-isre.txt">here</a>.
<P>
In December 2005 I wrote some
<a href="http://www.cs.bham.ac.uk/research/cogaff/misc/emotions-questions.html">quick answers to short questions</a>
about emotions sent to me by a well known emotion researcher.
</blockquote>
<p>
A longer messy (incomplete) file listing things I've written about
emotions is
<a href="emotion-papers.html">here.</a>
<p>
<a name="pride"></a>
<b>Pride</b> (Added: 5 Oct 2007)
<br>
<blockquote>
I have some notes on pride that I wrote as a result of being
interviewed by Jeremy Webb in 1998 for a new Scientist article. The
discussion led to some useful clarification of several points about
varieties of emotions and other kinds of affective states and
processes.
<p>
The correspondence is here:
<br/>
<a href="http://www.cs.bham.ac.uk/research/cogaff/pride.html">http://www.cs.bham.ac.uk/research/cogaff/pride.html</a>
<p>
<a href="http://www.newscientist.com/article/mg15721275.400">http://www.newscientist.com/article/mg15721275.400</a>
<br/> The article (now available free of charge) starts
<blockquote>
<small>
    28 March 1998,  Magazine issue 2127
<br>

"DO birds consider whether the nest they have built is better than the
one built in the next tree?" asks Aaron Sloman, professor of artificial
intelligence and cognitive science at the University of Birmingham. "I
doubt it." If his assessment is correct, it's a safe bet that you won't
find a bird that feels pride.

Sloman's point is that being proud isn't easy. At the very least you
need a sense of "self" and a way to compare yourself with others. So
feeling superior takes a higher level of mental complexity than most
animals can muster. That doesn't apply to all emotions. The fear that
keeps animals out of the path of a predator or a speeding car, for
instance, is almost universal across species and needs little or no
thought.

But it's the complex emotions like pride that fascinate Sloman. He
believes that they arise naturally from the information-processing ...
</small>
</blockquote>
<p>
</blockquote>
<P>
<a name="virtual"></a>
<HR>
<H3><B>
4. Virtual machines and causation
</B></H3>
<blockquote>
Apart from the sorts of divisions between layers of functionality
mentioned above there is a deeper notion of layers of virtual machines
depicted crudely
    <a href="http://www.cs.bham.ac.uk/~axs/fig/levels.jpg">in this
diagram showing multiple levels of reality</a>
where higher levels are <i>implemented in</i> the lower levels, as
opposed to running in parallel with them performing different tasks.
<P>
Philosophers often refer to this relation as 'supervenience'.
Unfortunately they tend only discuss supervenience of states and
properties -- e.g. how can a property of being angry supervene on
brain states. What they should discuss, but mostly ignore, is how
machines can supervene on other machines, especially how virtual
machines can supervene on physical machines. E.g. see
<a href="#mos09">the link above.</a>
<P>
I have written several papers and given presentations on what the
relations are between levels, and how it is that there can be causes and
effects within higher level virtual machines.
<blockquote>
<small>
Perhaps the hardest unsolved problem in philosophy is analysis of
the notion of 'causation'. (A D.Phil student I supervised at Sussex,
Chris Taylor, produced
<a href="http://www.informatics.sussex.ac.uk/users/christay/Tayl93.html">a
very interesting thesis</a>
in 1992 that has only recently been made available online.)
<p>
I believe the problem of how events in virtual machines can be causes is
not only important for philosophers trying to understand the relations
between mind and brain and trying to make sense of notions like mental
processes causing actions (along with muddles about free will) but also
important for scientists trying to understand how minds work by studying
neural phenomena.
<blockquote>
A talk on this can be found here:
    <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/talks/#inf">Talk 26:
What are information-processing machines? What are information-processing virtual machines?</a>
<br>
I argue that besides <i>matter-manipulating</i> and <i>energy-manipulating</i>
machines there are also machines that manipulate <i>information</i>, though we
are still in the early stages of understanding their variety and
producing any sort of general theory about them. Computer scientists
think their general theory of computation does that, but they are only
discussing a subset of the phenomena.
</blockquote>
<p>
Evolution started producing very sophisticated examples long
before we did, and that is part of what made the evolution of humans
possible.
<p>
I argue that like 'energy', and most other deep concepts from the
natural sciences, 'information' is a notion that cannot be explicitly
defined in terms of more familiar or simpler concepts, but can be
<i>implicitly</i> be defined with increasing depth and precision as our
theories about its varieties, forms, functions, consequences, etc.
develop. (As happened with our concept of energy.)
<p>
A peculiar feature of information processing machines is that the most
powerful examples are all <i>virtual</i> machines, whose components and
internal processes are not describable in the language of the physical
sciences, even though they all have to be ultimately <i>implemented</i> in
physical machines.
<p>
A controversial claim I make about virtual machines is that events and
processes in virtual machines can be causes, both of other
virtual machine events, processes and states and also of physical
events,
processes and states, for instance when an operating system detects
an attempt to access a protected file and produces a message on a
screen, or a robot reasons that its current plan will lead to damage and
therefore alters its direction of movement. Analysing our notions of
causation is a very difficult task, not least because we need
<a href="#humeandkant"> two different concepts </a>
a Humean (correlational, probabilistic) and a Kantian (structure based,
deterministic) concept, both of which are unavoidable in science,
engineering and everyday life, including the life of infants.
</small>
</blockquote>
<P>
Matthias Scheutz and I gave a tutorial on Philosophy of AI at IJCAI in
1991 which included discussion of virtual machines and causation (among
other things):
    <a href="http://www.cs.bham.ac.uk/~axs/ijcai01/">http://www.cs.bham.ac.uk/~axs/ijcai01/</a>
</blockquote>
<P>
A short unpublished letter to New Scientist, commenting on a letter
by Daniel Dennett and Andy Clark about consciousness, and
'realisation/realization' is here
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/clark-dennett-realisation.html">
Realisation and Virtual Machines</a>
<P>
A more recent presentation on virtual machines for a general
audience is
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#wpe08">
Virtual Machines in Philosophy, Engineering & Biology (at WPE 2008)
</a>
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/sloman_2_1.pdf">
A short (six page) conference paper summarising the issues for
an interdisciplinary audience.</a>
<p>
There is more about virtual machines and causation in
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0807">COSY-TR-0807 (PDF):
The Well-Designed Young Mathematician
</a>
<br/>
Published in AI Journal December 2008.
<P>
<a name="consciousness"></a>
<HR>
<H3><B>
5. Consciousness and virtual machines
</B></H3>
<blockquote>
<P>
I have been arguing for some time that people who regard the noun
'consciousness' as having some sort of definite reference so that they
can
ask questions like the following are just confused:
'When did <I>it</I> evolve?' 'Why did <I>it</I> evolve?'
'Which animals have machines <I>it</I>?',
'Which machines have <I>it</I>?', 'At what stage of development of a
foetus does <I>it</I> first occur?', 'At what stage is <I>it</I> lost in
various degenerative brain diseases?'
<P>
That is not because consciousness is a matter of degree as some people
suppose (e.g. Susan Greenfield), nor because there is some mysterious
truth which is inaccessible to us, but because the questions are muddled
because the concepts they use are muddled.
<blockquote>
<small>
This point is related to but different from the point made by Minsky
in labelling 'consciousness'
<a href="http://www.edge.org/3rd_culture/minsky/minsky_p2.html">a suitcase
concept</a>. Philosophers sometimes talk about 'cluster
concepts' which are mixtures without definite boundaries. These comments
on consciousness are correct, but <i>in addition</i> it is important
that sometimes people trying to explain what they mean by
'consciousness' (or 'free-will', or 'god', or 'goodness', or 'reality')
end up gesturing at subtly <i>incoherent</i> concepts.
</small>
</blockquote>
The muddle is
something like, but much more subtle than, the muddle involved in asking
'Which way is the universe moving?', or 'Exactly when does a new century
begin - 1st January 2000, or 1st January 2001?', or 'Where exactly does
the earth have to be in relation to the sun for a new day to start?',
or 'When exactly is it midnight on the moon?'.
<a name="cons09"></a>
<p>
<b>Added: 19 Dec 2009</b>
<br/>
<blockquote>
One of the main sources of muddle, which I have only recently
understood clearly is that the concept "X is conscious of Y" is
<i>polymorphic</i> in the same sense as "X is an efficient Y", "X is
a cure for Y", "X is a tall Y", "X is a perfect specimen of Y", and
many more.
<p>
They are all polymorphic in the sense that the instances of the
patterns have very different meanings which depend on the what is
substituted for "X" and for "Y", and also on the context of use.
This is very obvious in examples like "tall house", "tall giraffe",
"tall mouse", where there is no fixed height that has to be exceeded
for something to be tall. Likewise there is no fixed set of
properties that anything has to have in order to be efficient, or a
cure, or a perfect specimen: it will depend at least on Y and the
context, and sometimes on the type of thing X is.
<p>
This can be regarded as similar to the Computer Science concept of
"Parametric Polymorphism" except the polymorphism of ordinary
language concepts is not always made explicit by the provision of
explicit disambiguating parameters: rather the parameters often have
to come from the context.
<p>
I think that to a first approximation "X is conscious of Y" is a
statement about X having access to information about Y which it can
use in some way. But the requirements for this vary enormously
depending on what Y is (the time of day, a toothache, somebody's
unpopularity, the colour of a fingernail, a fallacy in a proof, the
risk in an action, etc.), and also what X is. These points are
elaborated in a long paper on the concept of phenomenal
consciousness, and an associated tutorial, both provoked by the very
mixed and only partially comprehending reactions to a paper I wrote.
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#cons09">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#cons09</a>
<br/>
Why the "hard" problem of consciousness is easy and the "easy" problem hard.
    (And how to make progress) (PDF tutorial presentation)
<br/>
Also on
<a href="http://www.slideshare.net/asloman/presentations">slideshare.net in flash.</a>
<p>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#906">http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#906</a>
<br>
Phenomenal and Access Consciousness and the "Hard" Problem:
    A View from the Designer Stance
<blockquote>
This was published, along with a related paper and commentaries, in
<a href="http://www.worldscinet.com/ijmc/02/0201/S17938430100201.html">Vol 2, Issue 1
of "International Journal of Machine Consciousness"</a>
<br/>
Unfortunately, the commentaries are not freely available, only my
responses, which could be very unfair to commentators.
</blockquote>
<p>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#910">http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#910</a>
<br/>
An Alternative to Working on Machine Consciousness.
<br/>
Invited "target" article too hastily written
for International Journal of Machine Consciousness.
</ul>
Those items can be regarded as updated versions of this 2001 slide
presentation (PDF):
    <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/talks/#talk9">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/talks/#talk9</a>
</blockquote>
<P>
Partial attempts to expose the confusions can also be found in these
unpublished discussion papers
<UL>
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/96-99.html#33">The evolution of what?</a>
<LI>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/rock/">'What is it like to be a rock?'</a>
<br>
(A semi-serious paper, which seems to be one of my most frequently
referenced.)
</UL>
In a usenet posting which I had forgotten, but recently
discovered quoted by Marvin Minsky
<a href="http://web.media.mit.edu/~minsky/E4/eb4.html">here</a>, I once
put the point thus:
"It is not worth asking how to define consciousness, how to
explain it, how it evolved, what its function is, etc., because there's
no one thing for which all the answers would be the same. Instead, we
have many sub-capabilities, for which the answers are different: e.g.
different kinds of perception, learning, knowledge, attention control,
self-monitoring, self-control, etc." (posting to
<I>comp.ai.philosophy</I> circa December 1994).
<P>
As an antidote to the confusions I have for some time being trying to
argue that if we think of a mind as a control system, then we can see
that there are very many types of control system, as pointed out in
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#18">The mind as a control
system</a>. Some control systems include quite sophisticated
self-monitoring, and can to that extent be described as having
particular kinds of self-consciousness that other systems lack. The full
variety of types of process needed to replicate all the phenomena that
cause humans to be aware that they have minds and to be puzzled by what
they know has not yet been analysed.
<p>
Some of the more subtle phenomena
are mentioned in this paper
    <a href="http://www.cs.bham.ac.uk/research/cogaff/03.html#200302">Virtual Machines and
Consciousness</a>,
    (written with Ron Chrisley for a book edited by Owen Holland, and
published in JCS). In particular we try to show how a self-monitoring
system that develops its own ways of categorising its internal states
using some sort of self-organising classifier, would have concepts that
are 'causally indexical' and inherently incommunicable to others. This
is a core part of the explanation of the phenomena that make
philosophers and others want to talk about 'qualia' or 'what it is like
to be a so and so' (a deeply seductive piece of disguised nonsense).
<p>
A strategy I recommend strongly, but which puzzles and irritates people
who want to talk about consciousness, is this:
<blockquote>
<small>
<i>
The best way to understand consciousness is to stop talking about it and
instead try to analyse and explain <i>everything</i> else (including
sensing, perception, remembering, inferring, explaining, noticing,
attending, being surprised, being puzzled, stopping being puzzled,
wanting, preferring, disliking, being obsessed, falling asleep, waking
up, being hypnotised, and many, many more). Then it will turn out that
everything of substance that could be said or asked about consciousness
will already have been covered.
</i>
<p>
A
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0602">
slide presentation</a>
on learning to experience a 3-D
environment containing manipulable objects and many affordances,
illustrates the approach.
<p>
</small>
</blockquote>
<b>Some other things related to consciousness (Added 25 Feb 2007)</b>
<ul>
<a name="stapp"></a>
<li>
Interactions with Henry Stapp (and others) on
consciousness and quantum mechanics. This went on for several years, and
involved Pat Hayes, David Chalmers, Kathy Laskey, Stan Klein, and
others.
See Henry Stapp's website for details:
<br>
<a href="http://www-physics.lbl.gov/~stapp/stappfiles.html">http://www-physics.lbl.gov/~stapp/stappfiles.html</a>
<blockquote>
Examples:
<br/>
<a href="http://www-physics.lbl.gov/~stapp/aaron.txt">Reply to Aaron Sloman on Science and the Human Person (Dec 14, 2000)</a>
<br/>
<a href="http://www-physics.lbl.gov/~stapp/s-h.txt">Reply to Sloman
and Hayes, Nov 6, 1999</a>
<br/>
<a href="http://www-physics.lbl.gov/~stapp/repslo-9-24-98.txt">Classical
Physical Theory vs Pragmatic QT. [Reply to Sloman] Sept 24, 1998
</a>
<br />
And others
</blockquote>
<li>
Notes on a presentation at the Royal Society of Arts on Consciousness
on 26th Feb 1996:
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/consciousness.rsa.text">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/consciousness.rsa.text</a>
<br>
A systems approach to consciousness (How to avoid talking nonsense?)
<blockquote>
<small>
I am embarrassed to be writing about consciousness because my impression
is that nearly everything written about it, even by distinguished
scientists and philosophers, is mostly rubbish and will generally be
seen to be rubbish at some time in the future, perhaps two hundred years
from now. This means that my own work is probably also rubbish.
<p>
However I shall outline some ways in which we can hope to make progress
through collaborative, multi-disciplinary research. By doing this work
we are sure to learn <i>something!</i>
<p>
First, I need to distinguish three different types of questions,
empirical questions, design questions and conceptual questions. Design
questions are at the heart of our problems.
</small>
</blockquote>
</ul>
</blockquote>

<P>
<a name="vision"></a>
<HR>
<H3><B>
6. Work on vision, visual architectures and affordances
<br>
(Updated 8 Mar 2008, and 8 Mar 2009)
</B></H3>
<a name="startvision"></a>
<h3><b>
<small>
6.a How my work on vision started</a>
</small>
</b></h3>
<blockquote>
My work on vision in AI goes back to discussions with
<a href="http://www.cs.bham.ac.uk/research/cogaff/sloman-clowestribute.html">Max
Clowes</a> whom I met around 1969. Unlike most AI vision
researchers, I was largely motivated by attempting to show that
human visual capabilities are closely related to human mathematical
capabilities, especially our ability to reason about geometrical and
topological structures and processes. This led to my first AI
publication
<a href="http://www.cs.bham.ac.uk/research/cogaff/04.html#200407">http://www.cs.bham.ac.uk/research/cogaff/04.html#200407</a>
(paper in IJCAI 1971) arguing against the logicism of
<a href="http://www-formal.stanford.edu/jmc/mcchay69.html">
(McCarthy and Hayes, 1969).</a> I tried to show that intelligent
agents will sometimes find it useful to reason with analogical
representations. But I was aware then (and stated in the paper) that
a lot more work was needed to enable machines to understand and
reason about spatial structures. That paper got me an invitation
from Bernard Meltzer to spend a year (1972-3) in Edinburgh during
which I learnt a lot more about AI, vision and robotics.
<p>
A few years later (around 1975) a UK research council grant enabled
me to work (at the University of Sussex) on implementing a first
draft visual architecture (with much help from David Owen, then
later Geoffrey Hinton and Frank O'Gorman). We developed the
Popeye program, described in
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap9.html">
Chapter 9</a> of
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/">The Computer Revolution in
Philosophy</a>. The work was too unfashionable and our request for
funds to expand it was unsuccessful.
<p>
I have continued working vision intermittently since then -- mostly
clarifying requirements, and also partially specifying designs for a
visual architecture.
<p>
In 1982 I was invited to give a talk on
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/06.html#604">
Image Interpretation, The Way Ahead?
</a> at an international symposium organised by
The Rank Prize Funds, London, Sept 1982. The proceedings were
published in 1983.
This paper enlarged the
requirements specification, for instance pointing out for visual
control of actions it was sometimes more effective to compute
changing 2-D relations in the optic array (or image plane) rather
than working out the full 3-D structures and 3-D relations of the
objects involved in the action. I believe that much confused
theorising about visual pathways concerned with "what" vs "where"
information was based on a failure to understand that distinction
properly.
<blockquote>
<small>
The distinction was later confusingly described by Milner and
Goodale as being a distinction between "perception" vs
"guidance of action", e.g. in
<a href="http://psyche.cs.monash.edu.au/v4/psyche-4-12-milner.html">The
Visual Brain in Action
</a> (1988).
</small>
</blockquote>
<p>
As a result of that publication I was invited by the editor
Journal of Experimental and Theoretical Artificial
Intelligence to write a paper on vision, and the results was
published in 1989.
    <a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#7">
    On designing a visual system: Towards a Gibsonian
    computational model of vision.
</a>
This elaborated some of the points in the 1982 paper, including a
critique of "Modular" theories of vision, such as the one proposed
by David Marr in his 1981 book. Instead I offered a "labyrinthine"
theory of vision, proposing far more links in various directions
between visual subsystems and other subsystems in a human
information processing architecture. I also composed a list of
common erroneous beliefs about the nature of vision, most of which
still seem to be alive and well in 2008.
<p>
As a result of publication of that paper I was invited by David
Vernon in 1991 to give a talk on "How to design a visual system --
Gibson remembered", to a workshop on vision he organised in
Ireland, whose proceedings were published in
<i>Computer vision: craft, engineering, and science</i>, Ed D.
Vernon, Springer Verlag, 1994. David kindly produced a chapter of
that book from my slides, as I was too busy with my new commitments
at Birmingham.
<P>
I continued developing ideas about requirements for visual systems
as part of my work on architectures for human like machines. In
particular this continued to develop the idea of perceptual
subsystems requiring multiple ontological layers (not the same as
part-whole hierarchies). These layers correspond, in part to
different stages in evolution of intelligent animals, and have their
main connections to different layers in the central cognitive
system, e.g. because they share information structures and
ontologies with different central subsystems. An example was the
evolution of perceptual layers concerned with "reading" minds of
other intelligent agents, which would share a meta-semantic ontology
with an architectural layer concerned in part with self-monitoring
and self-control (meta-management) was well as acquisition and use
of information about others. Another example is the need for a
perceptual layer (or layers) capable of seeking and acquiring
information of a kind that can be used by <a href="#fullydel">a
fully deliberative</a> cognitive subsystem.
<P>
My next paper specifically about vision was
    <a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#76">
Evolvable Biologically Plausible Visual Architectures,
</a>
     in Proceedings of British Machine Vision Conference, Manchester,
Sept 2001. (Conference interrupted by 9-11).
This attempted to make the point that studying vision on its own
would lead to poor requirements specifications, which could be met
by designs that were not extendable for use in some complete
architectures, e.g. human-like architecture. This is related to what
I later started calling the difference between "scaling up" and
"scaling out". Many AI systems are designed with the requirement to
scale up (i.e. continue to perform well as problem complexity
increases). In contrast biological systems, and subsystems in
human-like robots need to be able to "scale out", namely they need
to be able to be integrated with many other components in a fully
functional architecture where subsystems often have to cooperate.
Most AI designs for mechanisms do not meet that requirement because
they are designed for and tested in limited test harnesses, often
with fairly simple agreed benchmarks that are nowhere near an
adequate sample of requirements in a fully functional robot.
<p>
<a name="affordances2"></a>
A draft incomplete paper on visual affordances, inadequacies in HCI,
evolution of
varieties of forms of representation, the role of vision in reasoning,
and related topics is
    <a href="http://www.cs.bham.ac.uk/research/cogaff/sloman-vis-affordances.pdf">
What the brain's mind tells the mind's eye.
</a>
I started it in 2002, and don't know if I'll ever finish it. It overlaps
with more recent things. It includes some important points about
different ontologies and different forms of representation that
still need to be developed fully.
<P>
</blockquote>
<a name="cosyvision"></a>
<h3><b>
<small>
6.b The influence of the CoSy robotic project
</small>
</b></h3>
<blockquote>
The EU-funded
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/">CoSy
project</a>) started in September 2004 as part of the EU Cognitive
Systems initiative. One of my tasks in that project was to work on
requirements for representations in a robot interacting with a 3-D
environment, including manipulating 3-D objects. During 2005, while
working with Jeremy Wyatt and others on some of the problems facing
a robot manipulating 3-D objects of various structures on a table
top (the
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/PlayMate-start.html">PlayMate
demonstrator</a>)
I realised the need for a
new (possibly new?) theory of vision which combined many elements of
what I had previously been working on, including vision,
spatial/visual reasoning, causality, virtual machines,
varieties of representation.... The main new feature was recognition
of the central importance of concurrent perception
of <i>processes</i> at different levels of abstraction, all of which could
be aspects of a single physical process.
<p>
I gave a talk on this entitled
'A (possibly) new theory of vision' (with apologies to
Berkeley), in several universities in October and November 2005.
It is closely
related to a presentation on children learning about
<a href="#humeandkant">two kinds of causation, </a>
namely Kantian and Humean causation, also given in October 2005.
Papers and presentations on vision and causation since that date
have further developed the ideas.
<P>
<blockquote>
<small>
The two related PDF presentations developing the ideas were
installed online in October 2005, and may continue being developed:
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0505">
A (possibly) new theory of vision
</a>
<br>
<a
href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0506">
Two views of child as scientist: Humean and Kantian
</a>
<p>
</blockquote>
Work arising out of that led to a discussion paper in the form of
a web page expanding some of the ideas:
<a href="http://www.cs.bham.ac.uk/research/cogaff/misc/orthogonal-competences">
Orthogonal Competences Acquired by Altricial Species</a>,
which overlaps with and extends John McCarthy's paper on
<a href="http://www-formal.stanford.edu/jmc/child1.html">The well-designed child.</a>
</small>
</blockquote>
</blockquote>
<a name="morevision"></a>
<h3><b>
<small>
6.c Ongoing work on vision related to other things
</small>
</b></h3>
<blockquote>
All the above also links up with the work on
<a href="#affordances1">predicting and explaining
affordances and changes in affordances,</a>
including both <i>action</i> affordances and <i>epistemic</i>
affordances, which was partly inspired by reflections on the
inadequacies of our current robot's visual control of manipulation.
<p>
<a name="compmod07"></a>
In 2007 I was invited to give the introductory talk at a
BBSRC-funded Computational Modelling Workshop, organised by Dietmar
Heinke:
<blockquote>
<a href="http://comp-psych.bham.ac.uk/workshop.htm">http://comp-psych.bham.ac.uk/workshop.htm</a>
<br/>
Closing the gap between neurophysiology and behaviour:
A computational modelling approach
<br/>
University of Birmingham,
May 31st-June 2nd 2007
</blockquote>
I used the opportunity to illustrate aspects of the speed of
processing of totally unexpected visual views right up to high
levels of abstraction, and an informal experimental presentation
making the point is available here
<blockquote>
<small>
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/multipic-challenge.pdf">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/multipic-challenge.pdf</a>
<br>
Originally forming part of the workshop PDF presentation:
<br/>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#compmod07">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#compmod07</a>
</small>
</blockquote>
The paper subsequently written for the workshop proceedings
provided both a retrospective summary of my work on vision,
emphasising the link between vision and mathematical reasoning,
and included some new ideas, including a sketchy suggestion for a
network of dynamical systems some closely coupled with the physical
environment some not. A shortened version was published in the
conference proceedings (to appear 2009):
<blockquote>
<small>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0801">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0801</a>
<br>
Architectural and representational requirements for seeing processes
and affordances. (PDF)
</small>
</blockquote>
Among other things, the paper generalises the notion of
'affordances' to include 'proto-affordances' which are concerned
with possibilities for and constraints on changes in the environment
that are not necessarily related to the perceiver's goals and
capabilities, discusses various ways in which proto-affordances can
be combined and the implications for the variety of forms of
representation required in a visual architecture. It also
distinguishes action affordances from epistemic affordances, and
discusses representational and other requirements for <i>composition</i> of
affordances.
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0801a">The full paper</a>
was also published in proceedings of
<a href="http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=08091">
a Dagstuhl workshop on vision
</a>
held in February 2008.
<p>
Related developments linking work on vision to work on
mathematical understanding, came
from the opportunity to present some ideas
described in the section on
<a href="#liverpool">philosophy of mathematics</a>,
about how mathematical capabilities were related to human visual
capabilities and what this implied for philosophy of mathematics.
<p>
I have attempted to summarise work I have been doing on requirements
for vision in
<br/>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/vision-requirements.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/vision-requirements.html</a>
<br/>
It includes a list of most of my papers, presentations and
discussion notes on vision and its functions.
</blockquote>


<P>
<a name="meaning"></a>
<HR>
<H3><B>
7a.
Work on meaning, the nature of representations, and attacks on symbol
grounding theory
</B></H3>
<blockquote>
This work has several interrelated strands, including attempting to
go beyond factional disputes about which forms of representation are
best towards analysing dimensions in which representations can vary
and the tradeoffs, and also analysing the requirements for a machine to
use semantic information, since I thought that Dennett's claim that we
had to adopt the 'Intentional stance' in order to attribute meaning was
false.
<p>
Much of the work is also an attack on the view that all meaning has to be derived
from experience of instances, i.e. concept-empiricism, demolished in 1780 by Kant,
and again by 20th century philosophers of science (because it cannot account for the
meanings of theoretical terms in deep scientific theories), but always tempting to
beginner philosophers. The idea is frequently reinvented in ignorance of the work of
Kant and the philosophers of science. A recent example is the spread of adherence to
'Symbol-grounding' theory, which I have contrasted with the theory that the semantic
content of most concepts comes from their roles in theories using the concepts, where
the theories are loosely 'tethered' to observable, measurable, phenomena via
techniques and mechanisms for observation, experiment and measurement. which can
change without changing the core theory. So I now contrast <b>symbol grounding</b> with
<b>theory tethering.</b> The use of the idea of tethering in this context was
suggested by Jackie Chappell, when we began to collaborate in 2005.

<UL>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/sloman-1962/">My 1962 DPhil thesis</a>
was in part about varieties of concepts and definitions.

<li>
<a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#67">
The primacy of non-communicative language (1979) </a>
<br>
argued that before
external communicative language could develop there had to be internal
forms of representation with syntax and semantics. This was also a
pervasive assumption of
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/">my 1978 book.</a>
There's more on evolution and development of language
<a href="#primacy">below.</a>
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#3">Why we need many knowledge representation formalisms
(1984-5)</a>
<br>
both extended some of the work on analogical/Fregean
representations, showing that there are actually many ad hoc forms of
representation with different features, useful for different kinds of
reasoning and other functions, and analysed some of the ontological
presuppositions of some logical and non-logical forms of
representations.
<LI>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#4">
     What enables a machine to understand?
</a>
<br>
in IJCAI 1985, tried to show that understanding was not an all or
nothing phenomenon and that a primitive form was present in all
computers. This and other papers stressed the role of the
<i>
structure of a theory
</i>
as a major determinant of meaning (later called the 'Symbol tethering'
analysis of meaning, in contrast with 'Symbol Grounding'.
<LI>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#5">
      Reference without causal links,
</a>
<br>
in ECAI 1986, argued against notions that reference had anything to do
with causal links or correlations (e.g. because you can refer to the
distant past or to non-existent or even impossible entities)
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#31">
Towards a general theory of representations (1996)
</a> was one of several attempts to characterise dimensions in which
forms of representations could vary.
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#18">
The mind as a control system (1996)
</a> attempted to show that within a complex architecture different
functions could be performed in parallel, requiring different sorts of
representations for different tasks.
<LI>
    <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/talks/#meanings">Talk on varieties of meaning</a>
-- one of several attacks on 'symbol grounding theory'.
<br>
Another is
<a href="http://www.cs.bham.ac.uk/research/cogaff/talks/#grounding">
Getting meaning off the ground: symbol grounding vs symbol
attachment/tethering
</a>
(2002).
</a>
<p>
<LI>
<i>
Disguised nonsense
</i>
<br>
As explained above in connection with consciousness, I've
tried to explain (partly inspired by Kant, Frege and Wittgenstein) how
we can, especially when doing philosophy or hard science, invent
<i>incoherent</i> concepts without realising it. Special cases are logical and
semantic paradoxes like 'The liar paradox' and sentences like 'The
father of the subject of this sentence is a mathematician', discussed in
<a href="http://www.cs.bham.ac.uk/research/cogaff/03.html#200304">
Tarski, Frege and the Liar Paradox',
</a>
     Originally in <I>Philosophy</I>, Vol XLVI, pages 133-147, 1971.
<br> But many more subtle examples arise in connection with discussions
of qualia, free-will, god, platonism in mathematics, ....
</UL>

Symbol-grounding theory is just a reinvention of the old philosophy of
concept empiricism, refuted around 1780 by Kant, but still found very
compelling by non-philosophers who only think about very simple
concepts. I've tried to present an alternative, building on work of 20th
Century philosophers of science (e.g. C.G. Hempel's work on 'meaning
postulates', and Tarki's semantic theories) who thought about the role
of concepts in deep scientific theories referring to things that could
not be experienced (e.g. 'neutrino', 'electromagnetic radiation') and
other things.
<P>
From this viewpoint, meaning comes mainly from structure (e.g. syntax if
you like) and how the structure is used, which determines a class of
possible interpretations. There is always some residual indeterminacy or
ambiguity which can be progressively diminished both by adding more
structure and by adding links to perception and action, which, for a
while I called 'symbol attachment', but which Jackie Chappell persuaded
me to call 'symbol tethering', explained in the above papers and
presentations.
</blockquote>
<P>
<a name="information"></a>
<HR>
<H3><B>
7b. What is information?
</B></H3>
<blockquote>
For many years, like many other scientists, engineers and philosophers,
I have been writing and talking about "information-processing" systems,
mechanisms, architectures, models and explanations, e.g.:
<UL>
<LI>
My 1978 book
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/">
<I>The Computer Revolution in Philosophy</I>
</a>
(especially chapter 10).
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#18">
The mind as a control system,
</a> (A paper written in 1993 and published in 1996).
</UL>
Since the word "information" and the phrase "information-processing"
are both widely used in the sense in which I was using
them, I presumed that I did not need to explain what I meant.
Alas I was naively mistaken:
<UL>
<LI>
Not everyone agrees with many things now often taken as obvious, for
instance that all organisms process information.
<LI>
Some people think that "information-processing" refers to the
manipulation of bit patterns in computers.
<LI>
Not everyone believes information can cause things to happen.
<LI>
Some people think that talk of "information-processing" involves
unfounded assumptions about the use of representations.
<LI>
There is much confusion about what "computation" means, what its
relation to information is, and whether organisms in general or brains
in particular do it or need to do it.
<LI>
People often ask for a definition if "information" and if one is not
forthcoming think that must mean the concept is flawed.
<LI>
Most people who discuss issues relevant to natural or artificial
information processing systems do not have enough knowledge of what
virtual machines are, how they are implemented in lower level virtual or
physical machines, or how events in virtual
machines can be causes. Software
engineers understand these matters and use them in their work every day,
but this is <I>craft</I> knowledge and they do not articulate it
explicitly in a manner than clarifies the philosophical issues.
<LI>
As a philosophical software engineer I have tried to explain things in a
way that will, I hope, clarify some debates in philosophy, AI, cognitive
science, psychology, neuroscience, and biology.
Examples are in these documents:
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#inf">
What are information-processing machines?
What are information-processing virtual machines?
</a>
<br>
(A talk presented in 2003 and repeated several times since in various
places.)
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#grounding">
Getting meaning off the ground: symbol grounding vs symbol
attachment/tethering
</a>
<br>
(A talk prepared for a visit to MIT in 2002, also tested in Birmingham).
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/whats-information.html">What is information? Meaning? Semantic content?</a>:
My extended answer to a request to define "information" on the
<a href="http://www.jiscmail.ac.uk/archives/mindmechanisms.html">MindMechanisms</a>
email list.
<br>
(Expanded since the original posting to the MM list, and likely to
grow).
<li>
A section on different kinds of information in biological systems in
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/sloman-vis-affordances.pdf">
An incomplete paper on vision and affordances.
</a>
</ul>
At some point I should try to pull all that stuff together in a
monograph or book, though by then technical and scientific books, and
possibly philosophical ones too,
will probably be defunct.
</blockquote>
<a name="altricial"></a>
<HR>
<H3><B>
8.a The altricial-precocial spectrum in animals and robots
    and the evolution of intelligence
</B></H3>
<blockquote>
    The nature-nurture tradeoff as an aspect of the exploration of
    design space and niche space.
<P>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/05.html#200502">
The Altricial-Precocial Spectrum for Robots
</a>
For IJCAI-05
co-author Jackie Chappell (School of Biosciences University of
Birmingham)
<P>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/05.html#200503">
    Altricial self-organising information-processing systems,
</a>
     Abstract for International Workshop on The Grand Challenge in
Non-Classical
     Computation 18-19th April 2005, York, UK
co-author Jackie Chappell (School of Biosciences University of
Birmingham)
<P>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0609">
Natural and artificial meta-configured altricial information-processing
systems
</a> (invited journal paper, with Jackie Chappell, to appear in IJUC,
in 2007). Closely related is
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0604">
this seminar presentation (PDF)
</a>
on 'Ontology extension' in evolution and in development, in animals and
machines (2006).
<blockquote>
<b>Updated 2 Feb 2015</b>
<br>
Key ideas in both that paper and the presentation are summarised in
this diagram illustrating aspects of epigenesis:
<p>
<img alt="ijuc" border="1" width="500"
src="http://www.cs.bham.ac.uk/~axs/fig/evol-behav-rec-delay.jpg"/>
<p>
The routes from genome to behaviours on the left, are evolutionarily old, and
more sophisticated versions are found in precocial species, born or hatched with
mostly previously evolved competences.
<p>
Routes further to the right (a) depend on later products of evolution in the
genome, and (b) are manifested later in individual development, some quite late
in life. The routes from genome to behaviour further to the right depend on more
waves of influence from the environment during stages of individual development.
<p>
This is also related to our work on
<a href="#evolang">evolution of language.</a>
</blockquote>
<P>
This work is about the differences between animals that get most of
their cognitive competence from their genes (e.g. deer that can run with
the herd soon after birth) and animals that apparently start off much
less competent, but through play and exploration build deeper and richer
cognitive systems with more varied and complex end results, depending on
the environment.

<p>
A challenge to anti-nativists to explain how an animal (e.g. a human)
can interpret a moving collection of 2-D lines as a projection of a
rotating 3-D wire-frame cube, using only a general purpose learning
algorithm, with no prior information about 3-D structures and process in
it implicitly or explicitly can be found
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/nature-nurture-cube.html">here.</a>

<P>
<a name="primacy"></a>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#67">
        The primacy of non-communicative language (1979) </a>
<blockquote>
This argues
that both in evolutionary and developmental processes rich,
structured, internal languages (forms of representation) had to exist
before the development of external languages used to communicate. This
is because of the information processing requirements for perception,
learning, planning, information seeking, collaboration, fighting, etc.
in animals and young children that lack external linguistic competences.
This implies that the evolution of language in our species and the
development of language in young children instead of requiring a huge
discontinuity in the architectures and mechanisms instead required
relatively minor changes to support new applications of mechanisms that
existed earlier.
<p>
This leads to a new theory of the nature of linguistic
communication,
as just another aspect of creative intelligence. This can
be combined with Grice's theories of the principles of discourse to
produce what I think may be a new theory about various aspects of
language, as presented in
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0605">this
draft discussion paper</a> (Spatial prepositions as higher order
functions: And implications of Grice's theory for evolution of
language.)
<p>
<a name="evolang"></a>
Added 20 Mar 2007:
<br>
In March 2007 I gave a talk attempting to bring some of these ideas
together, using a generalised notion of language (g-language) which
can be used entirely for internal processing (e.g. in planning,
learning, reasoning, perceiving, wanting, etc.). The PDF slides are
online here:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0702">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0702</a>
<br>
What is human language? How might it have evolved?
<p>
<b>26 March 2007</b>
<br>
Short commentary (with Jackie Chappell) on the book by Jablonka and
Lamb, <i>Evolution in Four Dimensions</i>, for BBS:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0307">Computational Cognitive Epigenetics</a>
to appear in
<i>Behavioral and Brain Sciences</i> 2007.
</blockquote>
<P>
<a href="http://www.cs.bham.ac.uk/~axs/polyflaps">Polyflaps</a> are an
attempt to identify one of a range of possible domains in which an
altricial robot might learn by exploratory play.
<P>
Because biologists use the altricial/precocial distinction in a
rather narrow way, Jackie Chappell and I have started (since 2005)
talking about two kinds of competence: preconfigured (e.g. mainly
determined by genes, even if they develop relatively late) and
meta-configured, i.e. determined by interactions between
preconfigured bootstrapping programs and the current environment.
The latter allow far greater diversity across generations, and much
faster learning than most of the current AI learning mechanisms. For
more on this see
<a href="#altricial">the section on precocial and altricial
(preconfigured and metaconfigured) competences.</a>
</blockquote>
<P>

<a name="devel"></a>
<HR>
<H3><B>
8.b. Learning and development in some 'altricial' animals
</B></H3>
<blockquote>
The work described above, in combination with some recent (late 2005)
work on <a href="#vision">vision as providing information about
processes</a>
(mentioned above) has led to a new kind of focus on learning (in humans,
a few other animal species, and future robots) as based on a mixture of
'meta-level' innate mechanisms and playful exploration driven by those
mechanisms, as a result of which the child acquires many 'orthogonal'
competences based on what has been learnt about the environment, and
learns how to recombine those competences in perceiving new situations
and solving new problems.
<P>
Some of the ideas are presented in this web site:
<a href="http://www.cs.bham.ac.uk/research/cogaff/misc/orthogonal-competences.html">'Orthogonal
competences'</a>.
<P>
A summary of the ideas was presented as
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/presentations/cogsys2-poster.pdf">a
poster (PDF)</a>
at the CogSys II conference in Nijmegen, April 2006.

</blockquote>

<P>
<a name="gc5"></a>
<HR>
<H3><B>
9. The Grand Challenge 5: The architecture of brain and mind
</B></H3>
<blockquote>
I was part of the small panel that proposed this as one of the UK
research grand challenges in November 2002. The panel was chaired at
first by Mike Denham, and then I took over from about May 2003 to
February 2005. See the
    <a href="http://www.cs.bham.ac.uk/research/cogaff/gc/">Overview of the grand challenge
and its history up to 2005.</a>
<P>
A shorter summary, written with help from others,
<a href="http://www.cs.bham.ac.uk/research/cogaff/gc/gc5-abstract-04-04.html">
is here
</a>, also included in the
UKCRC booklet on research grand challenges available on
their
<a href="http://www.ukcrc.org.uk/grand_challenges/index.cfm">'Grand Challenges' web page.</a>
<P>
<a href="http://www.cs.bham.ac.uk/research/cogaff/gc/aisb06">A symposium AISB 2006
</a> added to this.
</blockquote>
<P>
<a name="ontology"></a>
<HR>
<H3><B>
10. Incomplete work on an ontology for a simple (or not so simple)
agent (with links to
perception, learning, problem-solving and causation)
</B></H3>
<blockquote>
<b>Discussion notes, on various aspects of ontology, metaphysics, epistemology,</b>
<br/>
including links to epigenesis and nature-nurture
tradeoffs,
partly connected with the
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/">CoSy robotic project (2004-8),</a>
and the
<a href="http://www.cs.bham.ac.uk/research/projects/cogx/">
CogX robotic project (2008-12).</a>
<UL>
<LI>

    <a href="http://www.cs.bham.ac.uk/research/cogaff/misc/whats-ontology.txt">http://www.cs.bham.ac.uk/research/cogaff/misc/whats-ontology.txt</a>
<LI>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/misc/ontology-for-a-manipulator.txt">http://www.cs.bham.ac.uk/research/cogaff/misc/ontology-for-a-manipulator.txt</a>
<LI>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/misc/ontology.pdf">http://www.cs.bham.ac.uk/research/cogaff/misc/ontology.pdf</a>
</UL>
<p>
<b>Requirements for representations in a young robot (or animal)</b>
<br/>
Some of that work was subsumed in a document written
during August and September 2005, attempting to assemble
various ideas about this (with help from colleagues) into a
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0507">
(still draft) report on requirements for representations
</a>
for the CoSy project.
<P>
<a name="simtheory"></a>
<b>Vision and processes, simulations, possibilities</b>
<br/>
A (partly) new idea that came out
of that
work was
<a
href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0505">the
suggestion</a>
that perception, especially visual perception, is primarily
concerned with acquiring information about <i>processes</i>
(actually occurring and also possible processes in the environment)
and
involves constructing and constantly modifying a collection of
<I>simulations of parts the environment </I>
running in parallel at different levels of abstraction in registration
with sensory data when appropriate. (Of course this is quite closely
related to some old and familiar ideas, e.g. about perception as
construction, and Kenneth Craik's 1943 notion that animals build models
of the environment that they can run.)
<small>
<blockquote>
This is related to
R. Grush,
2004,
The emulation theory of representation: Motor control, imagery, and perception,
<i>Behavioral and Brain Sciences,</i> 27, pp. 377--442,
</blockquote>
</small>
It is not clear whether something
like the proposed multi-simulation perceptual system could possibly be
implemented using known mechanisms (subject to all the constraints and
requirements), but I am sure we still have not discovered all the
powerful mechanisms 'invented' by evolution. This idea can tie together
most of the strands of my work summarised here (though that may not be
obvious to all readers, as the idea still needs to be developed).
<p>
Those ideas were later developed in the paper on vision written
for a <a href="#compmod07"> conference on vision and neuroscience
</a>
in mid 2007:
Architectural and representational requirements for seeing processes
       and affordances. (Mentioned above.)
<P>
<a name="humeandkant"></a>
<b>
Two concepts of causation: Humean and Kantian
</b>
<br>
Closely related to the above is a contrast between Humean (basically
probabilistic) causation, and Kantian (basically deterministic and
structure-based) causation. I have recently been trying to show how that
distinction relates to both the simulation theory of perception
<a href="#simtheory">(suggestion mentioned above)</a>,
and to a view of (at least) two
very different kinds of learning about causation
(Two views of child as scientist: Humean and Kantian)
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0506">in infants,
children, and some animals (e.g. Crows).</a>
<p>
Unlike most people who argue over whether Hume or Kant (or one of their
successors) is right about what causation is, I claim that we need both
concepts and use both. A Humean (correlational, probabilistic) notion of
causation is the default when all we have is observations, but where
available the Kantian notion of causation (deterministic,
structure-based) gives deeper understanding and more general predictive
and explanatory competence. I think human infants use both, and grow
both as a result of their explorations of the environment, including
themselves.
<p>
Jackie Chappell and I were invited to start the proceedings at the
EU/NSF funded
<a href="http://www.cs.arizona.edu/projects/wonac/">International
Workshop on Natural and Artificial Cognition</a> held in Oxford
24-26 June 2007, by talking about
Kantian and Humean Causation and the Altricial/Precocial
distinction</a>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/wonac">
Kantian and Humean Causation and the Altricial/Precocial
distinction</a>
<p>
<a name="descriptive"></a>
<b>Descriptive metaphysics for babies -- natural and artificial
(16 Nov 2008)</b>
<br/>
In response to initiation of
<a href="http://www.cs.bham.ac.uk/research/projects/cogx/">the CogX project</a>
and ongoing discussions with Jackie Chappell and Susannah Thorpe (in
Biosciences) about cognition in birds and orangutans I started
making more explicit some ideas about the ontology needed by a
human-like baby robot and the ways the ontology could develop.
A first draft brain-dump, which will continue growing, was begun in
October 2008
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#babystuff">
Assembling bits of stuff and bits of process,
  in a baby robot's world
  A Kantian approach to robotics.</a>
This is closely related to the development of mathematical
understanding discussed <a href="#liverpool">above.</a>
<p>
It is also related to the discussion of
<a href="#topography">logical topography, below.</a>
</blockquote>

<P>
<a name="robotics"></a>
<HR>
<H3><B>
11. Robotics and the CoSy project
</B></H3>
<blockquote>
This
<a href="http://www.cognitivesystems.org">multi-site four year project,</a>
funded by the EC, started in Sept 1994 is
concerned with how to design and build a robot that has (or acquires)
the kind of mixture of competences that would be useful in a future
domestic robot, helping with household tasks of various kinds. The CoSy
project cannot achieve more than a tiny subset of that. The Birmingham
team led by
<a href="http://www.cs.bham.ac.uk/~jlw">Jeremy Wyatt</a>
and me are focusing on the competences involved
in manipulating 3-D structures using vision and a single robot arm.
Thinking in detail about the problems involved has proved
extraordinarily fertile and quite a lot of the work I have done since
2004 has been inspired by attempts to analyse the requirements for such
a robot, including discussions with CoSy collaborators, and
<a href="http://www.biosciences.bham.ac.uk/staff/staff.htm?ID=90">Jackie Chappell</a>
in the School of Biosciences.
<UL>
<LI>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/">http://www.cs.bham.ac.uk/research/projects/cosy/</a>
<LI>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/PlayMate-start.html">http://www.cs.bham.ac.uk/research/projects/cosy/PlayMate-start.html</a>
<P>
Some of the papers, technical reports and presentations are accessible
<a
href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/">here</a>.
<P>
An unplanned outcome of the CoSy project is development of a tool to
support collaborative development of requirements specifications using a
<a href="#matrix">matrix of types of requirements,</a>
some varying in content, some in degree
of sophistication (long term future, medium term, what to do next year,
etc.)
<P>
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/manip">A pre-cursor proposal</a>
</UL>

<P>
This project actually follows on from a succession of earlier failed
project proposals and some discussions with others about such a project.
I had been trying for several years to get funds for such a project from
UK sources, without success, then was able to benefit from the vision of
the people in the European Commission who set up the 'Cognitive Systems'
initiative that is funding CoSy.
<p>
A recent (Dec 2005-Jan 2006) example of the thinking inspired by work on
requirements for this robot can be found in these notes on
<a href="http://www.cs.bham.ac.uk/research/cogaff/misc/orthogonal-competences.html">'Orthogonal
competences'</a> which appears to be a (partly) new specification of
some of the requirements for learning in an intelligent human-like agent
coping with a complex and varied physical environment.

<p>
<a name="embodiment"></a>
<b>Issues concerning embodiment</b>
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0804">
Some Requirements for Human-like Robots:
<br/>
Why the recent emphasis on embodiment has held up progress
</a>
<p>
Invited paper for collection of papers reporting Honda conference on
robotics, Feb 2007. This position paper (not presented at the
conference, but invited afterwards for the book) takes Brooks' paper
"Elephants don't play chess" as a starting point for a critique of
so-called "Nouvelle AI" which emphases embodiment, interaction,
using the environment instead of representations, and treats
symbolic AI as either totally irrelevant or a small, relatively
unimportant, and easily achieved addition to a highly competent
embodied robot. The paper suggests that this ignores some of the
important factors driving biological evolution -- of humans and some
other species, admittedly a minority of species.
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/embodiment-issues.html">Computation
and Embodiment: Three issues, not two</a>
<br/>
A brief note on how many people misconstrue the main connection
between embodiment and cognition.
</blockquote>
</blockquote>
<P>
<a name="defragment"></a>
<HR>
<H3><B>
12. Ideas for de-fragmenting AI: at the IJCAI 2005 Tutorial and elsewhere
</B></H3>
<blockquote>
<b>The IJCAI 2005 Tutorial</b>
<br>
There's an online
    <a href="http://www.cs.bham.ac.uk/research/projects/cosy/conferences/edinburgh-05.html">tutorial overview</a>
including pointers to detailed schedule of tutorial, list of speakers
and abstracts and a booklet in which I wrote a longish introduction on
<I>AI in a new millennium</I> -- all online. The draft
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/conferences/ijcai-booklet/">tutorial booklet</a>
(to be revised after the conference) may be useful for some people who
were not able to attend the tutorial.
Some of my introduction to the tutorial has been extracted as a separate
paper
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0503">
 AI in a New Millennium: Obstacles & Opportunities
</a>
<P>
A sequel to this tutorial is
<a href="http://www.cs.bham.ac.uk/research/cogaff/gc/aisb06">the
two day symposium at AISB'06</a>
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0608">Abstract for How to Put the Pieces of AI Together Again</a>
presented at
AAAI'06 Members Poster Session, Boston July 2006.
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0603">Poster here.</a>
<p>
<b>Contributions to euCognition Research Roadmap project</b>
<br>
<a href="http://www.eucognition.org/wiki/index.php?title=Research_Roadmap">http://www.eucognition.org/wiki/index.php?title=Research_Roadmap</a>
including
<a
href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0701">an
invited presentation</a> in Jan 2007
<a href="http://www.eucognition.org/six_monthly_meeting_2.htm">at the first meeting</a>
at Munich airport.
<p>
<a name="metarequirements"></a>
<b>Meta-requirements, or 'ilities'</b>
<br>
Started a web site on meta-requirements of various sorts.
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0701">
A First Draft Analysis of some Meta-Requirements
       for Cognitive Systems in Robots</a> (started January 2007).
Contributions welcome.
<p>
<b>Controversies in Cognitive Systems Research</b>
<br>
Started a web site presenting
<a href="http://www.eucognition.org/wiki/index.php?title=Controversies_in_Cognitive_Systems_Research">
several controversies</a>, because many young researchers are nowadays
taught one side of a controversy without being given any indication that
it is controversial and that there is another side. Contributions to
this website are welcome.

</blockquote>
<P>
<HR>
<a name="freewill"></a>
<H3><B>
13. Free will
</B></H3>
<blockquote>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#8">How to dispose of the free will issue</a>
    (posted to a news group around 1989).
<P>
    Dennett developed similar ideas, but I think neither of us
    added very much to David Hume. Stan Franklin took my version and
    re-wrote it as a chapter of his book
<a href="http://www.msci.memphis.edu/~franklin/"><I>Artificial Minds</I></a>
    (with my permission.)
<p>

In response to some people who said they were unconvinced by the above
material I started to write a document (in May 2006) on
<a href="http://www.cs.bham.ac.uk/research/cogaff/misc/four-kinds-freewill.html">Four concepts of
freewill</a>.
<br>
Two of these concepts are useful, namely, the
ordinary every day notion of doing
something of your own free will as opposed to doing under duress, etc.
and the legal extensions of this to deal with decisions in court about
how to treat offenders. Both of these concepts can be used in a
deterministic world -- in fact they depend on the world being
deterministic. The other two concepts, which are alleged to be
incompatible with determinism are incoherent garbage: namely the
theological notion of freewill designed to let god off the hook, and the
romantic notion of freewill. This paper also includes a discussion of
counterfactual conditionals and causation and explains why in principle
a suitably designed robot could have as much freewill as you have.
<P>
An
<a href="http://www.cs.bham.ac.uk/research/cogaff/sloman-bogey.html">earlier paper</a>
entitled 'Physicalism and the Bogey of Determinism' was presented at an
interdisciplinary conference in 1971 and published in 1974. Although I
had not heard of Dennett at that stage I proposed what I think is a
superior version of the 'Intentional stance', namely that a piece of
physical behaviour <b>B</b> can constitute an intentional action
<b>A</b> only if <b>B</b> is <i>interpreted</i> as
<b>A</b> by the agent, which presupposes that the agent has an
appropriate architecture.
Expanding on this requires the design-stance. I have been elaborating on
requirements and designs for natural and artificial agents with that
sort of capability ever since.
Of course this may be unfair to some animals, e.g. insects, which many
people would say perform actions (e.g. feeding, landing on a flower,
mating) but lack the resources to interpret their behaviour as anything.
This only shows the need to use more subdivisions instead binary
oppositions.
</blockquote>
<P>
<a name="philsci"></a>
<HR>
<H3><B>
14. Contributions to philosophy of science
</B></H3>
<UL>
<LI>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap2.html">http://www.cs.bham.ac.uk/research/cogaff/crp/chap2.html</a>
    Chapter 2 of
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/">The Computer Revolution in Philosophy</a>
in which the various aims of science are separated out and the study of
the form of reality (the study of what is and is not possible) is
distinguished from the study of its actual content.
<LI>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/misc/cs-research.html">http://www.cs.bham.ac.uk/research/cogaff/misc/cs-research.html</a>
notes on the nature of research in AI and computer science.
<LI>
Investigation of the notions of virtual machine, information, and
information processing, and how this is related to the physical
sciences. E.g. see
<a href="http://www.cs.bham.ac.uk/research/cogaff/talks/#inf">this
presentation</a> and other talks and papers on supervenience.
<p>
And other things not online here, including an old paper in
<a href="http://mind.oxfordjournals.org/cgi/content/citation/LXXIII/289/84">Mind</a>
arguing that the then current dispute (involving A.N. Prior and others)
as to whether certain forms of reasoning used special rules of inference
or suppressed premisses was a bogus dispute. (This was made available
online
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/06.html#0606">here</a>
on 31 Dec 2006.)
</UL>
<P>
<HR>
<a name="philmath"></a>
<H3><B>
15. Contributions to philosophy of mathematics and philosophy of logic
</B></H3>
<a name="earlystuff"></a>
<b>D.Phil Thesis and early papers</b>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/sloman-1962">Oxford DPhil
thesis 1962</a>
<br/>Knowing and Understanding
<blockquote>
    Relations between meaning and truth, meaning and necessary truth,
    meaning and synthetic necessary truth
    <p>
    The quality of digitisation is poor because the library had only
    a carbon-copy to start with.
    <br/>
    Can anyone advise on getting OCR done with this?
</blockquote>
<br>
Attempting to defend Kant's claim that mathematical knowledge is
both synthetic and non-empirical.
<p>
<li>
1968 paper on
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#712">Explaining
Logical Necessity.</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/cogaff/04.html#200407">http://www.cs.bham.ac.uk/research/cogaff/04.html#200407</a>
(paper in IJCAI 1971, reprinted in AI journal and at least one book).
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap8.html">http://www.cs.bham.ac.uk/research/cogaff/crp/chap8.html</a>
chapter on learning about numbers, largely inspired by Benjamin, aged 5.
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap7.html">http://www.cs.bham.ac.uk/research/cogaff/crp/chap7.html</a>
slightly modified version of 1971 paper.
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/03.html#200304">http://www.cs.bham.ac.uk/research/cogaff/03.html#200304</a>
Tarski, Frege and the Liar Paradox'
     Originally in <I>Philosophy</I>, Vol XLVI, pages 133-147, 1971
<LI>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#rog">A 1963 paper on 'Functions and Rogators'</a>.
extending Frege's
concept of a function to "rogators", which are like
functions in that they take arguments and produce results, but are
unlike functions in that their results can depend on the state of
the world, in addition to which arguments they are applied to.
<br/>
This
was presented at a Logic Colloquium in Oxford in in 1963, and
published in 1965.
<br/>
It was scanned in and digitised in December 2007,
and put online
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#rog">here</a>.
<br/>
(This paper was described by David
Wiggins as 'neglected but valuable' in his
<a href="http://assets.cambridge.org/052145/4115/sample/0521454115ws.pdf">'Sameness and Substance Renewed'
(2001)</a>.
<li>
Some
parts of my
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#12">review of Penrose</a>
are also relevant here.
<p>
<li>
A chapter of 'The Computer Revolution in Philosophy' was about
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap8.html">Learning to count and understanding the concept of
number</a>.
<p>
</ul>
<a name="philmathbirm"></a>
<b>Philosophy of mathematics after coming to Birmingham</b>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#58">
Diagrams in the mind?
</a>
Originally an invited talk at Conference on Thinking With Diagrams,
1998, then in Springer book.
<p>
Our ability to think about transfinite ordinals is one of the things
to be explained. Why can't a 4 year old child understand them
whereas an older one can? I can teach most adults to think about
them in about five minutes. That tells us something about human
minds.
<p>
<a name="liverpool"></a>
<li>
<a href="liv.html">Added March 2008:
Could a child robot grow up to be a mathematician and
philosopher?</a>
<br>
An invitation to give a talk
on 21st January 2008, in the
<a href="http://www.liv.ac.uk/philosophy/mathsandscience/">
Thinking about Mathematics and Science</a> series at Liverpool
University gave me an opportunity to return to writing about
philosophy of mathematics and AI and the topic of
<a href="#diagrams">Diagrammatic Reasoning discussed above.</a>
<p>
The online slides, expanded after the talk, are
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#math-robot">here.</a>
The talk briefly summarises various philosophies of mathematics and
presents a (partial) defence of Kant's view that mathematical
knowledge is both non-empirical and synthetic, which can be opposed
to Hume's view of mathematicians (or a popular version of Hume's
view). The difference in views between Kant and Hume on the nature
of mathematics roughly parallels the difference in views expressed
by Richard Feynman and Bertrand Russell.
<p>
The slides start from Feynman's suggestion that mathematics is 'the
language nature speaks in', and presents a disorganised argument,
illustrated with examples, that requirements for a young animal or
robot to develop the ability to interact intelligently with a
complex and changing 3-D environment are closely related to the
requirements for doing mathematics, especially geometric and
topological reasoning about spatial structures and processes. But
there are still many unanswered questions about the design for such
a robot especially questions about how 3-D vision should work.
<p>
See also this presentation on vision at a Schloss Dagstuhl workshop
in Feb 2008:
<blockquote><small>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/dag08">http://www.cs.bham.ac.uk/research/projects/cogaff/dag08</a>
</small>
</blockquote>
<a name="kant-robots"></a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0802">
Added May 2008 Kantian Philosophy of Mathematics and Young Robots</a>

<blockquote>
In Proceedings
    <a href="http://events.cs.bham.ac.uk/cicm08/mkm08/">(MKM 2008)</a>
<br/> 7th International Conference on Mathematical Knowledge
Management
<br/>
    28-30 July 2008
<br/>
Slides for the presentation are here
<br/>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#mkm08">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#mkm08</a>
</blockquote>
<li>
(Added 4 Feb 2009):
<br/>
There is more about the nature of mathematics and mathematical
learning in
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0807">The
Well-Designed Young Mathematician
</a>
<br/>
In AI Journal December 2008. (Published as a
companion piece to McCarthy's paper on 'The Well-Designed Child')
</ul>
<a name="toddlers"></a>
<b>Work on 'Toddler theorems' and how biological competences feed
into mathematical competences.</b>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#toddler">
Added Dec 2008: Work on 'Toddler theorems' developing the above
ideas
</a>
<blockquote>
Expanding, with more examples, the notion that empirical things
learnt initially by play and experimentation, can later be
reconstrued as having some kind of necessity, e.g. mathematical
necessity. As a result of presenting the ideas in this talk at
Sussex and Birmingham I have begun to expand the varieties of types
of theory that a learner may have to use or develop, including the
notion of a (usually implicit) 'framework theory' which determines
what is perceivable, thinkable, doable, and also what sorts of
things can be thought of as existing in the environment.
<p>
However unlike the supposedly innate knowledge discussed by some
psychologists (e.g. Spelke) I don't claim that innate framework
theories are true or immutable. Instead they can be part of a
complete system that continually <i>tests itself</i> by interacting
with the environment and inevitably finds flaws and then <i>debugs
itself</i>. As far as I know this kind of bootstrapping has never
been modelled, though seeds of the idea can be found in Piaget.
<p>
As far as I can tell, most developmental psychologists have never
noticed the fact that a child can first discover something
empirically then learn that it is a necessary truth, e.g. that
a collection of 8 cubes cannot be made to form a square, whereas a
collection of 9 can (and hundreds more, some presented in the above
talk).
</blockquote>

<P>
Various other things, including
some of the talks
<a href="http://www.cs.bham.ac.uk/research/cogaff/talks/">here</a>
</UL>
<P>
<a name="antiai"></a>
<HR>
<H3><B>
16. Critiques of people attacking AI (Searle, Penrose)
</B></H3>

<blockquote>
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#12">The Emperor's Real Mind</a>
        1992 critique of Penrose
<I>
The Emperor's New Mind
</I>
<P>
<a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#70">Did Searle attack strong strong or weak strong AI?</a>
A critique of Searle's discussion of the Chinese room.
<P>
   (Originally appeared in A.G. Cohn and J.R. Thomas (eds)
<I>
Artificial Intelligence and Its Applications,
</I>
John Wiley and Sons 1986.
Proceedings AISB
Conference, Warwick University 1985)
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/clark-dennett-realisation.html">Short
discussion note expanding on what Clark and Dennett might have
meant by mind being 'realised' in matter.</a>
</blockquote>
<P>
<a name="irrelevance"></a>
<HR>
<H3><B>
17. Irrelevance of Turing machines to AI
</B></H3>

<blockquote>
<a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#77">The Irrelevance of Turing Machines to AI</a>
in
     <a href="http://www.nd.edu/~mscheutz/publications/scheutz02mitbook.html">Computationalism: New Directions,</a>
Ed Matthias Scheutz pages
87--127,
     Cambridge, MA, MIT Press, 2002.
<P>
The point is that all the most important features of computers that are
relevant to AI come from work on control systems for machinery going
back long before Turing, including the Jacquard loom, and, especially,
Babbage's recognition of the importance of machines that can obey
instructions to modify their own instructions, whose profound
implications were seen by Ada Lovelace about a century before Turing
machines were invented. This is not to belittle the work of Alan Turing,
or the importance of the concept of a Turing machine for theoretical
analysis of forms of computation. Unfortunately many critics of AI think
that if they know about Turing machines they know all there is to know
about computers and their relevance to the design and implementation of
intelligent machines.
<p>
This paper also attempts to explain how a finite physical machine (e.g.
a computer or brain) can implement an infinite virtual machine. It all
has to do with true sets of counterfactual conditionals.
</blockquote>

<P>
<a name="better"></a>
<HR>
<H3><B>
18. Contributions to meta-ethics: Work on the logic of 'better' and 'ought'
</B></H3>
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#88">"How to Derive 'Better' From 'Is'"</a>
in
<I>American Philosophical Quarterly</I>
         6, 1969
<P>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#703">"Transformations of Illocutionary
Acts"</a> in <I>Analysis</I> 30, 1969.
<P>
<a href="http://www.cs.bham.ac.uk/research/cogaff/05.html#ought-better">"'Ought' and 'Better'" in <I>Mind</I> Vol 79, 1970.</a>
<P>
These are contributions to what philosophers call
<a href="http://en.wikipedia.org/wiki/Meta-ethics">'meta-ethics'</a>, as
well as proposing what I believe was a new approach to a
subset of linguistic theory treating words like 'better' and 'ought' as
higher-order predicates some of whose arguments tend to be suppressed.
To see the context, look at Jimmy Lenman's very useful annotated
<a href="http://www.lenmanethicsbibliography.group.shef.ac.uk/Bib.htm">Bibliography of
Meta-ethics</a>
<P>
For many years I had thought that nobody had ever read my writings on
those topics, but that seems to be changing, as the 'Ought and better'
paper was discovered recently
<a href="http://semantics-online.org/blog/2005/09/sloman_papers_online">by researchers on semantics</a>
at MIT and nearly 20 years ago by
<a href="http://www.uwichill.edu.bb/bnccde/epb/ellhp.html">a researcher on ellipsis</a>
in the University of the West Indies, and now, four decades after publication,
various philosophers and linguists have started citing it (but not the more basic
paper on 'Better').
<p>
This work is also related to what I have started calling
<a href="#topography">the study of 'logical topography'</a>.
<P>
To help anyone else who might be interested I have recently put the
above papers online.
</blockquote>
<P>
<a name="involuntary"></a>
<HR>
<H3><B>
20. Why some mental states must be expressed involuntarily
</B></H3>
<blockquote>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#10">Prolegomena to a Theory of Communication and Affect</a>
   In Ortony, A., Slack, J., and Stock, O. (Eds.)
<I>
Communication from an Artificial Intelligence Perspective: Theoretical and Applied Issues.
</I>
Heidelberg,
Germany:
   Springer, 1992, pp 229-260.
<P>
The key idea is that if the only way individuals can find out about the
intentions of others is by asking them, or depending on their overt
statements about what they are going to do, then that will be
biologically very inefficient because of all the wasted effort required
to deal with cheats etc. Too many bets will need to be hedged. So if
intentions and other states of mind are displayed involuntarily, some
individuals will lose out but on balance everyone will win.
This still leaves it open for really good actors to become conmen, but
threats of severe punishments if detected can deter some of them.
</blockquote>

<P>
<a name="scenario">
</a>
<HR>
<H3><B>
21. Scenario based methodology for AI
</B></H3>
<blockquote>
Some work on scenario-based research, using partially ordered sets of
scenarios to define aims and requirements, and criteria for progress:
can be found here:
<a href="http://www.cs.bham.ac.uk/research/cogaff/gc/targets.html">http://www.cs.bham.ac.uk/research/cogaff/gc/targets.html</a>
and
here (templates for specifying collections of scenarios):
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/scenarios/">http://www.cs.bham.ac.uk/research/projects/cosy/scenarios/</a>
<P>
<a name="matrix"></a>
A recent (December 2005) extension is an online framework to support
development of
<a
href="http://www.cs.bham.ac.uk/research/projects/cosy/deliverables/matrix">
a matrix of requirements</a> for a variety of stages in research on
intelligent robots.
<p>

<a href="#metarequirements">
<b>See web-site on meta-requirements</b>
</a>
</blockquote>
<P>
<a name="whyId"></a>
<HR>
<P>
<H3><B>
22. Why 'intelligent design' theory should be taught to science
students.
</B></H3>
<blockquote>
<a href="id/">Not for the reasons its proponents think.</a>
<p>
Also explains why I became an atheist as a child and feel sorry
for people whose thinking powers have been corrupted by religion
and the associated
<a href="politician-manager-messages.html#footbinding">mind-binding.</a>
</blockquote>
<P>
<HR>
<a name="philwork"></a>
<h3><b>
23. How has the study of philosophy distinguished your work or point of
view?
</b></h3>
I was asked that question by Linda World:
<P>
<blockquote>
My reply was:
<blockquote>
Mainly it has made me far more careful about assuming we all mean the
same thing by common words, e.g. emotion, intelligence, reasoning,
representation, information, consciousness, spatial.
<P>
(I might have added that it has also made me careful about assuming that
I mean anything at all by an utterance simply on the basis that I think
I understand what I am saying: philosophy has shown that sincerely
uttered questions and assertions may be incoherent in ways their authors
have never thought of.)
<p>
I have just discovered the following in a message I posted
to psyche-d on
Sun, 3 Mar 1996,
<a
href="http://listserv.uh.edu/cgi-bin/wa?A2=ind9603&L=PSYCHE-D&P=R78&D=0&H=0&I=-3&O=T&T=0">
archived here.</a>
<small>
<blockquote>
<i>
It's a pity the human brain is not better equipped to tell when its
owner doesn't know what he/she is talking about. But that's just one
of many ways in which our self-monitoring capability is limited.
</i>
</blockquote>
</small>
<P>
Also I can see the deep continuity between many very old problems in
philosophy, e.g. about the nature of mind, about the nature of
knowledge, about what mathematical reasoning is, about
<a href="#freewill">free will,</a>
etc. and problems in AI.
<P>
As I wrote in my
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#42">
IJCAI-95 'Philosophical encounter' paper</a>
mis-quoting Santayana:
<P>
<blockquote>
"Those who are ignorant of
philosophy
 are doomed to reinvent it, often badly."
</blockquote>
</blockquote>
<p>
Many people who come up with theories in AI (or related
disciplines),
e.g. about emotions, about consciousness, about knowledge, about meaning
(e.g. symbol grounding theory) unwittingly re-invent a version of an old
philosophical theory that has already received a lot of discussion in
philosophical literature (possibly under a different name -- e.g.
'symbol-grounding theory' = 'concept empiricism'). Sometimes the
supposedly new theory has already been decisively refuted, and replaced
by more sophisticated theories.
<P>
<a name="otherphil"></a>
<b>
Other philosophical connections
</b>
<br>
<ul>
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/chap4.html">How to do conceptual analysis.</a>
<p>
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/00-02.html#57">Architecture-based concepts of mind</a>
<br>
(and the 'periodic table' of mental concepts).
<p>
<LI>
Cluster concepts -- and the muddles they cause (e.g. 'consciousness'
'emotion'). I have an unfinished paper on this written jointly with
Matthias Scheutz.
<p>
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#16">The structure of motivators (with Luc Beaudoin)</a>
<br>
Why there are somewhat more components to a motivator than you might
think.
<p>
<li>
<a href="http://www.cs.bham.ac.uk/~axs/ijcai01/">
The IJCAI 2001 tutorial
</a>
(with Matthias Scheutz) was on philosophical foundations of AI.
<p>
<li>
Work on  <a href="#consciousness">consciousness and virtual machines</a>
<p>
<li>
Work on <a href="#virtual">causation and virtual machines</a>
<p>
<li>
Philosophy of <a href="#philsci">science</a>
<p>
<li>
Philosophy of <a href="#philmath">mathematics</a>
<p>
<a name="topography"></a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/logical-geography.html">Two Notions Contrasted: 'Logical Geography' and 'Logical Topography'</a>
<br>Variations on a theme by Gilbert Ryle:
The logical topography of 'Logical Geography'.
<br>
Including analysis of some relations between 'ordinary language'
philosophy and science. Is conceptual analysis empirical? I suggest
that doing philosophy well involves doing a kind of abduction that
includes inventing new concepts as well as new explanatory theories
using those concepts. This is closely related to how science
advances.
<p>
<li>
<a href="http://www.cs.bham.ac.uk/research/cogaff/talks/sloman-ki2006.pdf">My slides for the symposium on 50 years of AI</a>
at the KI'2006 conference
in Bremen include several examples of the connections between AI and
philosophy, explaining why AI researchers and cognitive scientists who
don't know how to do conceptual analysis risk thinking they have
explained or modelled something when in fact they have at most dealt
with a few simple sub-cases.
</ul>
<p>
Many other portions of this web page are on philosophical connections.
</blockquote>
<P>
<a name="softeng"></a>
<hr />
<h3><b>
24. Implications of constraints on software engineering for government policies.
</b></h3>
<blockquote>
Triggered by news reports of
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/isoft/references.html">
the iSoft/NHS government fiasco
</a> I decided to write down an analysis of the problems of long term IT
project that I had been developing for some time. This led to the
conclusion that long term monolithic projects were doomed to fail
and should instead be replaced by more open ended exploratory projects
without any long term commitments at the beginning, with various
contractual and other constraints to help ensure that work paid for from
public funds is made generally available for public benefit, even if
the work failed to meet its specific objectives.
<p>
I made the analysis and my proposals available in August 2006 in
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/isoft-government-projects.html">
an open letter to my MP, Lynne Jones.
</a>
I soon received quite a lot of comment and appended the comments to the
open letter web site.
<p>
Maybe this could be described as a venture into political philosophy.
</blockquote>
<P>
<a name="spread"></a>
<HR>
<H3><B>
25. Generalising Spreadsheets to non-numerical data
</B></H3>
<blockquote>
I had forgotten that this was one of the things I once worked on until
today (5 Jan 2006) when I stumbled across
<a href="http://www.ainewsletter.com/newsletters/aix_0505.htm">
The May 2005 AI Newsletter
</a> Entitled
<i>
'The Spreadsheet issue, Jocelyn's Model Master, Scheme, ZigZag and
others, and Amzi!'s new ARulesXL'</i>, which includes a section referring to
something I did in 1983, and
which survives as a library within Poplog
(<a href="http://www.cs.bham.ac.uk/research/poplog/packages/current/teaching/help/vcalc">LIB
VCALC</a>). It has a section headed 'Spreadsheets in functional
languages' which starts:
<blockquote>
<small>
Older than Siag - dating from 1985 or so, it may be the first
spreadsheet to go beyond numerical calculations - is Aaron Sloman's
VCalc. Sloman wrote this in Pop-11, one of the languages making up the
Poplog system. Although written as an experiment, VCalc was used for
some serious tasks, such as allocating limited computing connections
between competing groups of users, subject to various constraints. One
feature was a constraint checker which could run arbitrary Poplog code -
for example, an expert system could be invoked!
<P>
VCalc is not grid-based, but uses declarations in a file read by
Poplog's Ved editor to indicate where cells are to be displayed. This is
excusable in a mid-1980s program running on cursor-addressable
terminals; with modern Poplog graphics, a much better version could be
written.
</small>
</blockquote>
Amazing how much I have forgotten. This reminded me of another tool
implemented in Ved,
<a href="http://www.cs.bham.ac.uk/research/poplog/help/cref">LIB
CREF</a>, also developed around 1983, to help in the extraction of rules
for expert systems on the basis of interview transcripts and other
textual data. It was partly inspired by a similar tool that was part of
the KEATS expert system shell developed at the Open University (in an
Alvey-funded project led by Marc Eisenstadt).
The help
file starts:
<blockquote>
<small>
CREF is an experimental VED-based document analyser/browser/cross-
referencer.
<P>
The assumption is that you have a file containing information that you
wish to analyse, for example a transcript of an interview, or a set of
notes for a book. You wish to re-organise the material in any one of a
variety of different forms, for instance:
<P>
1. A statistical summary of different kinds of texts.
<br>
2. A theory about the concepts, beliefs, and rules used by the person
interviewed
<br>
3. A new draft of the book, with the material re-organised more
logically.
<br>
<etc>
<P>
The CREF package does not automate any of this, but provides a tool to
help you in the process. It assumes the text is composed of fragments,
each of which is associated with a set of keys. Keys can either be
explicit artificial symbols that you have associated with the fragments
as a result of reading them and labelling them in various ways, or else
words or portions of words that occur in the original text. The former
we call explicit keys the latter implicit. (At present it doesn't handle
phrases sensibly, so you need to map significant phrases into labels
associated with fragments, then use the labels as explicit keys.)
<P>
CREF builds indexes mapping text fragments onto keys and keys onto
fragments.
<br> etc....

</small>
</blockquote>
I believe this CREF package was the original basis for the 'Ladder' tool
later developed by Nigel Shadbolt.
</blockquote>

<P>
<a name="othertopics"></a>
<HR>
<P>
<H3><B>
OTHER TOPICS TO ADD, WHEN I GET TIME.
</B></H3>
<UL>
<LI>
Around 1983 after selling Poplog myself for a year (and making quite a
lot of money for the University of Sussex) arranged for Systems
Designers Ltd (SDL) to take over marketing of Poplog to everyone but UK
Academics. Later SDL became SD, then SD-Scicon, later taken over by
<a href="http://www.eds.com">EDS</a>.
<LI>
Helping to launch <a href="http://www.cogapp.com">Cognitive Applications
Ltd</a> around 1986, when I was at Sussex University, originally
intended as an AI technology transfer company.
<LI>
Helping to launch Integral Solutions Ltd (ISL), a spinoff company from
SD founded by Alan Montgomery.
ISL's original mode of existence was selling and supporting
<a href="http://www.cs.bham.ac.uk/research/poplog/freepoplog.html">Poplog</a>,
which had been developed at Sussex university, mostly under my
management. Eventually ISL produced
other products and services including the
<a href="http://www.spss.com/clementine/">Clementine Data Mining system</a>
(implemented in Poplog) which was so successful that
<a href="http://www.spss.com">SPSS</a> bought ISL around 1989 in order
to get Clementine. Shortly after that, Poplog became available free and
open source, hosted in Birmingham.
<LI>
<a href="http://www.cs.bham.ac.uk/research/cogaff/81-95.html#10">
The distinction between intensity and insistence
</a>
<BR>
And why in humans emotions (later called tertiary emotions) are
connected with loss of control of attention. Also connected with our
<a href="#grief">analysis of grief in 1996</a>
<LI>
The concept of a 'norm field' (never written up)
<LI>
The uncertainty/abstraction tradeoff
<LI>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/matrix">Use of requirements matrix to guide research in AI</a>
<LI>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0507">Multi-strand relationships and multi-strand processes</a>
<br>
(also important for
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0505">my recent work on
vision.</a>)
</UL>


<P>
<a name="mytalks"></a>
<HR>
<P>
<H3><B>
Lots of slides (pdf mainly) prepared for talks in various places
</B></H3>
<blockquote>
Available
<a href="http://www.cs.bham.ac.uk/research/cogaff/talks/">here.</a>
<br/>
A reverse chronological list of presentations since about 2001 is
<a href="talks.html">here.</a>
<P>
The slides are mainly written so that they don't depend on me being
available to present them. So there is far more detail per slide than
normal.
<P>
More presentations are in the
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/">Birmingham
CoSy project web site.
</a>
</blockquote>
<P>
<a name="workmilitary"></a>
<HR>
<H3><B>
I do not work for 'the military'
</B></H3>
I once discovered
<a href="http://cogweb.ucla.edu/Abstracts/Sutherland_on_Fodor_00.html">a review</a>
by Keith Sutherland, which contained this strange bit of text:
<P>
<blockquote>
<small>
On the other hand computer science and artificial intelligence are
engineering disciplines -- 'AI was generally supposed to be about
engineering, not about
science; and certainly not about philosophy'. Although Marvin Minsky and
Aaron Sloman may like to think they are researching how the mind works,
their paymasters (mostly in the military) are more interested in
ensuring that the next generation of Cruise missiles hits Saddam's
bunker, rather than the hospital next door.
</small>
</blockquote>
I have never worked for 'the military'. I did for a while get some
unsolicited research funding from DERA (The UK Defence Evaluation and
Research Agency, which no longer exists). They learnt about my work when
two of my PhD students were interviewed for jobs (which they did not
accept). There was group of people who wished to develop expertise in AI
partly because they might be involved in advising the UK government on
tools for developing intelligent systems. I accepted their offer of
support because
<UL>
<LI>
They wanted to support work that I was doing anyway (namely development
of
<a href="http://www.cs.bham.ac.uk/research/poplog/packages/simagent.html">the
SimAgent Toolkit</a>, to help me and my students build models of
things we were interested in -- e.g. models of some human emotional
processes)
<LI>
They imposed no constraints on my freedom to publish and talk about the
work to anyone interested (and they published their work done with me
openly too).
<LI>
One of the reasons why they wanted to develop expertise was to be able
to advise the UK Ministry of Defence on purchase of software tools, on
which I thought there was a risk of large amounts of tax-payer's money
being spent on products available in the US for which totally
unrealistic promises were being made -- and I thought it would be good
to develop critical expertise to save our tax-payers' money.
</UL>
Most of my work is summarised
<a href="http://www.cs.bham.ac.uk/research/cogaff/talks/">
in these presentations
</a>
and
<a href="http://www.cs.bham.ac.uk/research/cogaff/">the CogAff
project</a>. It is almost all science and philosophy and not
engineering. (Not that I have anything against engineers). The leading
researchers in AI (e.g. Simon, McCarthy, Minsky, Newell, and Turing, for
instance) have always been at least as interested in the science as in
applications, and some (like me) more so.
<P>
I wrote to Keith Sutherland on 10th December 2005 after discovering his
implied claim
that I work for the Military, and he has now replied, saying:
<blockquote>
<em>
My unreserved apologies to Aaron Sloman for an unintended libel, caused
by a combination of sloppy journalism and the very tight word-limit of
THES reviews. What I meant to say was that, as an engineering
discipline, much of the research in artificial intelligence has been
financed by the military. I was quite wrong to personalise it in this
way and apologise without reservation.
<br>
--
<br>
Keith Sutherland
</em>
</blockquote>

<P>
<HR>
<H3><B>
I do not really juggle (except with ideas)
</B></H3>
<P>
<img alt="Aaron Juggling" width="500" src="fig/aaron-juggles.jpg">
<BR>
One sunny afternoon, in May 2005,
after
<a href="http://www.cs.bham.ac.uk/~rwd/">Richard Dearden</a> had given a
spectacular demonstration of juggling and other circus competences I
tried juggling with <I>one</I> cutlass, and
<a href="http://www.jonathans.me.uk/">Jonathan</a>
took a picture,
fortunately before I dropped it. I think it was still on its way up.
<P>
I manage flute a little better, and violin er, ... not very well.
<P>
If I ever have an epitaph (following cremation, if no
hospital wants my body for teaching/research) it should be
<blockquote>
<I>
'Sorry I'm late again'
</I>.
</blockquote>
<P>
<HR>
<P>
<small>
Maintained by
<a href="http://www.cs.bham.ac.uk/~axs">Aaron Sloman</a>
<br/>
Last updated: 10 Oct 2009; 19 Dec 2009; 3 Jan 2010; 21 Aug 2010; 8
Sep 2010; 3 Oct 2010; 15 Dec 2014
<br/>
Begun: June 2005
</small>
</div>
</body></html>
