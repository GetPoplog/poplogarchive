<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<HTML>
<HEAD>
<TITLE> SLOMAN - PRESENTATIONS</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<META name="description" content="Talks about AI, Cognitive Science,
Philosophy, Biology, Computing">
<META name="keywords" content="Philosophical foundations,
    Architectures for intelligent agents,
    Child as scientist,
    Computers and emotions, synthetic agents and emotions,
    Consciousness,
    Deep and shallow models,
    Digital Companions
    Emotions, moods, attitudes, affect,
    Evolution of Language,
    Evolution, Co-evolution,
    Evolvable architectures,
    Humean causation,
    Kantian causation,
    Language learning,
    Ontology,
    Ontology development,
    Philosophy of Artificial Intelligence,
    Philosophy of Cognitive Science,
    Philosophy of Computation,
    Philosophy of Computing,
    Philosophy of mind,
    Robotics,
    Robot carers,
    Symbol grounding,
    Symbol tethering,
    Theory tethering,
    Tools for Artificial Intelligence,
    Tools for exploring agent designs,
    causation,
    design space,
    diagrammatic representations,
    downward causation,
    machine consciousness,
    minds and matter,
    niche space,
    representations,
    research roadmap,
    spatial reasoning,
    supervenience,
    virtual machines,
    visual representations,
    Emergence">
</HEAD>
<BODY bgcolor="#ffffff" text="#000000" link="#000080" alink="#0000FF" vlink="#000080"
    style="margin-left:20px; margin-bottom:5px; width:750px"
>
<h3 align="center">
<a href="http://www.cs.bham.ac.uk/">
    <img alt="School of Computer Science"
    height="60" border="0"
    src="http://www.cs.bham.ac.uk/~axs/fig/cs2.png"
/>
</a>
<a href="http://www.bham.ac.uk/">
<img alt="THE UNIVERSITY OF BIRMINGHAM"
    height="60" border="0"
    src="http://www.cs.bham.ac.uk/~axs/fig/ub4.png"/>
</a>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/">
    <img alt="CoSy project"
    height="60" border="0"
    src="http://www.cs.bham.ac.uk/research/projects/cosy/images/coSylogo_web.jpg"/>
</a>
<a href="http://www.cs.bham.ac.uk/research/projects/cogx/">
    <img alt="CogX project"
    height="58" border="1"
    src="http://www.cs.bham.ac.uk/~axs/images/cogx.png"/>
</a>
<P>
<b>
PAST, RECENT AND PENDING PRESENTATIONS
<br>
<small>
By
<a href="http://www.cs.bham.ac.uk/~axs/">Aaron Sloman</a>
<br>
<a href="http://www.cs.bham.ac.uk/">School of Computer Science</a>
<br>
The University of Birmingham, UK.
</small>
</b></h3>
</b>
This is
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/</a>
<br>
Also accessible as:
<a href="http://goo.gl/piY2Lv">goo.gl/piY2Lv</a>
<p>
These are presentations on topics in philosophy of mind, philosophy of
mathematics, philosophy of computation, various aspects of AI, cognitive
science, and education, including work on the
<a href="http://www.cs.bham.ac.uk/research/cogaff/cogaff.html">Birmingham Cognition and Affect Project</a>
(1991--, begun previously at Sussex university), work done
in the
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/">Cosy
Project (2004-8)</a>,
and its successor the
<a href="http://cogx.eu/consortium/index.html">the CogX Project (2008-12)</a>,
including: consciousness, emotions and other affective
states and processes, reasoning, evolution (trajectories in design space
and niche space), information-processing, artificial intelligence,
cognitive science, biology, physics, philosophy of mind, supervenience,
philosophy of mathematics, epistemology, virtual machines,
implementation, vision and other forms of perception -- especially
visual perception of affordances, architectures for intelligent systems,
forms of representation, software tools for exploring architectures and
designing intelligent agents, and to some extent also about neuroscience
and psychology.
<P>
<a name="contentslist"></a>
<h3><b>
CONTENTS
</b></h3>
<blockquote>
Note added 25 Sep 2010: The main list is in roughly reverse chronology, but I
have started to build a list of pointers to talks on particular topics. This
will take some time, so some of the pointers are just stubs, for now.
<ul>
<p>
<li>
<a href="#reverse">
<b>
CONTENTS: ROUGHLY REVERSE CHRONOLOGY
</b>
</a>
<p>
<li>
<a href="#topics">
<b>
CONTENTS: MAJOR TOPICS (a sort of index, to be extended).
</b>
</a>
<P>
<b>Note</b> Some of these presentations are also on
<a href="http://www.slideshare.net/asloman/slideshows">'slideshare.net'</a>.
Unfortunately Slideshare no longer allows uploads to be updated. So many of my
presentations there are out of date. Look for newer versions here.
<p>
<b>WARNING:</b>
<br>
Any of my pdf slides found at any other location are likely to be out of date.
</ul>
<p>
There is more information organised by topic in my
<a href="http://www.cs.bham.ac.uk/~axs/my-doings.html">"DOINGS" list</a>
but it has not been updated for some time.
</blockquote>
<p>
<hr/>

<a name="topics"></a>
<h3><b>
CONTENTS: MAJOR TOPICS (a sort of index, to be extended).
</b></h3>
Some of these sub-headings will be revised.
<ul>
<li>
The (Turing-Inspired) Meta-Morphogenesis project, investigating evolved
information processing mechanisms (and the construction-kits they require)
began late 2011, but most of the presentations there are (messy) online web
pages
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html</a>
<li>
<a href="#talk115">
Talk 115: A short introduction to the Meta-configured Genome theory
</a>
<br>
One of the themes of the Meta-Morphogenesis project:
<li>
Proto-mathematics and the Philosophy of Mathematics
<li>
Virtual machines, supervenience, causation,
qualia, the evolution of consciousness
<li>
Architectures for cognition -- from microbes onwards
<li>
Symbol-grounding, concept empiricism, and theory-attachment
<li>
Ontologies, extending ontologies, altricial-precocial, kinds of stuff
<li>
Generalised languages GLs and the evolution of language
<li>
Mistakes about embodiment (how to think about its role in cognition)
<li>
What is science? The metaphysics of science
<li>
Causation: Humean, Kantian and why we need both
<li>
What is AI, and how does it relate to software engineering?
<li>
AI Tools
<li>
Affordances generalised: proto, vicarious, epistemic, etc. affordances
<li>
The importance of possibilities
<li>
Vision: primarily about motion and possibilities for motion.
<li>
Consciousness: muddles and clarifications
<li>
Information, life and mind: What's information?
<li>
The Meta-Morphogenesis project
<li>
Philosophy of various kinds: viewed from a designer standpoint
<li>
Emotions and muddles about them -- Cognition, Affect and Architectures
<li>
Meta-cognition, meta-management, and mathematical thinking.
<li>
How to think about requirements and roadmaps for AI and Robotics
<li>
Digital companions
<li>
Meaning and its varieties
<li>
Grand challenges: Architectures and Genomes for Architectures
<li>
Turing machines: and their irrelevance to AI
<li>
Designing a mind
<li>
Varieties of reasoning: using different forms of representation
<li>
Tutorials
<li>
Presentations to funding agencies and companies
</ul>

<p>
<hr/>
<a name="reverse"></a>
<h3><b>
CONTENTS: ROUGHLY REVERSE CHRONOLOGY
</b></h3>
<p>
Below is a summary list of presentations in (roughly) reverse
chronological order, followed by more details on each presentation,
in (roughly) chronological order. The summary has links to the
details.
<p>
The order is only "roughly" chronological since many of the older
talks have been revised recently, and some have also been presented
recently.
<p>
<b>WARNING:</b>
<br>
Any of my pdf slides found at any other location are likely to be out of date.
<br>
I try to keep the versions on slideshare.net up to date, but sometimes forget to
<br>
upload a new version.
<p>
<a href="http://scholar.google.co.uk/citations?sortby=pubdate&hl=en&user=lTc3UwsAAAAJ&view_op=list_works">Google Scholar
publications list</a>,
<br>
(N.B. DO NOT BELIEVE CITATION COUNTS. They can be inflated or incomplete.)
<ul>
<li>
<a href="#talk115">Talk 115: Pre-recorded Video Presentation at Tehran Conference</a>
<br>
April 2019
<br>
"How can a physical universe produce mathematical minds?
And why are they so hard to replicate in current AI systems?"
<p>
<li>
<a href="#talk114">
Talk 114: Short Guest talk at East Side Gallery, Nov 2018
</a>
<p>
<li>
<a href="http:#talk113">Talk 113: Video
Presentation at AGA workshop IJCAI August 2017</a>
<br>
Why can't (current) machines reason like Euclid
or even human toddlers?
<br>
(And many other intelligent animals)
<p>
<li>
<a href="#talk112">
Talk 112: Quarter-day Tutorial at IJCAI 2016 in New York
<br>
Tutorial T24: If Turing had lived longer, how might he
have investigated what AI and Philosophy can learn
from evolved information processing systems?
</a>

<p>
<li>
<a href="#talk111">
Talk 111: Two Related Themes
<br>
What are the functions of vision?
<br>
How did human language evolve?
<br>
(Languages are needed for internal information processing, including visual
processing)
</a>
<br>
Talk to AI students (MSc and ICY) 17 Mar 2015, Birmingham.
<br>
Also presented 7 Feb 2017
<p>
<li>
<a href="#talk110">
Talk 110 (poster):
<br>
What can we learn about animal cognition including biological vision, by
studying evolution of varieties of biological information processing?
<br>
At
First ViiHM Workshop on Biological and Machine Vision,
24-25 Sep 2014
</a>
<p>
<li>
<a href="#talk109">
Talk 109: ARTIFICIAL INTELLIGENCE AND PHILOSOPHY (Replaces talk13)
<br>
How AI (including robotics) relates to philosophy
and in some ways Improves on Philosophy
</a>
<br>
(Updated 5 Mar 2015)

<p>
<li>
<a href="#talk108">
Talk 108:
Why is it so hard to make
human-like AI (robot) mathematicians?
<br>
Especially Euclidean geometers.
</a>
<br>
Talk at PTAI 2013


<p>
<li>
<a href="#talk107">
(Three talks on the Meta-Morphogenesis project: Slides should be merged!)
<br>
Talk 107a: Tutorial on Meta-morphogenesis for AGI Conference, Dec 2012, Oxford
<br>
Talk 107b: Presentation at Dagstuhl  Seminar 10-15 Feb 2013
(Mechanisms Of Ongoing Development in Cognitive Robotics)
<br>
Talk 107c: Meta-Morphogenesis: How
could our minds and the rest of life have come from a cloud
 of dust?
<br>
At The Bath Royal Literary and Scientific Institution 2nd April 2013
</a>
<br>
(With links to related videos).
<p>
<li>
<a href="#talk106">
Talk 106: Thinking Architecturally
</a>
<br>
Talk at Architectural Thinking Workshop Cambridge 28-9 Nov 2012
<p>
<li>
<a href="#talk105">
Talk 105: What is computational thinking? Who needs it?
<br>
Why? How can it be learnt?
(Can it be taught?)
</a>
<br>
Talk at At Conference Manchester University 11 Sep 2012
<br>
With link to video of presentation (done without slides).
<br>
<b>Revised version added 5 Aug 2014</b>
<p>

<li>
<a href="#talk104">
Talk 104:
Biological, computational and robotic
connections with Kant's theory
of mathematical knowledge
</a>
<br>
Invited Talk at ECAI 2012 Turing and Anniversary session, August
2012
<p>
<li>
<a href="#talk103">
Talk 103:
 Meta-morphogenesis and the Creativity of Evolution
<br>
<small>
 Mechanisms for bootstrapping biological minds
</small>
</a>
<br>
Talk at
ECAI 2012 Workshop
 on Computational Creativity, Concept
 Invention, and General Intelligence
<br>
Montpellier, 27th August 2012
<p>
<li>
<a href="#talk102">
Talk 102:
Meta-Morphogenesis: of virtual machinery with "physically indefinable" functions
</a>
<br>
<small>
Overlaps with
<a href="#talk101"> Talk 101.</a>
</small>
<br>
VERSION of presentation for Workshop "The Incomputable": June 2012.
<p>
<li>
<a href="#talk101">
Talk 101:
Meta-Morphogenesis: Evolution of mechanisms for producing minds
<br>
OR
<br>
Evolution, development and learning, producing new mechanisms
of evolution, development and learning.
<br>
</a>
<br>
Talk at  Cambridge University Computing and Technology Society
<a href="http://www.cucats.org">www.cucats.org</a> Tues 8th May 2012.
<p>
<li>
<a href="#talk100">
Talk 100: Architectures for more or less intelligent life
<br>
<small>
How to turn philosophers of mind into engineers
-- to help them solve old philosophical problems
</small>
</a>
<br>
Talk for Philosophy of Cognitive Science Students, Birmingham Feb 2012.
<p>
<li> <a href="#talk99">
Talk 99:
The Meta-Morphogenesis project - An introductory overview
<br>
Two talks in Birmingham October 2011 (and elsewhere later)
<p>
<li> <a href="#talk98">
Talk 98:
The deep, barely noticed, consequences of embodiment.
<br>
(Ignored by most embodiment theorists)
<br>
Invited talk for PT-AI Conference, Thessaloniki, 3 & 4 October 2011
Philosophy and Theory of Artificial Intelligence
<p>
<li>
<a href="#talk97">
Talk 97:
How to combine science and engineering to solve philosophical
 problems
</a>
<br>
Talk at:
"Barcelona Cognition, Brain and Technology summer school - BCBT"
<a href="http://bcbt.upf.edu/bcbt11">http://bcbt.upf.edu/bcbt11</a>
September 7, 2011
<p>
<li>
<a href="#talk96">
Talk 96: Philosophy as AI and AI as philosophy (needs expansion)
<br>
(Tutorial at AAAI11 8 Aug 2011 )
</a>
<p>
<li>
<a href="#talk95">
Talk 95:
Evolution of mind as a feat of computer systems engineering
<br> Lessons from decades of development of virtual machinery,
including self-monitoring virtual machinery.
<br>
Varieties of Self-Awareness and Their Uses
in Natural and Artificial Systems
</a>
<br>
<small>
Invited talk at SPS Workshop on Philosophy of Artificial Intelligence,
Nancy 19th July 2011.
</small>
<p>

<li>
<a href="#talk94">
Talk 94:
Varieties of Self-Awareness and Their Uses
in Natural and Artificial Systems
<br>
Metacognition and natural cognition
<br>
Towards a conceptual framework</a>
<br>
<small>
Talk at EPICS workshop Birmingham June 2011.
</small>
<p>
<li>
<a href="#talk93">
Talk 93: What's vision for, and how does it work?
<br>
From Marr (and earlier)
<br>
to Gibson and Beyond
<br>
(With some potted, rearranged, history)
<br>
<small>
Presented at Birmingham Vision Club, and Sheffield psychology dept.
(June 2011).
</small>
<p>
<li>
<a href="#talk93a">
Talk 93a: What's vision for?
<br>
Modified version of talk 93.
<br>
(Lecture for Birmingham UG students. 31 Jan 2012).
<p>
<li>
<a href="#talk92">
Talk 92:
Computing: The Science of Nearly Everything. Including Biology!
</a>
<br>
<small>
Talk for CAS "TeachShare" presentation, 8 Jun 2011
</small>
<p>
<li>
<a href="#talk91">
Talk 91: LIFE and INFORMATION
<br>
Self-modifying information-processing architectures
</a>
<br>
<small>
Talk for 2nd Year CS students, Birmingham, 28 Jan 2011
</small>
<p>
<li>
<a href="#talk90">
Talk 90a: Piaget (and collaborators) on Possibility and Necessity
<br>
And the relevance of/to AI/Robotics/mathematics (in biological evolution
and development)
<br>
<small>
Presented 21 Feb 2011, Birmingham, 28th March Dagstuhl, 6th April Oxford.
</small>
<br>
Talk 90b: Modified version Dagstuhl March 28th 2011, Oxford April 5th 2011.
</a>
<p>
<li>
<a href="#talk89">
Talk 89: Genomes for self-constructing, self-modifying
information-processing architectures
</a>
<br>
<small>
Slides for invited talk at SGAI 2010
<a href="http://www.cs.bham.ac.uk/~jlw/cognitive-robotics-workshop.html">Workshop on Bio-inspired and Bio-Plausible Cognitive Robotics</a>
</small>
<p>
<li>
<a href="#talk88">
Talk 88: A Multi-picture Challenge for Theories of Vision
<br>
<small>
Including a sketch of a specification for dynamical systems required.
</small>
</a>
<p>
<li>
<a href="#talk87">
Talk 87: What does AI have to do with Biology?</a>
<br>
<small>
Talk for first year Introduction to AI students Nov 2010
<br>
School of Computer Science, University of Birmingham
</small>
<p>
<li>
<a href="#talk86">
Talk 86: Supervenience and Causation in Virtual Machinery
<br>
Revised 8 May 2014
</a>
<br>
<small>
Ongoing work: attempts to explain what running virtual machines are, in terms of
kinds of dynamical system whose behaviours and competences are not best
described in terms of physics and chemistry, even though they have to be fully
implemented in physical mechanisms in order to exist and operate. This is an
incomplete attempt to explain, in more detail than my earlier papers, how
"sideways causation" and "downward causation" can both occur in running virtual
machines, i.e. non-physical things causally influencing one another and also
influencing physical events and processes, with special reference to
requirements for biological virtual machines running on animal brains.
<br>
Current computer based virtual machines embedded in complex systems interacting
with each other and with complex external environments provide "proofs of
possibility", but still lack some of the required detail. I still don't have
either questions or answers clear and deep enough for my own satisfaction.
I don't think anyone else has either! (Comment expanded: 20 Sep 2015)
</small>
<p>
<li>
<a href="#talk85">
Talk 85: Daniel Dennett on Virtual Machines
</a>
<br>
20 Sept 2010; Revised 29 Nov 2010; 5 Dec 2010 (Ongoing)
<p>
<li>
<a href="#talk84">
Talk 84:
Using virtual machinery to bridge the "explanatory gap"
<br>
<small>
Or:
Helping Darwin: How to Think About Evolution of Consciousness
<br>
Or: How could evolution (or anything else) get ghosts into machines?
</small>
</a>
<br>
Invited Talk at SAB2010 France, 28th August 2010
<br>
Also presented (shortened form) 10th
Sept at Conference on "Nature and
Human Nature" (Consciousness and Experiential
Psychology) Oxford.
<p>
<li>
<a href="#talk83">
Talk 83 Routes from Genome to Architecture (provisional title)
<br>
<small>
(PDF presentation on how to do research in this area in preparation)
</small>
</a>
<p>
<li>
<a href="#talk82">
Talk 82:
Steps Towards a 21st Century University:
<br>
Planting Seeds ...
for a unified science
of information
</a>
<br>
Talk at Research Awayday, 21st July 2010.
<p>
<li>
<a href="#talk81">
Talk 81:
The Design-Based Approach
to the Study of Mind
<br>
(in humans, other animals, and machines)
<br>
Including the Study of Behaviour
involving Mental Processes
</a>
<br>
Talk at AIIB'2010.
<p>
<li>
<a href="#talk80">
Talk 80:
Helping Darwin:
<br>
How to Think About
Evolution of Consciousness
</a>
<br>
Presented at BioSciences Seminar, UoB, 11th May 2010
<p>
<li>
<a href="#talk79">
Talk 79:
If learning maths requires a
teacher, where did the first
teachers come from?
<br>
Why (and how) did biological evolution
produce mathematicians?
</a>
<br>
Presented at Symposium on Mathematical Practice and Cognition 2010
<p>
<li>
<a href="#talk78">
Talk 78:
Computing: The Science of Nearly Everything.
</a>
<br>
<small>
Presented at:
<a href="http://www.computingatschool.org.uk/">Computing At School (CAS)</a>
meeting, Microsoft Research, Cambridge, Apr 2010, then revised for
the CAS conference in Birmingham 9th July 2010.
</small>
<p>
<li>
<a href="#talk77">
Talk 77:
How to do
AI-inspired biology, as a change from biology-inspired AI.
<br>
<small>
Some thoughts about the past and future of AI as science and
philosophy
<br>
For
Workshop on AI Heritage, MIT, June 11-12, 2009
</small>
</a>
<p>
<li>
<a href="#talk76">
Talk 76:
Title
The history, nature,
and significance
of virtual machinery
</a>
<p>
<li>
<a href="#talk75">
Talk 75: Dagstuhl 2009 talk on proto-affordances:
<br>
Possibilities between form and function
<br>
Or between shape and affordances.
</a>
<p>
<li>
<a href="#talk74a">
Talk 74a: For Workshop: Inside and Outside of Computers and Minds
<br>
 Why robots interacting intelligently with a complex 3-D environment
will need qualia and how they can have them.
</a>
<p>
<li>
<a href="#talk74">
Talk 74: Why the "hard" problem of consciousness is easy
and the "easy" problem hard.
<br>
And how to make progress.
</a>
<p>
<li>
<a href="#talk73">
Talk 73: Virtual Machines and the Metaphysics of Science
</a>
<br>
Presented at:
    <a href="http://www.bristol.ac.uk/metaphysicsofscience/MoS_09/MoS_09_Programme.htm">Metaphysics of
Science'09</a>)
<p>
<li>
<a href="#talk72">
Talk 72:
Some thoughts and demos, on ways of using
computing for deep education on many topics.
</a>
<br>
<small>
As a change from teaching:
<ul>
<li>
 "useful" skills (of various kinds),
<li>
 uses of computing,
<li>
 computer science
<li>
 computer/software engineering.
</ul>
</small>
<p>
<li>
<a href="#cogsci09">
Talk 71: What Cognitive Scientists Need to Know about Virtual Machines.
<br>
Presentation
at the
CogSci'2009 Conference
</a>
<p>
<li>
<a href="#maggiefest">
Talk 70: What Has Life Got To Do With Mind? Or vice versa?
</a> (PDF)
<br>
(Thoughts inspired by discussions with Margaret Boden.)
<br>
Presented at a seminar on Margaret Boden's work, Sussex University, 22 May,
2009. Includes some reminiscences about Cognitive Science/AI at Sussex
University from 1965, and a discussion of whether mind requires life, or life
requires mind (defined as information processing, or informed control).
<p>
<li>
<a href="#talk69">
Talk 69: Future Human-Like Robots: Requirements vs. Designs
</a>
<br>
<small>
Understand problems before you try to solve them
(using iterated implementation if necessary).
</small>
<small>
Invited talk at
<a href="http://ec.europa.eu/information_society/events/cf/item-display.cfm?id=2176">Session on 'The Ultimate Robot'</a>
FET'09, Prague, April 2009.
</small>
<p>
<li>
<a href="#talk68">
Talk 68: Ontologies for baby animals and robots
</a>
<br>
<small>
From "baby stuff" to
the world of adult science:
Developmental AI from a Kantian viewpoint.
</small>
<br>
Presented at
Workshop on Matching and Meaning, AISB'09 Edinburgh 9th April 2009.
<br>
and  at
Pattern Recognition and Computer Vision Colloquium, Prague 23rd April 2009
<br>
Revised version presented at Brown University Cognitive Science
department 10 Jun 2009
<p>
<li>
<a href="#talk67">
Talk 67: Why (and how) did biological evolution produce mathematicians?
<br>
or
<br>
If learning mathematics requires a teacher, where did
the first teachers come from?
<br>
or
<br>
Talk 67: A New Approach to Philosophy of Mathematics:
<br>
Design a young explorer, able to
discover "toddler theorems"
</a>
<br>
<small>
Invited talk at University of Sussex, Tuesday 9th December 2008.
<br>
Also presented at a joint meeting of the Language and Cognition Seminar and the
Vision Club, School of Psychology Univ of Birmingham, Friday 12th December 2008,
and at a CISA seminar, Informatics Edinburgh Wed 8th April 2009,
Computer Science, York University, May 2009.
</small>
<p>
<li>
<a href="#talk66">
Talk 66: Virtual Machines in Philosophy, Engineering & Biology (at WPE 2008)
</a>

<p>
<li>
<a href="#babystuff">
Talk 65: Assembling bits of stuff and bits of process,
<br>
in a baby robot's world
<br>
<small>
A Kantian approach to robotics.
</small>
</a>
<br>
(Intended for CogX Kick-off workshop)
<p>
<li>
<a href="#talk64">
Talk 64: Why virtual machines really matter -- for several disciplines
<br>
(Or, Why philosophers need to be robot designers)
</a>
<br>
Talk at School of Computer Science (open) Seminar 16 Oct 2008, and
<br>
<a href="http://thegreatdebate.org.uk/UnnoticedConnections.html">Newcastle 'Great Debate'</a>
21st Oct 2008
and
<br>
<a href="http://www.conted.ox.ac.uk/courses/details.php?id=O08P107PHR">Mind as
Machine, Continuing Education Weekend
Course</a> Oxford 1-2 Nov 2008
<p>
A revised, extended version of parts of previous presentations on
virtual machines, information, and architectures.
<p>
<li>
<a href="#talk63">
Talk 63: Kantian Philosophy of Mathematics and Young Robots
<br>
Could a baby robot grow up to be
a Mathematician and Philosopher?
</a>
<br>
Talk at <a href="http://www.sis.uncc.edu/~anraja/Metareasoning/">Workshop on
                MetaReasoning: Thinking about Thinking</a>
<br>
at
7th International Conference on Mathematical Knowledge Management
Birmingham, UK, 28-30 July 2008
<br>
<a href="http://events.cs.bham.ac.uk/cicm08/mkm08/">http://events.cs.bham.ac.uk/cicm08/mkm08/</a>
<br>
University of Birmingham, 29 Jul 2008
<p>
<li>
<a href="#talk62">
Talk 62: Varieties of Meta-cognition in Natural and Artificial Systems
<br>
<small>
Some pressures on design-space
from niche-space
</small>
</a>
<br>
Talk at <a href="http://www.sis.uncc.edu/~anraja/Metareasoning/">Workshop on
                MetaReasoning: Thinking about Thinking</a>
<br>
at <a href="http://www.aaai.org/Conferences/AAAI/aaai08.php">AAAI'08,</a>
<br>
Washington, 13-14 July 2008.
<p>
<li>
<a href="#talk61">
Talk 61: Evolution, development and modelling of architectures for intelligent organisms and robots.
</a>
<br>
(For Graduate School Seminar series,
Biosciences, on 24th June 2008).
<p>
<li>
<a href="#talk60">
Talk 60: Requirements for a Human-like Information Processing Architecture that Builds Itself
by Interacting with a Rich Environment
</a>
<br>
given at
<a href="http://events.cs.bham.ac.uk/cci-env08/">Birmingham
Informatics CRN Workshop on Complexity and Critical Infrastructures
- Environment focus.
</a>
<br>
Modified version of talk given at UIUC Complexity conference.
<p>
<li>
<a href="#talk59">
Talk 59: Understanding the Functions of Animal Vision -- What Are We Trying To Do:
<br>
How Do Logic And Probability
Fit Into The Bigger Picture?
</a>
<br>
Invited talk at:
<blockquote>
<a href="http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=08091">Dagstuhl Seminar No. 08091, 24.02.2008-29.02.2008</a>
<br>
Logic and Probability for Scene Interpretation.
Schloss
<br>
Dagstuhl, Feb 25th 2008
</blockquote>
<p>
<li>
<a href="#talk58">
Talk 58: What designers of artificial companions need to understand about biological ones
</a>
<br>
Invited Presentation at
<a href="http://www.aisb.org.uk/convention/aisb08/invited.html#pubLect">Public Session of AISB'08,</a>
3rd April 2008, Aberdeen
<p>
<li>
<a href="#talk57">
Talk 57: Seeing Possibilities: A new view of Empty Space
</a>
<br>
Presentation at Intelligent Robotics Lab Seminar, Birmingham, 22nd
Jan 2008
<p>
<li>
<a href="#talk56">
Talk 56: Could a Child Robot Grow Up To be A Mathematician And Philosopher?
</a>
<br>
Invited talk at
Thinking about Mathematics and Science Seminar, University of
Liverpool. 21st Jan 2008
<p>
<li>
<a href="#talk55">
Talk 55: Why Some Machines May Need Qualia and How They Can Have Them: Including a Demanding New Turing Test for Robot Philosophers
</a>
<br>
Invited talk at
Symposium on Machine Consciousness at AAAI Fall Symposium,
Washington, 9-11 November 2007
<p>
<li>
<a href="#devrep">
Talk 54: Diversity of Developmental Trajectories in Natural and Artificial Intelligence
</a>
<br>
Invited talk at
Symposium on
<a href="http://yertle.isi.edu/~clayton/aaai-fss07/">
Computational Approaches to Representation Change
During Learning and Development
</a> at AAAI Fall Symposium, Washington November 2007
<p>
<li>
<a href="#talk53">
Talk 53: Requirements for Digital Companions and their implications: It's harder than you think
</a>
<br>
Position Paper for workshop on Digital Companions at Oxford Internet
Institute
<p>
<li>
<a href="#talk52">
Talk 52: Evolution of minds and languages. <br> What evolved first and develops first in children:
 Languages for communicating, or
 languages for thinking (Generalised Languages: GLs)
</a>
(Partly superseded by <a href="#talk111">Talk 111</a>)
<br>
For Birmingham Language and Cognition seminar, 19 Oct 2007
<br>
And
<a href="http://www.conted.ox.ac.uk/courses/details.php?id=O08P107PHR">Mind as
Machine, Continuing Education Weekend
Course</a> Rewley House, Oxford 1-2 Nov 2008
<p>
<li>
<a href="#talk51">
Talk 51: Why robot designers need to be philosophers -- and vice versa
<br>
Presentation at University of Bielefeld on 10th October
2007
(PDF)</a>
<p>

<li>
<a href="#talk50">
Talk 50: Understanding causation in robots, animals and children: Hume's way and Kant's way.
</a>
<br>
<small>
(Includes some methodological background and biological
conjectures.)
</small>
<br>
Presentation at CoSy MeetingOfMinds Workshop, Paris, Sept 2007
<p>
<li>
<a href="#models">
Talk 49: Why symbol-grounding is both impossible and unnecessary,
    and why theory-tethering is more powerful anyway.
</a>
<br>
Alternative title:
<br>
Introduction to key ideas of semantic models, implicit definitions and symbol tethering
<br>
Revised and clarified version of the portion of
<a href="#talk14">Talk 14</a> that dealt with model-based semantics.
</a>
<p>
<li>
<a href="#enf07">
Talk 48: Machines in the ghost
</a>
<br>
Invited talk at
<a href="http://www.indin2007.org/enf/">ENF'2007</a>
Vienna July 2007
<p>
<li>
<a href="#wonac07">
Talk 47: Causal competences in animals and machines,
(with Jackie Chappell),
</a>
<br>
Invited talks by Jackie Chappell and Aaron Sloman at
The NSF/EU-funded Workshop on Natural and Artificial Cognition,
Pembroke College, Oxford, 24th-26th June 2007
<br>
<a href="http://www2.cs.arizona.edu/projects/wonac/">http://www2.cs.arizona.edu/projects/wonac/</a>
<p>
<li>
<a href="#compmod07">
Talk 46: Architectural and representational requirements for seeing processes and affordances.
</a>
<br>
Invited talk at
<a href="http://comp-psych.bham.ac.uk/workshop.htm"> BBSRC funded Workshop</a>
<br>
Closing the gap between neurophysiology and behaviour:
A computational modelling approach,
University of Birmingham, United Kingdom,
May 31st-June 2nd 2007
<p>
<li>
<a href="#pac07">
Talk 45 (Poster): Consciousness in a Multi-layered
Multi-functional Labyrinthine Mind
</a>
<br>
Poster presentation at
<a href="http://www.bris.ac.uk/philosophy/department/events/PAC_conference/index.html/Conference.htm">PAC-07 Conference, 1-3 July 2007, Bristol.</a>
<p>
<li>
<a href="#cospal07">
Talk 44: Some requirements for human-like visual systems, including seeing processes,
structures, possibilities, affordances, causation and impossible objects.
</a>
<br>
Invited talk at
<a href="http://www.cospal.org/Workshop.htm">COSPAL Workshop,</a>
Aalborg, June 2007
<p>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0702">
Talk 43: COSY-PR-0702: What is human language? How might it have evolved?</a>
<br>
<small>
Aaron Sloman
<br>
Slides for a seminar presented in Birmingham on 5th Mar 2007
</small>
<p>
<li>
<a href="#talk42">
Talk 42: COSY-PR-0701: What's a Research Roadmap For? Why do we need one? How can we produce one? (PDF)
</a>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0701">Old location</a>
<br>
Aaron Sloman
<br>
This is a much expanded version of a presentation at the euCognition
Research Roadmap discussion in Munich on 12 Jan 2007.
<br>For more on the
Research Roadmap project see:
<br>
<a href="http://www.eucognition.org/wiki/index.php?title=Research_Roadmap">http://www.eucognition.org/wiki/index.php?title=Research_Roadmap</a>

<p>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0604">
Talk 41: COSY-PR-0604: Evolution of ontology-extension:
<br>How to explain internal and external behaviour in organisms,
including processes that develop new behaviours. (PDF)
</a>
<br>
Aaron Sloman, with much help from Jackie Chappell
<br>
In collaboration with members of the EU CoSy Robotic Project
<br>
Presented to combined Biosciences and AINC seminar, University of
Birmingham, 9th Oct 2006, and in Edinburgh 7th Dec 2006.
<P>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0603">
Talk 40 (Poster):
COSY-PR-0603: Putting the Pieces of AI Together Again
(PDF)
</a>
<br>
Poster for Member's Poster Session: AAAI'06, Boston, July 2006.
<p>
<li>
<a href="#talk39">
Talk 39 (Poster): COSY-PR-0602: How an animal or robot with 3-D manipulation skills
experiences the world
(PDF)
</a>
<br>
Poster for ASSC10, Oxford June 2006.
<p>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0601">
Talk 38 (Poster): COSY-PR-0601: Acquiring Orthogonal Recombinable Competences
(PDF)
</a>
<br>
Poster for COGSYS II Conference, Nijmegen, April 2006
<p>
<li>
<a href="#ki2006">
Talk 37: FUNDAMENTAL QUESTIONS - THE SECOND DECADE OF AI
</a>
<br>
Towards Architectures for Human-like Machines.
<br>
Expanded version of invited presentation at
the Symposium on 50 years of AI
<br>
KI2006 Conference Bremen, 17th June 2006
<P>
<li>
<a href="#talk36">
Talk 36: TWO VIEWS OF CHILD AS SCIENTIST: HUMEAN AND KANTIAN
</a>
<br>
Presentation to Language and Cognition Seminar,
School of Psychology, U. of Birmingham. October 14th 2005
<br>
See also <a href="#wonac">the WONAC presentations (Chappell and
Sloman), below.</a>
<P>
<li>
<a href="#talk35">Talk 35 (Also COSY-PR-0505): A (POSSIBLY?) NEW THEORY OF VISION
</a>
<br>
Combining several old theories
<br>
Generating many new problems and research tasks.
<br>
Talk given in various places, October 2005.
<P>
<li>
<a href="#bled-04">
Talk 34: Tutorial on integration at EC Cognitive Systems 'Kickoff' Conference,
</a>
<br>
(Bled, Slovenia, 28-30 October 2004)
<br>
Aaron Sloman
<P>
<li>
<a href="#ijcai-05">
Talk 33: THE ALTRICIAL-PRECOCIAL SPECTRUM FOR ROBOTS
</a>
<br>
Talk at IJCAI-05 5th Aug 2005 (Chappell and Sloman)
<P>
<li>
<a href="#rse-05">
Talk 32: ROYAL SOCIETY OF EDINBURGH MEETING: Artificial Intelligence In your Life Today
</a>
<br>
Talk at RSE 5th Aug 2005
<P>
<li>
<a href="#humarch">
Talk 31: Architectures for Human-Like Machines
</a>
<br>
Talk at Goldsmiths 19th Jan 2005
<P>
<li>
<a href="#meanings">
Talk 30: VARIETIES OF MEANING
</a>
<br> Talk to language and cognition seminar 5th Nov 2004
<P>
<a name="gc"></a>
<li>
<a href="http://www.cs.bham.ac.uk/research/cogaff/gc#gcoverview">
Talk 29: UKCRC Grand Challenge 5: 'Architecture of Brain and Mind'
</a>
<br> Overview presentation at Grand Challenges Conference April 2004
(Also at Edinburgh University in November 2004).

<P>
<li>
<a href="#emotions">
Talk 28: Do Intelligent Machines, Natural Or Artificial, Really Need Emotions?
</a>
<br> Talk to Cafe Scientifique & Culturel Birmingham, 7th May 2004
(and Various other places since then).
<br>
Revised: 14 Jan 2014

<P>
<li>
<a href="#vis">
Talk 27: REQUIREMENTS FOR VISUAL/SPATIAL REASONING
</a>
<br> Talk to language and cognition seminar, Birmingham, Oct 2003
</a>

<P>
<li>
<a href="#inf">
Talk 26: What are information-processing machines?
</a>
<br>What are information-processing <i>virtual</i> machines?
<br> Notes from a workshop on models of consciousness, Sept 2003, and a
presentation in York, Feb 2004. Updated for Bham talk 16 Oct 2008

<P>

<li>
<a href="#talk25">
25: Architecture-based philosophy of mind (Invited talk at ASSC7)
</a>
<br>
Memphis June 2003.
<br>
What kind of virtual machine is capable of human consciousness?
(Revised from ECAP03 for ASSC7.)
<P>

<li>
<a href="#talk24">
Talk 24: Varieties of Affect and Learning In A Complete Human-Like
Architecture
</a>
<br>
Stanford, April 2003
<P>

<li>
<a href="#talk23">
23: Architecture-based philosophy of mind (ECAP-03)
<br>
What kind of virtual machine is capable of human consciousness?
</a>
(For ECAP03). See also Talk 25.
<br>
Glasgow, March 2003 (Superseded by talk 25)
<P>

<li>
<a href="#talk22">
22: THE IRRELEVANCE OF TURING MACHINES TO ARTIFICIAL INTELLIGENCE
</a>
<br>
Various places: March, April, 2003.
<P>

<li>
<a href="#talk21">
21: HUMAN VISION --- A MULTI-LAYERED MULTI-FUNCTIONAL SYSTEM
</a>
<br>
A talk on aspects of human and animal vision,
presented at a BMVA symposium January 2003.
<P>

<li>
<a href="#talk20">
20: WHEN WILL REAL ROBOTS BE AS CLEVER
 AS THE ONES IN THE MOVIES?
</a>
<br>
A talk on how to get human-like intelligence into robots.
Presented at ASE 2003, and at DAMTP Cambridge.
<P>

<li>
<a href="#talk19">
19: TOWARDS HUMAN-MACHINE SYMMETRY
</a>
<br>
A talk on how to get more intelligence into user interfaces, thereby
reducing the asymmetry between humans and machines.
<br>
For
second year AI and CS students at Birmingham. December 2002
2002.
<P>

<li>
<a href="#talk18">
Talk 18: What is Science? (Can There Be A Science Of Mind?)
</a>
<br>
Presented at the meeting to launch <I>Cafe Scientifique</I> in
Birmingham, MAC, 25th October 2002.
<P>

<li>
<a href="#talk17">
Talk 17: AI AND THE STUDY OF MIND (Early British AI)
</a>
<br>
Presented at
<a href="http://www.aiai.ed.ac.uk/events/ccs2002/">CCS symposium</a>
The Science Museum, London 11th October 2002.
<P>

<li>
<a href="#talk16">
Talk 16: MORE THINGS THAN ARE DREAMT OF IN YOUR BIOLOGY:
Information processing
in biologically-inspired robots.
</a>
<br>
Presented at
<a href="http://www.ecs.soton.ac.uk/~rid/wgw02/home.html">EPSRC/BBSRC International Workshop</a>
on
Biologically-Inspired Robotics:
The Legacy of W. Grey Walter
14-16 August 2002, HP Bristol Labs, UK
<P>

<li>
<a href="#talk15">
Talk 15: Can We Design A Mind?
</a>
<br>
Keynote talk presented at
<a href="http://www.arch.usyd.EDU.AU/kcdc/conferences/aid02">AID02
AI in Design Conference,</a>
Cambridge, 15th July 2002.
<P>

<li>
<a href="#talk14">
Talk 14: Getting Meaning Off The Ground: Symbol Grounding Vs Symbol
Attachment/Tethering
</a>
<br>
NOTE: following a suggestion from Jackie Chappell, I now use the phrase
'symbol tethering' instead of 'symbol attachment'.
<br>
A critique of concept empiricism including its modern descendant, symbol
grounding theory. Talk presented at MIT Friday 15th March 2002.
<P>

<li>
<a href="#aiandphil">
13: ARTIFICIAL INTELLIGENCE AND PHILOSOPHY (Out of date. See Talk 109)
</a>
<br>
A talk on AI and philosophy, and how AI can improve on philosophy
(and vice versa) for first year AI students at Birmingham.
<P>

<li>
<a href="#talk12">
12: SUPERVENIENCE AND IMPLEMENTATION
</a>
<br>
Presented at University of Birmingham in 2000, at
University of Nottingham, Nov 2001, revised Oct 2003.
<P>

<li>
<a href="#talk11">
11: ARTIFICIAL INTELLIGENCE DEVELOPMENT ENVIRONMENTS
</a>
<br>
A talk on AI languages and tools and why they are special, for
AI students at Birmingham.
<P>

<li>
<a href="#talk10">
10: WHAT IS ARTIFICIAL INTELLIGENCE?
</a>
<br>
Talk for applicants for AI undergraduate degrees at University of Birmingham.
<P>

<li>
<a href="#talk9">
9: VARIETIES OF CONSCIOUSNESS
</a>
<br>
Talk at Oxford Consciousness Society, 24th Oct 2001 and
CS/AI School seminar, Birmingham, on 8th Nov 2001.
<P>

<li>
<a href="#talk8">
Talk 8: Evolvable, Biologically Plausible Visual Architectures
</a>
<br>
Talk at British Machine Vision Conference (BMVC01), Sept 2001
<br>
And a more recent version.
<P>

<li>
<a href="#talk7">
7: WHEN IS SEEING (POSSIBLY IN YOUR MIND'S EYE) BETTER THAN
DEDUCING, FOR REASONING?
</a>
<br>
Presented at CS & AI Theory seminar, Birmingham, Sept 2001
<br>
Also at BCS/SGAI meeting City University London, March 2006
<P>

<li>
<a href="#talk6">
Talk 6: Architectures For Human-Like Agents,
</a>
<br>
Invited talk at Nokia Research Centre Helsinki, June 2001.
<br>
(Revised August 2006)
<P>

<li>
<a href="#talk5">
5: TUTORIAL ON
<b>
Philosophical foundations: Some key questions
</b>
</a>
<br>
Presented With Matthias Scheutz at IJCAI01 Seattle 5th Aug 2001
<P>
<li>
<a href="#free">
Talk 4a: Debate on 'This house believes that robots will have free will'
</a>
Edinburgh 2001
<p>

<li>
<a href="#talk4">
Talk 4: How To Understand Natural Minds Of Many Kinds.
</a>
<br>
BBSRC/EPSRC workshop on
Adaptive and interactive behaviour of animals and computational systems
(AIBACS)
<br>
Abingdon, March 2001.
<P>

<li>
<a href="#talk3">
Talk 3: Varieties of Affect and the CogAff Architecture Schema
</a>
<br>
At AISB2001, York, March 2001, revised for UCL talk June 2002.
<P>

<li>
<a href="#simagent">
2: SIMAGENT: TOOLS FOR DESIGNING MINDS
<br>A toolkit for philosophers and engineers.
</a>
<br>
Talk presented at seminars in Oxford, Birmingham, IRST (Trento),
Newcastle, York.
<P>

<li>
<a href="#talk1">
Talk 1: Varieties Of Evolvable Minds
</a>
<br>
or
<br>
How to think about architectures for human-like
and other agents
<br>
or
<br>
How to Turn Philosophers of Mind
into Engineers
<br>
Oxford (McDonnell-Pew Centre for Cognitive Neuroscience) 23 Jan 2001,
Windsor, Feb 2001, and elsewhere.
<P>

<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/96-99.html#31">
TALK 1998: What Sorts of Machines Can Love? Architectural Requirements for
Human-like Agents</a>
<br>
Slides for invited talk at the Royal Festival Hall on 21 Feb 1998
<br>
Part of a series of talks in the South
Bank Centre's Literature Programme.
<p>

<li>
<a href="#others">
OTHER COLLECTIONS OF SLIDES IN PREPARATION.
</a>
<ul>
<li>
<a href="#ibm02">
<b>
Slides for IBM Symposium March 2002:
<br>
Architectures and the spaces they inhabit
</b>
</a>
<p>
<li>
<a href="#darpa02">
<b>
Presentation at DARPA Cognitive Systems Workshop Nov 2002
<br>
How to Think About Cognitive Systems: Requirements and Designs
</b>
</a>
</ul>
<p>
<li>
<a href="#notes">
NOTES and related references.
</a>

<li>
<a href="#viewers">
DOWNLOADABLE VIEWERS
</a>
<br>
<P>

<li>
<a href="#ack">
ACKNOWLEDGEMENT
</a>
</UL>
<P>
<hr>
<P>
<a name=viewers"> </a>
<h3><b>USE OF LATEX AND TGIF PACKAGE</b></h3>
The diagrams in the slides were almost all produced using the small,
fast, versatile, portable, reliable, and free <b>tgif</b> package, available for linux
and unix systems from here:
<blockquote>
<a href="http://bourbon.cs.umd.edu:8001/tgif/">http://bourbon.cs.umd.edu:8001/tgif/</a>
</blockquote>

<P>
My slides are mostly composed in Latex, using home-grown macros, importing eps
or jpg files produced by tgif. More recent versions were created directly by
pdflatex.
<P>
From about talk 5 (May 2001) I started preparing the slides in a format
more suited to fill a typical computer screen which is wider than it is
tall. These need to be viewed in "Landscape" or "Seascape" mode (rotated
90 degrees to the left). Your pdf/postscript viewer
should provide such an option, if the wide display format is not used
automatically. Paper size is set to A4, which may cause problems printing some
of the slides on US letter paper.
<p>
Some documents (including documents in the 'Misc' directory,
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/</a>,
are produced using html, for online viewing, with pdf produced using a
combination of <i>html2ps</i> and <i>ps2pdf</i>.
<hr>
<h3><b>
SUMMARY LIST OF TALKS,
<br>
with more details later
</b></h3>
<p>
<a name="talk116"></a>
<h3><b>
Talk 116: A short introduction to the Meta-configured Genome theory
</b></h3>
See the second video in this playlist:
<br>
<a href="https://www.youtube.com/playlist?list=PLYC-dSilAaYa6Mk1g6hBGUyqCwrIvyOWB">https://www.youtube.com/playlist?list=PLYC-dSilAaYa6Mk1g6hBGUyqCwrIvyOWB</a>
<br>
The idea is explained in this document (under revision October 2019)
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-configured-genome.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-configured-genome.html</a>
<br>
The Meta-Configured Genome
<br>
(Multi-layered, multi-stage, parametrised, epigenesis)
<p>
<a name="talk115"></a>
<h3><b>
Talk 115: Pre-recorded Video Presentation at Tehran Conference
<br>
April 2019</a>
</b></h3>
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sharif-talk.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sharif-talk.html</a>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sharif-talk.pdf">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sharif-talk.pdf</a>
<br>
Invited talk on
<i>Artificial and Natural Intelligence Nature and Philosophical Debates</i>
<br>
Especially:
"How can a physical universe produce mathematical minds?
And why are they so hard to replicate in current AI systems?"
<br>
Includes link to recorded presentation and online notes on the presentation.
<br>
For Sharif University Spring School on AI Philosophy, Ethics, and Society
<br>
<a href="http://www.en.sharif.edu/">http://www.en.sharif.edu/</a>
<hr>
<p>
<a name="talk114"></a>
<h3><b>
Talk 114: Short Guest talk at East Side Gallery, Nov 2018
</b></h3>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sloman-eastside-2018.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sloman-eastside-2018.html</a>
<br>
Toddler space scientists:
<br>
Empty space includes billions of potential curved paths through which a wasp or
a ball could move. Mathematicians have studied space for centuries, but it is
also partially understood by many animals that see things in space, move through
space, and manipulate things, including nest-building birds, animals that hunt
for, peel, or tear open their food and pre-verbal human toddlers.
<br>
Note 1: Despite appearances in many impressive demos, current AI systems and
robots do not share this deep spatial understanding, as pointed out in the talk.
<br>
Note 2: "billions" is an understatement!
<hr>
<p>
<a name="talk113"></a>
<h3><b>
Talk 113: Video Presentation at AGA workshop IJCAI August 2017</a>
</b></h3>
This was an invited talk (presented remotely using a video recording) with
associated web page expanding on various aspects of the video. Available at
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/ijcai-2017-cog.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/ijcai-2017-cog.html</a>
(Also PDF)
<br>
Why can't (current) machines reason like Euclid
or even human toddlers?
<br>
(And many other intelligent animals)
<br>
The web page is still under development!
<hr/>
<a name="talk112"></a>
<h3><b>
Talk 112: IJCAI 2016 TUTORIAL
</b></h3>

This quarter-day presentation at IJCAI 2016 in New York used a web page rather
than slides:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sloman-tut-ijcai-2016.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sloman-tut-ijcai-2016.html</a>
<blockquote>
<b>
International Joint Conference on AI 2016 10th July 2016
<br>
Tutorial T24: If Turing had lived longer, how might he
<br>
have investigated what AI and Philosophy can learn
<br>
from evolved information processing systems?
</b>
<p>
 Including homage to John McCarthy and Marvin Minsky,
two of the founders of AI, recently deceased,
both interested in connections between AI and philosophy.
<br>
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sloman-tut-ijcai-2016.html#contents">Talk
Contents List</a>
</blockquote>

<hr/>
<a name="talk111"></a>
<h3><b>
Talk 111: Two Related Themes (intertwined).
<br>
What are the functions of vision?
<br>
How did human language evolve?
<br>
(Languages are needed for internal information processing,
<br>
including visual processing)
</a>
</b></h3>

<b>
<a href="ai-icy-vision-language.pdf">Available HERE (PDF).</a>
<br>
&nbsp;&nbsp;&nbsp;&nbsp; (Updated 22 Jul 2019)
<br>
Also on slideshare in flash format -- but out of date. Unfortunately Slideshare
no longer allows uploads to be updated. The version above is newer than the
slideshare version.
</b>
<br>
<a href="http://www.slideshare.net/asloman/evolution-of-46383806">http://www.slideshare.net/asloman/evolution-of-46383806</a>
<div style="margin-left:15px; margin-top:0px; margin-bottom:10px;">
(Guest lectures for MSc conversion students and intercalated year students.
2015)
<br>
<a href="http://www.cs.bham.ac.uk/">(School of Computer Science, University of Birmingham)</a>
<br>
<b>
Video recording of presentation in 2015
</b>
<div style="margin-left:5px; margin-top:0px; margin-bottom:0px;">
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/#ailect2-2015">http://www.cs.bham.ac.uk/research/projects/cogaff/movies/#ailect2-2015</a>
(<b>158MB</b>)
<br>
Kindly recorded and made available by Khalid Khattak (a student on the course).
<br>
(added 1 Apr 2015).
<br>
This was the second of two lectures. Slides for the first are <a href="#talk109">here.</a>
</div>
<b>
Audio recording of presentation in 2017
</b>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/audio/ai-msc-icy-lecture-feb-2017.ogg">(Audio with pauses while typing)</a>
</div>
The ideas presented here contradict most theories of evolution of language,
including the delightful theory by Danny Hillis that songs evolved first and
were then later transformed, endorsed by the distinguished physicist Freeman
Dyson in this 2014 lecture (at around 31Mins:29Secs):
<br>
<a href="https://www.youtube.com/watch?v=JLT6omWrvIw">https://www.youtube.com/watch?v=JLT6omWrvIw</a>
<p>
<b>Installed:</b> 28 Mar 2015
<br>
<b>Updated:</b> 15 Apr 2015; 11 Nov 2015; 7 Feb 2017
<p>
<b>Abstract</b>
<div style="margin-left:15px; margin-top:10px; margin-bottom:10px;">
This presentation combines major themes from two previous talks:
<div style="margin-left:15px; margin-top:10px; margin-bottom:10px;">
<a href="#talk52"><b>Talk 52:</b> Evolution of minds and languages.</a>
<p>
<a href="#talk93">
<b>Talk 93:</b> What's vision for, and how does it work?
</a>
<br>
From Marr (and earlier) to Gibson and Beyond
</div>

<font color="blue">
If human languages had to be learnt by users, human languages could not have
evolved. Instead they are not learnt, but <b>created</b> -- collaboratively.
</font>
<p>
Most people think language is essentially concerned with communication between
individuals. So they ask the wrong questions about evolution of language, and
give limited answers - concerned only with forms of communication.
<br>
A different view of language opens up more questions, requiring more
complex and varied answers:
<br>
A language is primarily a means by which information can be
represented, for any purpose, including internal purposes such as
learning, reasoning, formation of intentions and control of actions.
That includes perceptual information, e.g. visual information.
Instead of asking: how did communication using language evolve?
We can ask:
<p>
<b>o</b> <font color="blue">For what purposes do organisms use information?</font>
<br>
Learning about the environment (e.g. through visual perception), control of
actions, selection of goals,
formation of plans, execution of plans, making predictions, asking questions,
finding answers,
communication with other individuals, social teaching and learning....(add your
own ideas).

<div style="margin-left:15px; margin-top:0px; margin-bottom:0px;">
- What types of information do organisms need to acquire and use?
<br>
- In what forms (languages) can the information usefully be represented?
<br>
- What mechanisms are required for acquisition, storage and use of information?
<br>
- A special case: How did languages also come to be used for communication?
</div>
<p>
<h3><b>
Key ideas
</b></h3>
Animals need "internal languages" (internal representations/encodings of
information) for purposes that are not normally thought of as linguistic.
<br>
E.g. perceiving, experiencing, having desires, forming questions, forming
intentions,
working out what to do, initiating and controlling actions, learning things
about the
environment (including other agents), remembering, imagining, theorising,
designing .....
<br>
Without the use of richly structured internal languages, human vision, thought,
learning,
planning would be impossible. There would be nothing to communicate.
<br>
There would be no need for communicative languages if individuals had
nothing to communicate, and had no internal means of storing and using
information communicated or acquired by perception or learning.
<br>
So, having one or more internal languages is a prerequisite for using an
external language.(Sloman, 1978b, 1979)
<br>
Internal languages (forms of representation) must therefore have evolved
first, and must develop first in individuals: later both can develop in
parallel.
<br>
This requires a "generalised" notion of a language: a GL.
<br>
Internal GLs and external languages (ELs) require forms of representation that
are
manipulable, with

<div style="margin-left:15px; margin-top:0px; margin-bottom:0px;">
- structural variability,
<br>
- varying complexity (e.g. for information about objects/events of varying complexity),
<br>
- compositional semantics (allowing new meanings to be assembled from simpler
ones
</div>
There is a very compressed summary of theories of vision, especially in AI and
in Gibson's work (and Marr, in passing).
</div>
<p>
There are also connections with the examples of "toddler theorems"
in the presentation on evolution and development of mathematical capabilities
<a href="#toddler">below</a>, and with ideas on learning and development in the
work of Piaget and Karmiloff-Smith included in:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html</a>
<br>
<p>
<hr/>
<a name="talk110"></a>
<h3><b> Talk 110 (poster):
<br>
What can we learn about animal cognition
including biological vision, by studying evolution of varieties of biological
information processing?
<br>
<a href="viihm-stratford-sloman.pdf">Available HERE (PDF)</a>
<br> (Subject to change: please keep links rather than copies.)
</b>
</h3>
<b>Presented at:</b>
<br>
First ViiHM Workshop on Biological and Machine Vision
24th and 25th September 2014, Stratford upon Avon
<br>
<b>Draft abstract</b>
<br>
<blockquote>
Vision, Action and Mathematics From Affordances to Euclid.
<br>
Part of the Turing-inspired Meta-Morphogenesis project.
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html</a>
<br>
(What I suspect Alan Turing might have done if he had lived longer.)
<br>
Based on my 4th contribution to this book (pp 849-857):
<br>
<a href="http://www.cs.bham.ac.uk/~axs/amtbook">http://www.cs.bham.ac.uk/~axs/amtbook</a>
<p>
Compare <a href="#talk93">Talk 93</a>:
<br>
What's vision for, and how does it work?
From Marr (and earlier)
to Gibson and Beyond
</blockquote>
<b>Installed here:</b> 25 Sep 2014

<hr/>
<a name="talk109"></a>
<h3><b> Talk 109: ARTIFICIAL INTELLIGENCE AND PHILOSOPHY
<br>
(Updated 5 Mar 2015)
<br>
<small>
(Replaces Talk 13)
</small>
<br>
How AI (including robotics) relates to philosophy
and in some ways Improves on Philosophy
<br>
<a href="csai-phil-sloman.pdf">Available HERE (PDF).
</a>
<br> (Subject to change: please keep links not copies.)
<br>
Much older version on
<a href="http://www.slideshare.net/asloman/ai-and-phil-presentation">slideshare</a>.
</b>
</h3>
<b>Presented at:</b>
<blockquote>
Lecture1 for ICY and conversion MSc students 5 Mar 2015
<br>
Video recording of presentation
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/#ailect-2015">here</a>
<br>
Lecture 2 (17 March 2015) is <a href="#talk111">here.</a>
<p>
CNCR Journal Club Meeting on Monday 7th October 2013
</blockquote>
<b>Installed here:</b> 25 Nov 2013; Updated 5 Mar 2015

<p>
<b>Partial Abstract</b>
<blockquote>
Presents some of the differences and relationships between philosophy, science,
and engineering, illustrated in particular by the use of AI in enriching and
testing philosophical concepts and theories.
</blockquote>
<p>

<hr/>
<a name="talk108"></a>
<h3><b> Talk 108: Why is it so hard to make human-like
AI (robot) mathematicians?
<br>
 Especially Euclidean geometers. </a>
<br>
<a href="ptai13-sloman.pdf">DRAFT Available HERE (PDF).
</a>
<br> (To be revised.)
</b>
</h3>
<b>Presented at:</b>
<blockquote>
<a href="http://www.pt-ai.org/2013">http://www.pt-ai.org/2013</a>
<br>
Philosophy and Theory of Artificial Intelligence
<br>
21 Sep 2013
</blockquote>
<b>Installed:</b> DRAFT PDF will be installed 21 or 22 Sep 2013
<br>
(To be revised later.)

<p>
<b>Abstract</b> (As originally submitted).

<blockquote>
I originally got involved in AI many years ago, not to build new useful machines, nor
to build working models to test theories in psychology or neuroscience, but with the
aim of addressing philosophical disagreements between Hume and Kant about
mathematical knowledge, in particular Kant's claim that mathematical knowledge is
both non-empirical (apriori, but not innate) and non-trivial (synthetic, not
analytic) and also concerns necessary (non-contingent) truths.
<p>
I thought a "baby robot" with innate but extendable competences could explore and
learn about its environment in a manner similar to many animals, and learn the sorts
of things that might have led ancient humans to discover Euclidean geometry.
<p>
The details of the mechanisms and how they relate to claims by Hume, Kant, and other
philosophers of mathematics, could help us expand the space of philosophical theories
in a deep new way.
<p>
Decades later, despite staggering advances in automated theorem proving concerned
with logic, algebra, arithmetic, properties of computer programs, and other topics,
computers still lack human abilities to think geometrically, despite advances in
graphical systems used in game engines and scientific and engineering simulations.
(What those do can't be done by human brains.)
<p>
I'll offer a diagnosis of the problem and suggest a way to make progress,
illuminating some unobvious achievements of biological evolution.
</blockquote>
<p>
<hr/>
<a name="agitut"></a>
<a name="talk107"></a>
<a name="talk107a"></a>
<h3><b>
Three closely related talks on Meta-Morphogenesis:
<ul>
<li>
Talk 107a (AGI): Tutorial on Meta-morphogenesis for AGI Conference, Dec 2012, Oxford</b>
<br>
<a href="agi-tutorial-sloman.pdf">Available HERE (PDF).</a> (Still undergoing major
revision -- later all three files will be merged.)
<p>
<li>
<a name="m-m"></a>
<a name="talk107b"></a>
Talk 107b (Dagstuhl):
Meta-Morphogenesis theory as background to Cognitive Robotics and Developmental Cognitive Science
<br>
<a href="dag13-sloman.pdf">Available HERE (PDF)</a> [Slightly updated 4 Apr
2016]
<br>
Also at <a
href="http://www.slideshare.net/asloman/dag13-sloman">http://www.slideshare.net/asloman/dag13-sloman
(FLASH)</a>
<br>
How could our minds and the rest of life have come from a cloud of dust?
<br>
Presentation at Dagstuhl  Seminar 10-15 Feb 2013:
<a href="http://www.dagstuhl.de/13072">(Mechanisms Of Ongoing Development in Cognitive Robotics)</a>
<p>
<a name="talk107c"></a>
<li>
Talk 107c (BRLSI): Meta-Morphogenesis: How
could our minds and the rest of life have come from a cloud of dust?
<br>
<a href="dag13-sloman.pdf">Same slides as for talk 107b (PDF)</a>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/bath-brlsi-talk.html">Presented at The Bath Royal Literary and Scientific Institution</a>
<br>
Tuesday 2nd April 2013
</ul>
</b></h3>
Expanded and reorganised versions of slides originally prepared for a tutorial
presentation at the 2013 conference on AGI at St Anne's College Oxford.
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html#videos">Video of tutorial</a>
<br>
Video recording of the tutorial, made by Adam Ford:
<br>
<a href="http://www.youtube.com/watch?v=BNul52kFI74">http://www.youtube.com/watch?v=BNul52kFI74</a>
<br>
- - - (about 2 hrs 30 mins -- audio problem fixed on 14 June 2013):
<br>
Medium resolution version also available on the CogAff web site:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies#m-m-tut">http://www.cs.bham.ac.uk/research/projects/cogaff/movies#m-m-tut</a>
<p>
Adam Ford also made available two related interviews recorded at the conference:
<ul>
<li>
Margaret Boden interview:
<br>
<a href="http://www.youtube.com/watch?v=5dEXIOiAsaw">http://www.youtube.com/watch?v=5dEXIOiAsaw</a>
<li>
Aaron Sloman interview:
<br>
<a href="http://www.youtube.com/watch?v=iuH8dC7Snno">http://www.youtube.com/watch?v=iuH8dC7Snno</a>
<br>
Also available as a small HD .mp4 video
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies">here.</a>
<br>
Transcript available at
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/transcript-interview.html">http://www.cs.bham.ac.uk/research/projects/cogaff/movies/transcript-interview.html</a>
</small>

<p>
Please do not save or send anyone copies - instead keep a link
to this location and send that if necessary:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#talk107">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#talk107</a>
<p>
The PDF files grew too long and may later be split into smaller pieces.
<p>
For more on the Meta-Morphogenesis project see:
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/agi-2012-tut-sloman.html">Abstract for the tutorial</a>
<small>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html</a>
<br>
OR <a href="http://goo.gl/9eN8Ks">http://goo.gl/9eN8Ks</a> (Main project web
site.)
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/beyond-modularity.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/beyond-modularity.html</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/evolution-info-transitions.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/evolution-info-transitions.html</a>
</ul>
</small>

<p>
<hr/>
<a name="archthink"></a>
<a name="talk106"></a>
<h3><b>
<b>Talk 106: Thinking Architecturally</b>
<br>
Talk at Architectural Thinking Workshop Cambridge 28-9 Nov 2012
<br>
<a href="archthink-sloman.pdf">Available HERE (PDF).</a>
</b></h3>
Please do not save copies - instead keep a link to this
location.
<br>
My answers to questionnaire circulated before the meeting:
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/archthink-sloman.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/archthink-sloman.html</a>
<p>
<hr/>
<a name="alt2012"></a>
<a name="altc-12"></a>
<a name="talk105"></a>
<a name="cas14"></a>

<h3><b>
Talk 105 What is computational thinking? Old (2012) and new (2014) versions:
</b></h3>
<ul>
<b>
<li>Talk 105 New Version for CAS-2014 <a href="cas14-sloman.pdf">HERE (PDF).</a>
<br>
What is computational thinking?
<br>
&nbsp;&nbsp;&nbsp;
What Forms of computational thinking will our children need
<br>
&nbsp;&nbsp;&nbsp;
when they grow up?

</b>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/compthink.html">Pre-talk summary (HTML)</a>
<br>
Background notes for CAS Conference 21st June 2014, University of Birmingham,
expanded (messily) here:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/cas-2014-compthink.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/cas-2014-compthink.html</a>
<br>
<small>
Note: Like all my online presentations this is likely to be updated in response
to comments, criticisms and afterthoughts.
So please store links rather than copies.
</small>
<p>
<li>
<b>
Talk 105 (ALT2012 original):
<br>
<b>Invited talk at:</b> <a href="http://altc2012.alt.ac.uk/calendar">ALT 2012 Conference Manchester 11 Sept 2012</a>
<br>
What is computational thinking?
<br>
&nbsp;&nbsp;&nbsp;
Who needs it? Why? How can it be learnt? (Can it be taught?)
<br>
&nbsp;&nbsp;&nbsp;
<a href="alt2012-sloman.pdf">2012 version HERE (PDF).</a>
<br>
&nbsp;&nbsp;&nbsp;
<a href="http://www.slideshare.net/asloman/what-is-computational-thinking-who-needs-it-why-how-can-it-be-learnt-can-it-be-taught">Also
on Slideshare.net (Flash)</a>
</b>
<p>
Because of a projector problem I gave the ALT2012 talk without slides.
<br>
Also recorded on video. Link to Youtube version <a href="#alt-video">below.</a>
<br>
The video is also linked on the slideshare site (above).
</ul>
<p>
<a name="alt-video"></a>
Added: 1 Dec 2012:
<br>
<a href="https://www.youtube.com/watch?v=QXAFz3L2Qpo">Video of presentation at the conference
(without slides: projector not working!)</a>
<p>
Also at Computing at School (CAS) Conference, July 2013, University of Birmingham
<br>
<b>Original version Installed:</b> 20 Sep 2012;
<br>
<b>Updated:</b> 21 Sep 2012; 24 Jan 2013; 6 Aug 2014; 23 Aug 2014
<p>
<b>Abstract for 2012 version (relevant to 2014 version)</b>
<ul>
<li>
What is computational thinking?
<br>
Seeing the universe as made of matter, energy and information, all
interacting; trying to understand how
they interact, building and testing explanatory theories, and using that
understanding in many fields of
study:
<br>
understanding evolution, understanding learning, understanding emotions,
understanding education,
understanding the economy, understanding ecosystems, ... all in terms of
their information processing
mechanisms and functionality.
<li>
Who needs it?
<br>
Biologists, psychologists, neuroscientists, psychotherapists, social
scientists, philosophers, educators,
designers of educational technology, art historians, theologians,
politicians, managers, ... parents with
young children, ...
<li>
Why?
<br>
Because without computational thinking you will use shallow and
inadequate models, do shallow and
inadequate empirical research (like alchemists before chemistry was
built on a theory of the sub-atomic structure of matter
<a href="http://newsletter.alt.ac.uk/2012/06/is-education-research-a-form-of-alchemy/">(Sloman, 2012)</a>), develop misguided educational
strategies, and fail to prepare our
young learners for the rest of the 21st century.
<li>
 How can it be learnt?
<br>
There's no easy way: learn to build ever more complex models of natural
information processing systems, try to understand the engineering design
problems that evolution addressed: always ask questions about what information
is needed, why it is needed, what information is available, how is it acquired,
how is it interpreted, analysed, stored, used, accessed, combined with other
information, used to derive new information, ... in what ways are those
processes and mechanisms faulty or inadequate.
<br>
See
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/design-based-approach.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/design-based-approach.html</a>
<li>
Can it be taught? Yes -- but it has many facets.
</ul>
<p>
As an example, the presentation attempts to show that current
debates about whether to use phonics or look-and-say methods for
teaching reading cannot be resolved sensibly without thinking
computationally about the nature of reading, learning, thinking,
speaking, understanding, and how all of these depend on
multi-layered information-processing architectures that are still
growing in different ways while children are learning to read.
<br>
Michael Morpurgo mounted a campaign of criticism of rigid use of and testing of
phonics in 2012, e.g. in BBC talks
<a href="http://www.bbc.co.uk/programmes/b01hxh6w">http://www.bbc.co.uk/programmes/b01hxh6w</a>
<br>
Compare: Andrew Davis
<br>
A Monstrous Regimen of Synthetic Phonics: Fantasies of Research-Based
Teaching 'Methods' Versus Real Teaching
<br>
in <i>Journal of Philosophy of Education</i>, Vol. 46, No. 4, 2012, pp 560--573.
<br>
<a href="https://www.dur.ac.uk/education/staff/profile/?mode=pdetail&id=617&sid=617&pdetail=82425">https://www.dur.ac.uk/education/staff/profile/?mode=pdetail&id=617&sid=617&pdetail=82425</a>
<br>
Those criticisms would be strengthened by use of computational thinking about
processes of education and multiple functions and mechanisms that need to be
integrated in advanced reading (e.g. fast silent reading).
<p>
<b>Note added 21 Sep 2012</b>
<br>
Perhaps the slides should have referred to a 2007 ACM paper by Peter
J. Denning (much better than his earlier work on "Great Principles"):
<blockquote>
<b>Computing is a Natural Science</b>
<br>
Information processes and computation continue to be found abundantly in the
deep structures of many fields. Computing is not--in fact, never was--a science
only of the artificial.
<p>
COMMUNICATIONS OF THE ACM July 2007/Vol. 50, No. 7, pp 13--18.
<br>
<a href="http://cs.gmu.edu/cne/pjd/PUBS/CACMcols/cacmJul07.pdf">http://cs.gmu.edu/cne/pjd/PUBS/CACMcols/cacmJul07.pdf</a>
</blockquote>
<p>

<hr/>

<a name="talk104"></a>
<a name="anniv"></a>
<a name="ecaianniv"></a>
<h3><b>
Talk 104: Biological, computational and robotic connections with Kant's theory
<br>
of mathematical knowledge
</a>
<br>
<a href="ecai-anniv-sloman.pdf">Available here (PDF).</a>
</b></h3>
<b>Invited talk at:</b>
ECAI 2012 Turing and Anniversary session, August 2012
<b>Installed:</b> 4 Dec 2012
<p>
<b>Abstract</b>
<blockquote>
In my research I meander through various disciplines, using fragments of AI that I
regard as relevant to understanding natural and artificial intelligence, willing to
learn from anyone.
<p>
As a result, all my knowledge of work in particular sub-fields of AI is very patchy,
and rarely up to date. This makes me unfit to write the history of European
collaboration on some area of AI research as originally intended for this panel
session.
<p>
However, by interpreting the topic rather loosely, I can (with permission from the
event organisers) regard some European philosophers who were interested in Philosophy
of mathematics as early AI researchers from whom I learnt much, such as Kant and Frege.
Hume's work is also relevant.
<p>
Moreover, more recent work by neuro-developmental psychologist Annette Karmiloff-Smith,
begun in Geneva with Piaget then developed independently, helps to identify important
challenges for AI (and theoretical neuroscience), that also connect with philosophy
of mathematics and the future of AI and robotics, rather than the history.
<p>
I'll present an idiosyncratic, personal, survey of a subset of AI stretching back in
time, and deep into other disciplines, including philosophy, psychology and biology,
and possibly also deep into the future, linked by problems of explaining human
mathematical competences. The unavoidable risk is that someone in AI has done very
relevant work on mathematical discovery and reasoning, of which I am unaware.
<p>
I'll be happy to be informed, and will extend these slides if appropriate.
<p>
See online paper
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/12.html#1205">http://www.cs.bham.ac.uk/research/projects/cogaff/12.html#1205</a>
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/triangle-theorem.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/triangle-theorem.html</a>
<br>
Theorems About Triangles, and Implications for Biological Evolution and AI:
The Median Stretch, Side Stretch, Triangle Sum, and Triangle Area Theorems
</blockquote>
<p>

<hr/>
<a name="talk103"></a>
<h3><b>
Talk 103:
Meta-morphogenesis and the Creativity of Evolution
<br>
<small>
 Mechanisms for bootstrapping biological minds
</small>
</a>
<br>
<a href="3cgi-sloman.pdf">Available HERE (PDF).</a>
</b></h3>
<b>Presented at:</b>
<blockquote>
ECAI 2012 Workshop on Computational Creativity, Concept Invention, and General
Intelligence
<br>
Montpellier, 27th August 2012
<br>
<small>
<a href="http://www.cogsci.uni-osnabrueck.de/~c3gi">http://www.cogsci.uni-osnabrueck.de/~c3gi</a>
<br>
Workshop proceedings:
<a href="http://www2.lirmm.fr/ecai2012/images/stories/ecai_doc/pdf/workshop/W40_c3gi_pre-proceedings_20120803.pdf">http://www2.lirmm.fr/ecai2012/images/stories/ecai_doc/pdf/workshop/W40_c3gi_pre-proceedings_20120803.pdf</a>
</small>
</blockquote>
<b>Installed:</b> 28 Aug 2012
<p>
<b>Abstract</b>
<blockquote>
Whether the mechanisms proposed by Darwin and others suffice to explain
all details of the achievements of biological evolution remains open.
Variation in heritable features can occur spontaneously, and Darwinian
natural selection can explain why some new variants survive longer than
others. But that does not satisfy Darwin's critics and also worries
supporters who understand combinatorial search spaces.
<p>
One problem is the difficulty of knowing exactly what needs to be explained:
Most research has focused on evolution of physical form, and physical
competences and behaviours, in part because those are observable features of
organisms. What is much harder to observe is evolution of information-processing
capabilities and supporting mechanisms (architectures, forms of representation,
algorithms, etc.).
<p>
Information-processing in organisms is mostly <i>invisible</i>, in part
because it goes on inside the organism, and in part because it often has
abstract forms whose physical manifestations do not enable us to
identify the abstractions easily. Compare the difficulty of inferring
thoughts, percepts or motives from brain measurements, or decompiling
computer instruction traces. Moreover, we may not yet have the concepts
required for looking at or thinking about the right things: we may need
more than the vast expansion of our conceptual tools for thinking about
information processing capabilities and mechanisms in the last half
century. However, while continually learning what to look for, we can
collaborate in attempting to identify the many important transitions in
information processing capabilities, ontologies, forms of
representation, mechanisms and architectures that have occurred on
various time-scales in biological evolution, in individual development
(epigenesis) and in social/cultural evolution -- including processes
that can modify later forms of evolution and development:
meta-morphogenesis.
<p>
Conjecture: The cumulative effects of successive phases of meta-morphogenesis
produce enormous diversity among living information processors, explaining how
evolution came to be the most creative process on the planet. Progress in AI
depends on understanding the products of this process.
<p>
Latest version of the workshop paper:
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/12.html#1203">http://www.cs.bham.ac.uk/research/projects/cogaff/12.html#1203</a>
</blockquote>

<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html</a>
<br>
See the main Meta-Morphogenesis project site.

<p>
<hr/>
<a name="talk102"></a>
<h3><b>
Talk 102:
Meta-Morphogenesis: of virtual machinery with
"physically indefinable" functions
<br>
<a href="incomputable-sloman.pdf">Draft available here (PDF)</a>
<br>
<small>
Overlaps with
<a href="#talk101"> Talk 101.</a>
</small>
</b></h3>
<b>Installed:</b> 16 Jun 2012
<br>
<b>Updated:</b> 1 Jul 2012
<p>
<b>Abstract</b>
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/incomputable-abstract.html">Online
Abstract</a>
<br>
This is the latest version of the presentation given at the
Workshop "The Incomputable":
<br>
<a href="http://www.mathcomp.leeds.ac.uk/turing2012/inc/">http://www.mathcomp.leeds.ac.uk/turing2012/inc/</a>
<br>
Royal Society Kavli Centre, Chicheley: 11-15 June 2012
<br>
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/incomputable-abstract.html">Abstract
for talk.</a>
<br>
</blockquote>
See next talk, on the Meta-Morphogenesis project.
<hr/>

<a name="talk101"></a>
<h3><b>
Talk 101:
Meta-Morphogenesis: Evolution of mechanisms for producing minds
<br>
<small>
OR
<br>
Evolution, development and learning, producing new mechanisms
of evolution, development and learning.
</small>
</a>
<p>
Talk at  Cambridge University Computing and Technology Society
<a href="http://www.cucats.org">www.cucats.org</a>
</a>
<br>
<a href="sloman-cucats-talk.pdf">Available HERE (PDF).</a>
</b></h3>
<b>Invited talk at:</b>
Cambridge University Computing and Technology Society
(Tuesday 8th May 2012)
<br>
<b>NB:</b>  Criticisms and suggestions welcome.
<p>
<b>Installed:</b> 14 May 2012
<p>
<b>Abstract</b>
<blockquote>
See the abstract posted at:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/cucats-abstract.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/cucats-abstract.html</a>
<p>
<b>See also</b>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/examples/thinky.html">http://www.cs.bham.ac.uk/research/projects/poplog/examples/thinky.html</a>
<br>
types of programming education, including 'thinky' programming.
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/examples/examples.html">http://www.cs.bham.ac.uk/research/projects/poplog/examples/examples.html</a>
<br>
draft notes on how to teach 'thinky' programming.
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/cas-ai/video-tutorials.html">http://www.cs.bham.ac.uk/research/projects/poplog/cas-ai/video-tutorials.html</a>
<br>
experimental video tutorials.
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html</a>
<br>
The main Meta-Morphogenesis project site.
</ul>
</blockquote>
<p>
<hr/>
<a name="talk100"></a>
<h3><b>
Talk 100: Architectures for more or less intelligent life
<br>
<small>
How to turn philosophers of mind into engineers
-- to help them solve old philosophical problems
</small>
</a>
<br>
<a href="sloman-phil-cogsci.pdf">Available HERE (PDF).</a>
</b></h3>
<b>Guest lecture:</b>
<blockquote>
for Philosophy of Cognitive Science Students, Birmingham Feb 2012.
</blockquote>
<b>Installed/revised:</b>21 Apr 2012
<br>
14 Feb 2015: Some minor formatting fixes.
<p>
<b>Abstract</b>
<blockquote>
We can integrate philosophy of mind with other fields, and turn vague
insoluble problems into problems about what sorts of information
processing architectures make
different sorts of minds possible, including minds that grow and change
their architectures. By considering different evolutionary and
developmental trajectories in different species and in different sorts
of future machines and robots we can understand each case much better,
including understanding what human minds are, and how they grow and
change.
It's important not only to consider different sorts of minds, but also
whole architectures with different sorts of components performing
different functions, since the nature of each function depends on the
others it interacts with.
</blockquote>
<p>

<hr/>
<a name="talk99"></a>
<h3><b>
Talk 99:
The Meta-Morphogenesis project - An introductory overview
<br>
Two talks in Birmingham October 2011, and elsewhere in 2012
</a>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">The
main Meta-Morphogenesis web site (HTML).</a>
</b></h3>
Talks at:
<blockquote>
University of Birmingham, Language and Cognition, 21st October 2011
<br>
and School of Computer Science 31st October 2011.
<br>
Also: variants at: University of Aberystwyth; Royal Society meeting on
Animal Minds, Chichely Hall; EuCognition Meeting Oxford; University of
Nottingham.
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
All the presentations were informal and based on portions of these three
web sites (different portions):
<small>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/meta-morphogenesis.html</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/beyond-modularity.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/beyond-modularity.html</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html</a>
</ul>
</small>
Slides will be added here later. See also
<a href="#toddler">Slides on toddler theorems</a> below.
</blockquote>
<p>
<hr/>

<a name="talk98"></a>
<h3><b>
Talk 98:
The deep, barely noticed, consequences of embodiment.
<br>
(Ignored by most embodiment theorists)
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/pt-ai-abstract.html">Extended
Abstract HERE
(HTML)</a>
</b></h3>
Invited talk for PT-AI Conference, Thessaloniki, 3 & 4 October 2011
Philosophy and Theory of Artificial Intelligence
<br>
<a href="http://www.pt-ai.org/">http://www.pt-ai.org/</a>
<p>

<hr/>
<a name="talk97"></a>
<h3><b>
Talk 97:
How to combine science and engineering to solve philosophical
 problems
</a>
<br>
Based on
<a href="#talk96">Notes for AAAI Tutorial.</a>
</b></h3>
Invited talk September 7, 2011 at:
<blockquote>
"Barcelona Cognition, Brain and Technology summer school - BCBT"
<br>
<a href="http://bcbt.upf.edu/bcbt11">http://bcbt.upf.edu/bcbt11</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
I first learnt about AI in 1969 when I was a lecturer in philosophy, and
soon became convinced that the best way to make progress in solving a
range of philosophical problems (e.g. in philosophy of mathematics,
philosophy of mind, philosophy of language, philosophy of science,
epistemology, philosophy of emotions, and some parts of metaphysics) was
to produce and analyse designs for successively larger working fragments
of minds. I think that project can be enhanced by using it to pose new
questions about transitions in the evolution of biological
information-processing systems. I shall try to explain these
relationships between AI, biology and philosophy and show how they can
yield major new insights, while also inspiring important (and difficult)
new research. I hope to make the presentation interactive.
<p>
I shall post relevant reading matter on the web site being prepared for
a closely related tutorial in August at AAAI, here:
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/aaaitutorial/">http://www.cs.bham.ac.uk/research/projects/cogaff/aaaitutorial/</a>
</blockquote>
<p>

<hr/>
<a name="aaai11"></a>
<a name="aaai11tut"></a>
<a name="talk96"></a>
<h3><b>
Talk 96: Philosophy as AI and AI as philosophy (needs expansion)
<br>
<a href="sloman-aaai11-tut.pdf">PDF file</a>
</b></h3>

Slides for Tutorial presented at AAAI-20011 8 Aug 2011
<br>
The tutorial overview is available here:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/aaaitutorial/">http://www.cs.bham.ac.uk/research/projects/cogaff/aaaitutorial/</a>
<p>
A subset of these slides will be used for a talk at
<br>
<a href="http://bcbt.upf.edu/bcbt11/">The Barcelona Cognition, Brain and Technology summer school BCBT2011</a>
<br>
"How to combine science and engineering to solve philosophical problems"
<p>
<hr/>
<a name="sps11"></a>
<a name="talk95"></a>
<h3><b>
Talk 95:
Evolution of mind as a feat of computer systems engineering
<br>
    Lessons from decades of development of virtual machinery,
including self-monitoring virtual machinery.
<br>
Varieties of Self-Awareness and Their Uses
in Natural and Artificial Systems
<br>
<a href="sloman-sps-2011.pdf">Available here (PDF).</a>
</b></h3>
Invited talk at SPS Workshop on Philosophy of Artificial Intelligence
<br>
Nancy 19 July 2011
<br>
DRAFT -- Liable to change. Comments welcome.
<br>
Installed
19 Jul 2011: Part of this version was presented at the workshop.
Further revisions are likely.
<br>
The conference paper is <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/11.html#1103">here</a>
<br>
See also
<ul>
<li>
<a href="#talk86">
Talk 86: Supervenience and Causation in Virtual Machinery
<br>
Revised 8 May 2014
</a>
<li>
<a href="#talk85">
Talk 85: Daniel Dennett on Virtual Machines
</a>
<li>
<a href="#talk84">
Talk 84:
Using virtual machinery to bridge the "explanatory gap"
<br>
<small>
Or:
Helping Darwin: How to Think About Evolution of Consciousness
<br>
Or: How could evolution (or anything else) get ghosts into machines?
</small>
</a>
</ul>
<p>
<hr/>
<a name="talk94"></a>
<h3><b>
Talk 94:
Varieties of Self-Awareness and Their Uses
in Natural and Artificial Systems
<br>
Metacognition and natural cognition
<br>
Towards a conceptual framework
<br>
<a href="sloman-meta-cog-panel.pdf">Available here (PDF).</a>
</b></h3>
Talk at EPICS workshop Birmingham 2011
(Local contact Peter Lewis
<a
href="http://prlewis.com/files/peterlewis.pdf">http://prlewis.com/files/peterlewis.pdf</a>)
<br>
<a href="http://www.aware-project.eu/resource/">http://www.aware-project.eu/resource/</a>
<br>
DRAFT -- Liable to change. Comments welcome.
<br>
Update 19 Jul 2011: Part of this version was presented at the workshop.
Further revisions are likely.
<blockquote>
<small>
<pre>
Also posted <a href="http://www.aware-project.eu/2011/11/01/varieties-of-self-awareness-and-their-uses-in-natural-and-artificial-systems-aaron-sloman/">on slideshare</a>
by the AWARE EU project <a href="http://www.aware-project.eu/">http://www.aware-project.eu/</a>
</pre>
</small>
</blockquote>
See also
<ul>
<li>
<a href="#talk86">
Talk 86: Supervenience and Causation in Virtual Machinery
<br>
Revised 8 May 2014
</a>
<li>
<a href="#talk85">
Talk 85: Daniel Dennett on Virtual Machines
</a>
<li>
<a href="#talk84">
Talk 84:
Using virtual machinery to bridge the "explanatory gap"
<br>
<small>
Or:
Helping Darwin: How to Think About Evolution of Consciousness
<br>
Or: How could evolution (or anything else) get ghosts into machines?
</small>
</a>
</ul>
<p>
<hr/>
<p>
<a name="gibson"></a>
<a name="talk93"></a>
<h3><b>
Talk 93: What's vision for, and how does it work?
<br>
From Marr (and earlier)
<br>
to Gibson and Beyond
<br>
(With some potted, rearranged, history)
<br>
<a href="sloman-beyond-gibson.pdf">Available here (PDF)</a>
<br>
Also on Slideshare.net
<a href="http://www.slideshare.net/asloman/whats-vision-for-and-how-does-it-work-from-marr-and-earlierto-gibson-and-beyond-with-some-potted-rearranged-history">here
(FLASH)</a>
</b></h3>
Presented at Birmingham Vision Club (School of Psychology),
17th June 2011, and a Vision/Robotics workshop (Sheffield
University Psychology dept.) 23rd June 2011.
DRAFT -- Liable to change. Comments welcome.
<p>
<b>Note:</b>
<i>
(This is supplemented by a newer presentation: <a href="#talk111">Talk
111</a>, added March 2015, which presents themes linking evolution of language
and evolution of vision.)
</i>
<p>
<b>Abstract</b>
<blockquote>
Very many researchers assume that it is obvious what vision (e.g. in
humans) is for, i.e. what functions it has, leaving only the problem
of explaining how those functions are fulfilled.
<p>
So they postulate mechanisms and try to show how those mechanisms
can produce the required effects, and also, in some cases, try to show
that those postulated mechanisms exist in humans and other animals
and perform the postulated functions.
<p>
The main point of this presentation is that it is far from obvious
what vision is for - and J.J. Gibson's main achievement is drawing
attention to some of the functions that other researchers had ignored.
<p>
I'll present some of the other work, show how Gibson extends and
improves it, and then point out much more there is to the functions of
vision and other forms of perception than even Gibson had noticed.
<p>
In particular, much vision research, unlike Gibson, ignores vision's
function in on-line control and perception of continuous processes;
and nearly all, including Gibson's work, ignores meta-cognitive
perception, and perception of possibilities and constraints on
possibilities and the associated role of vision in reasoning.
<p>
If we don't understand that we cannot understand how biological
mechanisms arising from requirements for being embodied in a rich,
complex and changing 3-D environment underpin human mathematical
capabilities, including the ability to reason about topology and
Euclidean geometry.
<br>
See discussions of <a href="#toddler">"Toddler theorems" below.</a>
</blockquote>
<p>
<hr/>
<a name="talk93a"></a>
<h3><b>
Talk 93a: What's vision for?
<br>
Modified version of <a href="#talk93">Talk 93.</a>
<br>
<a href="sloman-whats-vision-for.pdf">Available here (PDF)</a>
</b></h3>

Guest Lecture for Birmingham UG students. 31 Jan 2012.
<br>
Part of Philosophy of Cognitive Science Lectures.
<p>
<b>Abstract</b>
<blockquote>
To Be Added
</blockquote>
<p>
<hr/>
<a name="cas11"></a>
<a name="talk92"></a>
<h3><b>
Talk 92: Computing: The Science of Nearly Everything. Including Biology!
<br>
<small>
Talk for CAS "TeachShare" presentation, 8 Jun 2011
</small>
</a>
<br>
<a href="sloman-cas-teachshare.pdf">Available here (PDF).</a>
<br>
<a href="http://www.slideshare.net/asloman/sloman-casteachshare">In Flash format, on slideshare.net.</a>
</b></h3>
<p>
Prepared for online presentation for <a href="http://computingatschool.org.uk">Computing At School (CAS)</a>
<br>
(Using elluminate conference tool.)
<blockquote>
Background notes:
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/teach-share.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/teach-share.html</a>
<p>
Recording of the presentation: <a href="http://bit.ly/iVhp0i">http://bit.ly/iVhp0i</a>
<br>
Requires JavaWebStart (javaws). Set up and test your system here first:
    <a href="http://www.elluminate.com/support">http://www.elluminate.com/support</a>
</blockquote>
<p>
<hr/>
<a name="talk91"></a>
<h3><b>
Talk 91: LIFE and INFORMATION
<br>
Self-modifying information-processing architectures
</a>
<br>
<a href="sloman-life-and-information.pdf">Available here (PDF).</a>
</b></h3>
<small>
Talk for 2nd Year CS students, Birmingham, 28 Jan 2011
</small>
<p>
<b>Abstract</b>
<blockquote>
 I contrast the evolution of physical forms, and observable
 behaviours with evolution of types of information processing in
 organisms of various kinds.
<br>
This could be described as
 "invisible evolution": hard to identify but essential to understand if we want
to understand the achievements of biological evolution and the nature of what
it produced -- including ourselves.
</blockquote>
<p>
<hr/>
<p>
<a name="piaget"></a>
<a name="talk90"></a>
</a>
<h3><b>
Talk 90a, 90b:
<br>
Piaget (and collaborators) on Possibility and Necessity
<br>
And the relevance of/to AI/Robotics/mathematics (in biological evolution
and development)
</a>
<br>
<small>
Two versions:
<br>
Presented 21 Feb 2011, Birmingham, 28th March Dagstuhl, 6th April Oxford.
</small>
<p>
Talk 90a: Piaget (and collaborators) on Possibility and Necessity
<br>
(Superseded by Talk 90b below)
<br>
Version 1: 21 Feb 2011 in Psychology and Computer Science, Birmingham
<a href="sloman-piaget-poss-ness.pdf">HERE, (PDF).</a>
<br>
Available
<a href="sloman-piaget-poss-ness-2-up.pdf">HERE, in 2-UP PDF Format.</a>
<p>
Talk 90b:
Version 2: presented at Dagstuhl workshop 28th March 2011, and Oxford
CIAO/Automatheo workshop 6th April (after revision).
<br>
Available
<a href="sloman-dagstuhl11.pdf">HERE, (PDF).</a>
<br>
Available
<a href="sloman-dagstuhl11-2up.pdf">HERE, in 2-UP PDF Format.</a>
</b></h3>
<p>

<p>
Videos relevant to the talk:
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/vid/">http://www.cs.bham.ac.uk/research/projects/cogaff/movies/vid/</a>
</blockquote>
<p>

<b>Note added 7 Mar 2011</b>
<blockquote>
Since the talk I have been looking at (among other things) Annette
Karmiloff-Smith's work on Representational Redescription, in her 1992 book
<a href="http://www.amazon.com/Beyond-Modularity-Developmental-Perspective-Cognitive/dp/0262611147">Beyond Modularity</a>
<br>
There is much overlap in our ideas, which I am attempting to document
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/beyond-modularity.html">here</a>.
<p>
I have also expanded the slides to include a rational reconstruction of what I
think Piaget was studying expressed in terms of the concept of "Exploration
Domain" (close to "micro-worlds" in AI and "microdomains" in Karmiloff-Smith).
<p>
Humans and some other animals seem to have the ability first to learn patterns
of phenomena in an exploration domain, then, in some cases, to reorganise
(unwittingly) the empirical information into something like a deductive system
in which previous patterns (sometimes corrected) become either
"examples" or "theorems". (Hence Possibility and Necessity.)
<p>
This process will depend on both features of the environment and mechanisms
produced by evolution to help animals cope with various sorts of environment.
Some of the features of this process are: different exploration domains are
explored and learnt about in parallel, sometimes domains can be combined to
form more complex domains, many, though not all, domains are closely related to
the structure of space, time and matter, most animals do not also have the
metacognitive ability to learn to make their own learning an exploration
domain, though humans do. Well known transitions in human language learning
seem to be based on late evolutionary developments of the above mechanisms in
humans. The processes of reorganisation depend on architectural growth,
sometimes combined with use of new special purpose forms of representation.
<p>
The processes of construction of deductive revisions, and the processes of
deployment of the new systems are sometimes buggy (as is mathematical theorem
proving (Lakatos: <b>Proofs and Refutations</b>). Also for each learner the
trajectory (development+learning) may be unique and depend on genetic, social
and physical environmental opportunities.
<p>
There seem to be deep implications for biology, developmental psychology,
neuroscience, comparative cognitive science, education, AI/Robotics and
philosophy (e.g. epistemology, philosophy of language and philosophy of
mathematics).
<p>
Results of the human genome project cannot be understood until much more is
known about what the genome (or genomes) contributes to these processes and
how.
</blockquote>

<b>Original Abstract</b>
<blockquote>
It is not widely known that shortly before he died Jean Piaget and his
collaborators produced a pair of books
on Possibility and Necessity, exploring questions about how two linked sets of
abilities develop:
<br>
(a) The ability to think about how things might be, or might have been,
different from the way they are.
<br>
(b) The ability to notice limitations on possibilities, i.e. what is necessary
or impossible.
<p>
I believe Piaget had deep insights into important problems for
cognitive science that have largely gone unnoticed, and are also important for
research on intelligent robotics, or more generally Artificial Intelligence
(AI), as well as for studies of animal cognition and how various animal
competences evolved and develop. <br> The topics are also relevant to
understanding biological precursors to human mathematical competences and to
resolving debates in philosophy of mathematics, e.g. between those who regard
mathematical knowledge as purely analytic, or logical, and those who, like
Immanuel Kant, regard it as being synthetic, i.e. saying something about
reality, despite expressing necessary truths that cannot be established purely
empirically, even though they may be initially discovered empirically (as
happens in children).
<p>
It is not possible in one seminar to summarise either
book, but I shall try to present an overview of some of the key themes and will
discuss some of the experiments intended to probe concepts and competences
relevant to understanding necessary connections.
<p>
In particular, I hope to
explain: (a) The relevance of Piaget's work to the problems of designing
intelligent machines that learn the things humans learn. (Most researchers in
both Developmental Psychology and AI/Robotics have failed to notice or have
ignored most of the problems Piaget identified.) (b) How a deep understanding
of AI, and especially the variety of problems and techniques involved in
producing machines that can learn and think about the problems Piaget explored,
could have helped Piaget describe and study those problems with more clarity
and depth, especially regarding the forms of representation required, the
ontologies required, the information processing mechanisms required and the
information processing architectures that can combine those mechanisms in a
working system -- especially architectures that grow themselves. <p> That kind
of computational or "design-based" understanding of the problems can lead to
deeper clearer specifications of what it is that children are failing to grasp
at various stages in the first decade of life, and what sorts of transitions
can occur during the learning. I believe the problems, and the explanations,
are far more complex than even Piaget thought. The potential connection between
his work and AI was appreciated by Piaget himself only very shortly before he
died.
<p>
One of the key ideas implicit in Piaget's work (and perhaps explicit in
something I have not read) is that the learnable environment can be decomposed
into explorable domains of competence that are first investigated by finding
useful, reusable patterns, describing various fragments.
<p>
Then eventually a large scale reorganisation is triggered (per domain) which
turns the information about the domain into a more economical and more powerful
generative system that subsumes most of the learnt patterns and, through use of
compositional semantics in the internal representation, allows coping with much
novelty -- going far beyond what was learnt.
<p>
(I think this is the original source of human mathematical competences.)
<p>
Language learning seems to use a modified, specialised, version of this more
general (but not totally general) mechanism, but the linguistic mechanisms were
both a later product of evolution and also get turned on later in young humans
than the more general domain learning mechanisms.
The linguistic mechanisms also require (at a later stage) specialised
mechanisms for learning, storing and using lots
of exceptions to the general rules induced (the syntactic and semantic rules).
<p>
The language learning builds on prior learning of a variety of explorable
domains, providing semantic content to be expressed in language.
Without that prior development, language learning must be very shallow and
fragmentary -- almost useless.
<p>
When two or more domains of exploration have been learnt they may be
combinable, if their contents both refer to things and processes in space time.
Space-time is the the great bed in which many things can lie together and
produce novelty.
<p>
I think Piaget was trying to say something like this but did not have the right
concepts, though his experiments remain instructive.
<p>
Producing working demonstrations of these ideas in a functional robot able to
manipulate things as a child does will require major advances in AI, though
there may already be more work of this type than I am aware of.
<p>
<small>
See also
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/11.html#1101">http://www.cs.bham.ac.uk/research/projects/cogaff/11.html#1101</a>
<br>
Evolved Cognition and Artificial Cognition:
   Some Genetic/Epigenetic Trade-offs for Organisms and Robots
</small>
</blockquote>

<p>
<hr/>
<a name="sgai10"></a>
<a name="talk89"></a>
<h3><b>
Talk 89: Genomes for self-constructing, self-modifying
information-processing architectures
<br>
<a href="sloman-sgai2010.pdf">Available HERE (PDF)</a>
<small>
<br>
(NB: Work in progress. Liable to change.)
</small>
</b></h3>
Slides for invited talk at SGAI 2010
<a href="http://www.cs.bham.ac.uk/~jlw/cognitive-robotics-workshop.html">Workshop on Bio-inspired and Bio-Plausible Cognitive Robotics</a>
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/sgai10-abstract.html">Pre-Workshop
Abstract</a>
<p>
<hr/>
<a name="talk88"></a>
<h3>
<b> Talk 88: A Multi-picture Challenge for Theories of Vision
<br>
<small>
Including a sketch of a specification for dynamical systems
required.
</small>
</a>
<br>
<a href="multipic-challenge.pdf ">Available HERE (PDF).</a>
<br>
<small>
Also on Slideshare.net here, in flash format:
<br>
<a href="http://www.slideshare.net/asloman/a-multipicture">http://www.slideshare.net/asloman/a-multipicture</a>
</small>
</b></h3>
Originally presented at a BBSRC workshop and 'vision club' meetings
in Birmingham, 2007.
<br>
Moved here 2008.
<p>
<b>Abstract</b>
<blockquote> One of the amazing facts about
human vision is how fast a normal adult visual system can respond to
a complex optic array with rich 2-D structure representing complex
3-D structures and processes, e.g. turning a corner in a large and
unfamiliar town.
<p>
This has implications for the mechanisms required, which I try to
spell out.
See also:

<blockquote>
 Aaron Sloman,
<br>
  Architectural and Representational Requirements for Seeing Processes, Proto-affordances and Affordances,
<br>
 In <i>Logic and Probability for Scene Interpretation,</i>
 Eds. Anthony G. Cohn, David C. Hogg, Ralf Moeller and Bernd Neumann,
<br>
 Dagstuhl Seminar 08091 Proceedings, 2008,
  Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, Germany,
<br>
  <a href="http://drops.dagstuhl.de/opus/volltexte/2008/1656">http://drops.dagstuhl.de/opus/volltexte/2008/1656</a>
</blockquote>
</blockquote>
<p>
<hr/>
<a name="ai-bio"></a>
<a name="talk87"></a>
<h3><b>
Talk 87:
What does AI have to do with Biology?
<br>
<small>
Talk for first year Introduction to AI students, 9th Nov 2010
<br>
School of Computer Science, University of Birmingham
</small>
<br>
<a href="ai-bio.pdf">Available HERE (PDF)</a>
</b></h3>
Added: 9 Nov 2010  --- Modified: 11 Nov 2010; 19 Nov 2010
<p>
The talk was presented on 9th Nov, showing these slides and some
videos. I may later extend the slides. Suggestions welcome.
<p>
<b>Abstract:</b>
<blockquote>
A task for AI is to work with biologists, not just learning from
them, but also providing them with new AI-informed concepts,
formalisms, questions, suggestions for experiments, theories, and
working explanatory models.
<p>
The videos shown in the lecture, and a few more, are available
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/vid/">here.</a>
<p>
See also:
<ul>
<li>
<a href="#talk78">Talk 78: Computing: The Science of Nearly Everything
</a> below.
<li>
<a href="#talk96">Philosophy as AI and AI as philosophy (AAAI 2011 Tutorial)</a>
<li>
<a href="#talk91">LIFE and INFORMATION Self-modifying information-processing architectures</a>
<li>
<a href="http:#talk95">Evolution of mind as a feat of computer systems engineering
<br>
Lessons from decades of development of virtual machinery, including
self-monitoring virtual machinery.
<br>
Varieties of Self-Awareness and Their Uses in Natural and Artificial
Systems
</a>
</ul>

</blockquote>
<p>
<hr/>
<a name="vmcauses"></a>
<a name="talk86"></a>
<h3><b>
Talk 86: Supervenience and Causation in Virtual Machinery
<br>
<small>
<a href="sloman-virtuality-causation.pdf">sloman-virtuality-causation.pdf</a>
</small>
</b></h3>
<b>Added:</b> 30 Sep 2010;
<br>
<b>Modified:</b> 15 Oct 2010; 22 Nov 2010 29 Nov 2010; 5 Dec 2010; ... 9 May 2014
(Ongoing)
<p>
<b>Related presentations:</b>
<ul>
<li>
<a href="#talk86"> (This talk)
Talk 86: Supervenience and Causation in Virtual Machinery
</a>
<p>
<li>
<a href="#talk95">
Talk 95:
Evolution of mind as a feat of computer systems engineering
<br>
    Lessons from decades of development of virtual machinery,
including self-monitoring virtual machinery.
<br>
Varieties of Self-Awareness and Their Uses
in Natural and Artificial Systems
</a>
<br>
(Presented at SPS 2011, Nancy, France)
<p>
<li>
<a href="#talk84">Talk 84: Using virtual machinery to bridge the "explanatory gap"
<br>
  Or: Helping Darwin: How to Think About Evolution of Consciousness
<br>
  Or: How could evolution (or anything else) get ghosts into
machines?
<br>
(This was presented at
<a href="http://www.sab2010.org/wiki/PostConference">SAB2010</a> and
a modified version at
British Psychological Society
<a href="http://www.bps.org.uk/conex/events/cep_2010/cep_2010.cfm">
Consciousness and Experiential Psychology Section
<br>
Annual Conference 2010: Nature and Human Nature
</a>
10th-12th September, St. Anne's College, Oxford
</a>
<p>
<li>
<a href="#talk85">
Talk 85: Daniel Dennett on Virtual Machines
</a>
<li>
<a href="#talk76">Talk 76: The history, nature, and significance of virtual
machinery</a> (Aimed at computer scientists.)
</ul>
<p>
<b>Abstract</b>

<blockquote>
This unfinished, still somewhat disorganised, draft attempts to
explain what running virtual machines are, in terms of kinds of
dynamical system whose behaviours and competences are not best
described in terms of physics and chemistry, even though they have
to be fully implemented in physical mechanisms in order to exist and
operate. This attempts to explain in more detail than my earlier
papers how "sideways causation" and how "downward causation" can
occur in running virtual machines, i.e. non-physical things causally
influencing one another and also influencing physical events and
processes -- without any magic, mysticism, quantum mechanics etc.
needed, just sufficiently tangled webs of true counterfactual
conditionals supported by sophisticated machinery designed or
evolved for that purpose.
<p>
Two notions of real existence are proposed (a) being able to cause or be caused
by other things (existence in our world) and (b) being an abstraction that is
part of a system of constraints and implications (mathematical existence,
story-relative existence, etc.). Some truths about causal connections between
things with the first kind of existence can be closely related to mathematical
connections between things of the second kind. (I think that's roughly Immanuel
Kant's view of causation, in opposition to Hume.)
<p>
Some of the problems are concerned with concurrent interacting
subsystems within a virtual machine, including co-operation,
conflict, self-monitoring, and self-modulation. The patterns of
causation involving interacting <b>information</b> are not well
understood. Existing computer models seem to be far too simple to
model things like conflicting tastes, principles, hopes, fears, ...
<br>
In particular physical opposing forces and other well understood
interacting physical mechanisms are very different from these
interactions in mental machinery, even though they are fully
implemented in physical machinery. This is likely to be "work in
progress for some time to come."
<p>
This presentation is intended to provide background supporting
material for other presentations and papers on virtual machinery,
consciousness, qualia, introspection and the evolution of mind,
including <a href="#talk84">Talk 84</a> below explaining how Darwin
could have answered some of his critics regarding evolution of mind
and consciousness.
<p>
<b>
Expanded 20 Sep 2015
<br>
I don't believe the ideas about requirements are clear enough yet or
the ideas about explanatory mechanisms deep enough.</b> See also:
<div style="margin-left:15px; margin-top:0px; margin-bottom:0px;">
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/vm-functionalism.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/vm-functionalism.html</a>
<br>
Virtual Machine Functionalism (VMF)
<br>
(The only form of functionalism worth taking seriously in
<br>
Philosophy of Mind and theories of Consciousness)
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/construction-kits.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/construction-kits.html</a>
<br>
The scientific/metaphysical explanatory role of construction kits:
<br>
fundamental and derived kits; concrete, abstract and hybrid kits.
</div>


</blockquote>
<p>
<hr/>
<a name="dennettvm"></a>
<a name="talk85"></a>
<h3><b>
Talk 85: Daniel Dennett on Virtual Machines
<br>
<small>
Available
<a href="sloman-dennett-vms.pdf">HERE (PDF).</a>
</small>
</b></h3>
Installed: 20 Sep 2010; Revised 20 Nov 2010; 29 Nov 2010;
<p>
<b>Related presentations:</b>
<ul>
<li>
<a href="#talk86">
Talk 86: Supervenience and Causation in Virtual Machinery
</a>
<li>
<a href="#talk84">Talk 84: Using virtual machinery to bridge the "explanatory gap"
</a>
<br>
Or: Helping Darwin: How to Think About Evolution of Consciousness
<br>
  Or: How could evolution (or anything else) get ghosts into
machines?
<li>
<a href="#talk85">
(This talk) Talk 85: Daniel Dennett on Virtual Machines
</a>
<li>
<a href="#talk76">Talk 76: The history, nature, and significance of virtual
machinery</a> (Aimed at computer scientists.)
</ul>
<p>
<b>Abstract</b>
<blockquote>
This is one of a collection of presentations regarding virtual
machines and their causal powers. See also
<br>
<a href="#talk86">Talk 86</a>, <a href="#talk84">Talk 84</a>,
<a href="#talk71">Talk 71</a>, and some older talks on supervenience
and virtual machinery.
<p>
This presentation provides a few notes on Dennett's views on
virtual machines, extracted from <a href="#talk73">Talk73</a> with
some revisions, including a criticism of what he says about
"centres of narrative gravity" and "centres of gravity" and
"point masses", e.g. in his paper "Real Patterns".
<p>
His occasional reluctance to be a realist about virtual machinery
and his reluctance to be a realist about mental states and processes
(as opposed to being willing to adopt "The intentional stance") were
both attributed in an early version of this presentation to a failure
to understand the significance of the explanatory power of virtual
machines and their causal powers in computing systems, as discussed
in various presentations listed here. However his more recent
publication
<blockquote>
The Cultural Evolution of Words and Other Thinking Tools
<br>
<a href="http://www.ncbi.nlm.nih.gov/pubmed/19687141">http://www.ncbi.nlm.nih.gov/pubmed/19687141</a>
</blockquote>
is
unequivocal about the importance and reality VMs.
</blockquote>
<p>
<hr/>
<a name="sab2010"></a>
<a name="talk84"></a>
<h3><b>
Talk 84:
Using virtual machinery to bridge the "explanatory gap"
<br>
<small>
Or:
Helping Darwin: How to Think About Evolution of Consciousness
<br>
Or: How could evolution (or anything else) get ghosts into machines?
<br>
<a href="sloman-bps-cep.pdf">Revised slides available HERE (PDF).</a>
<br>
Minor revision: 8 Jul 2018
<p>
Slides prepared for the SAB2010 presentation
HERE <a href="sloman-sab2010-slides.pdf"> (PDF)</a>
<br>
(Out of date but may be useful with the video.)
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/#sabtalks">Videos
of talks at SAB2010</a>
</small>
</b></h3>
<b>Installed:</b> 23 Nov 2010.
<br>
<b>Last Updated:</b> 23 Nov 2010; 10 Dec 2010;
<p>
Invited talk at:
<blockquote>
SAB2010
<br>
11th International Conference on Simulation of Adaptive Behaviour
<br>
Paris, 29 August 2010 (Presented at
Clos-Luc&eacute;, Amboise)
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/10.html#sab">The published paper.</a>
<p>
Also presented 10th Sept at Conference on "Nature and Human Nature" (Consciousness and Experiential
Psychology) Oxford:
<br>
<a href="http://www.bps.org.uk/conex/events/cep_2010.cfm">http://www.bps.org.uk/conex/events/cep_2010.cfm</a>
<p>
</blockquote>
<b>Related presentations:</b>
<ul>
<li>
<a href="#talk86">
Talk 86: Supervenience and Causation in Virtual Machinery
</a>
<li>
<a href="#talk84"> (This talk) Talk 84: Using virtual machinery to bridge the "explanatory gap"
<br>
  Or: Helping Darwin: How to Think About Evolution of Consciousness
<br>
  Or: How could evolution (or anything else) get ghosts into
machines?
</a>
<li>
<a href="#talk85">
Talk 85: Daniel Dennett on Virtual Machines
</a>
<li>
<a href="#talk76">Talk 76: The history, nature, and significance of virtual
machinery</a> (Aimed at computer scientists.)
</ul>

<p>
<b>Abstract</b>
<blockquote>
    Many of Darwin's opponents, and some of those who accepted the theory of
    evolution as regards physical forms, objected to the claim that human mental
    functions, and consciousness in particular, could be products of evolution.
    There were several reasons for this opposition, including unanswered
    questions as to how physical mechanisms could produce mental states and
    processes -- an old, and still surviving, philosophical problem.
<p>
We can now show in principle how evolution could have produced the
"mysterious" aspects of consciousness if, like engineers developing
computing systems in the last six or seven decades, evolution "solved"
increasingly complex
problems of representation and control (including
    self-monitoring and self-control) by producing systems with
increasingly abstract, but effective, mechanisms, including
self-observation capabilities, implemented in virtual machinery.
<p>
    It is suggested that these capabilities are, like many capabilities of
    computer-based systems, implemented in non-physical virtual machines which,
    in turn, are implemented in lower level physical mechanisms. For this,
    evolution would have had to produce far more complex virtual machines than
    human engineers have so far managed, but the key idea of
switching information processing to a higher level of abstraction,
might be the same.
<p>
However it is not yet clear
whether the biological virtual machines could have been implemented
in the kind of discrete technology used in computers as we know
them.
These ideas were not available to Darwin and his
    contemporaries because most of the concepts, and the technology, involved in
    creation and use of sophisticated virtual machines has only been developed
    in the last half century, as a by-product of a large number of design
    decisions by hardware and software engineers.
<p>
<b>Note:</b>
Some of the ideas about evolutionary pressures from the environment
are summarised  briefly in a commentary on a 'target article' by
Margaret Boden
<br>
Can computer models help us to understand human creativity?
<br>
<a href="http://nationalhumanitiescenter.org/on-the-human/2010/05/can-computer-models-help-us-to-understand-human-creativity/">http://nationalhumanitiescenter.org/on-the-human/2010/05/can-computer-models-help-us-to-understand-human-creativity/</a>
<br>
Previously at this defunct web site:
<br>
<a href="http://onthehuman.org/2010/05/can-computer-models-help-us-to-understand-human-creativity/">Can computer models help us to understand human creativity?</a>
<br>
My commentary is at the end of the above web page, and also copied
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/creativity-boden.html">here.</a>
<p>
<b>Note:</b> This is related to hard unsolved philosophical problems
about the concept of causation.
<p>
</blockquote>
<p>
<hr/>
<a name="genome"></a>
<a name="talk83"></a>
<h3><b>
Talk 83 Routes from Genome to Architecture (provisional title)
<br>
<small>
(PDF presentation on how to do research in this area in preparation)
</small>
</b></h3>
<blockquote>
Some ideas about this are presented here:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/gentoa">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/gentoa</a>
<br>
And in
<a href="#sgai10">Talk 89.</a>
</blockquote>

<p>
<hr/>
<a name="talk82"></a>
<h3><b>
Talk 82:
Steps Towards a 21st Century University:
<br>
Planting Seeds ...
for a unified science
of information
</a>
<br>
<a href="sloman-awayday-10-07.pdf">Available here (PDF).</a>
</b></h3>

Presented at:
<blockquote>
Research Awayday, 21st July 2010.
Winterbourne, University of Birmingham.
<p>
Followed up by a meeting (or series of meetings) to
discuss the question:
<br>
<i>
How  can  a  genome specify an information-processing architecture
    that grows itself guided by interaction with the environment?
</i>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/genome-architecture-project.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/genome-architecture-project.html</a>

</blockquote>
<hr/>
<a name="talk81"></a>
<a name="aiib10"></a>
<h3><b>
Talk 81:
The Design-Based Approach
to the Study of Mind
<br>
(in humans, other animals, and machines)
Including the Study of Behaviour
involving Mental Processes
<br>
<a href="sloman-aiib-2010.pdf">Available HERE (PDF).</a>
</b></h3>
Presented at:
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/aiib/">Symposium
on AI-Inspired Biology</a> at AISB'2010 convention,
31st March--1st April 2010.
<p>
The proceedings paper is
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/10.html#1002">here.</a>
</blockquote>
<p>
<b>Abstract (from paper in proceedings):</b>
<blockquote>
There is much work in AI that is inspired by natural intelligence,
whether in humans, other animals or
evolutionary processes. In most of that work the main aim is to
solve some practical problem, whether the
design of useful robots, planning/scheduling systems, natural
language interfaces, medical diagnosis
systems or others.
<p>
Since the beginning of AI there has also been an interest in the
scientific study of intelligence, including
general principles relevant to the design of machines with various
sorts of intelligence, whether biologically
inspired or not. The first explicit champion of that approach to AI
was John McCarthy, though many others
have contributed, explicitly or implicitly, including Alan Turing,
Herbert Simon, Marvin Minsky, Ada Lovelace
a century earlier, and others.
<p>
A third kind of interest in AI, which is at least as old, and
arguably older, is concerned with attempting to
search for explanations of how biological systems work, including
humans, where the explanations are
sufficiently deep and detailed to be capable of inspiring working
designs. That design-based attempt to
understand natural intelligence, in part by analysing requirements
for replicating it, is partly like and partly
unlike the older mathematics-based attempt to understand physical
phenomena, insofar as there is no
requirement for an adequate mathematical model to be capable of
replicating the phenomena to be
explained: Newton's equations did not produce a new solar system,
though they helped to explain and
predict observed behaviours in the old one.
<p>
This paper attempts to explain some of the main features of the
design-based approach to understanding
natural intelligence, many of them already well known, though not
all.
<p>
The design based approach makes heavy use of what we have learnt
about computation since Ada
Lovelace. But it should not be restricted to forms of computation
that we already understand and which can
be implemented on modern computers. We need an open mind as to what
sorts of information-processing
systems can exist and which varieties were produced by biological
evolution.
</blockquote>
<p>

<hr/>
(Provisional version of Talk for SAB2010)
<br>
<a name="talk80"></a>
<a name="darwin"></a>
<h3><b>
Talk 80:
Helping Darwin:
<br>
How to Think About
Evolution of Consciousness
<p>
Or  "How could evolution get ghosts into machines?"
</b></h3>
<p>
<b>Related presentations:</b>
<ul>
<li>
<a href="#talk86">
Talk 86: Supervenience and Causation in Virtual Machinery
</a>
<li>
<a href="#talk84">Talk 84: Using virtual machinery to bridge the "explanatory gap"
<br>
  Or: Helping Darwin: How to Think About Evolution of Consciousness
<br>
  Or: How could evolution (or anything else) get ghosts into
machines?
</a>
<li>
<a href="#talk85">
Talk 85: Daniel Dennett on Virtual Machines
</a>
<li>
<a href="#talk76">Talk 76: The history, nature, and significance of virtual
machinery</a> (Aimed at computer scientists.)
</ul>
<a href="biosciences-2010.pdf">Available HERE (PDF).</a> (Superseded by
related talks)
<p>
Also on
<a href="http://www.slideshare.net/asloman/slideshows">my
'slideshare.net' web site </a>
<p>
<small>
Preview of invited talk to be presented at Le Clos Luc&eacute;,
Amboise, France at
<a href="http://www.sab2010.org/wiki">SAB2010</a> in August 2010.
<br>
(Final version of presentation to go in
<a href="#talk84">Talk 84</a>.
<br>
Conference paper is
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/10.html#sab">here.</a>
</small>
<p>
Presented at School of BioSciences Seminar, UoB, 11th May 2010
<p>
<b>Abstract</b>
<blockquote>
    Many of Darwin's opponents, and some of those who accepted the theory of
    evolution as regards physical forms, objected to the claim that human mental
    functions, and consciousness in particular, could be products of evolution.
    There were several reasons for this opposition, including unanswered
    questions as to how physical mechanisms could produce mental states and
    processes -- an old, and still surviving, philosophical problem.
<p>
    We can now show in principle how evolution could have produced the
    "mysterious" aspects of consciousness if, like engineers developing
    computing systems in the last six or seven decades, evolution "solved"
    increasingly complex problems of representation and control (including
    self-monitoring and self-control) by using systems with increasingly
    abstract mechanisms based on virtual machines.
<p>
    It is suggested that these capabilities are, like many capabilities of
    computer-based systems, implemented in non-physical virtual machines which,
    in turn, are implemented in lower level physical mechanisms. For this,
    evolution would have had to produce far more complex virtual machines than
    human engineers have so far managed, but the key idea might be the same.
<p>
    However it's not yet clear whether the biological virtual machines could
    have been implemented in the kind of discrete technology used in computers
    as we know them. These ideas were not available to Darwin and his
    contemporaries because most of the concepts, and the technology, involved in
    creation and use of sophisticated virtual machines has only been developed
    in the last half century, as a by-product of a large number of design
    decisions by hardware and software engineers.
<p>
<b>Note:</b>
Some of the ideas about evolutionary pressures from the environment
are summarised  briefly in a commentary on a 'target article' by
Margaret Boden
<a href="http://onthehuman.org/2010/05/can-computer-models-help-us-to-understand-human-creativity/">Can computer models help us to understand human creativity?</a>
<br>
My commentary is at the end of the above web page, and also copied
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/creativity-boden.html">here.</a>
<p>
<b>Note:</b> This is related to hard unsolved philosophical problems
about the concept of causation.
<p>
<b>See also:</b>
<ul>
<li>
<a href="#talk76">Talk 76</a>
<br>
Presented to Theory lab Lunch meeting on 23rd March 2010
<li>
<a href="#talk74">Talk 74</a>
<br>
Why the "hard" problem of consciousness is easy and the "easy"
problem hard.
(And how to make progress)
</ul>

</blockquote>
<p>
<hr/>
<a name="talk79"></a>
<a name="mathcog10"></a>
<a name="mathcog"></a>
<h3><b>
Talk 79:
If learning maths requires a
teacher, where did the first
teachers come from?
<br>
Why (and how) did biological evolution
produce mathematicians?
<br>
<a href="sloman-mathcog-aisb10.pdf">Available HERE (PDF).</a>
<br>
<a href="http://www.slideshare.net/asloman/evolution-euclidmathematicalcognition">Also on
Slideshare.net (Flash)</a>
</b></h3>
<p>

<blockquote>
Presented at Symposium on Mathematical Practice and Cognition, AISB
2010 Convention, Leicester, March 29-30 2010.
<br>
<a href="http://homepages.inf.ed.ac.uk/apease/aisb10/programme.html">http://homepages.inf.ed.ac.uk/apease/aisb10/programme.html</a>
<p>
Proceedings paper available
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/10.html#1001">here.</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
This is a progress report on a long term quest to defend
Kant's philosophy of mathematics. In humans, and other species with
competences that evolved to support interactions with a complex,
varied and changing 3-D world, some competences go beyond discovered
correlations linking sensory and motor signals. Dealing with novel
situations or problems requires abilities to work out what can,
cannot, or must happen in the environment, under certain conditions.
<p>
I conjecture that in humans these products of evolution form the
basis of mathematical competences. Mathematics grows out of the
ability to use, reflect on, characterise, and systematise both the
discoveries that arise from such competences and the competences
themselves. So a "baby" human-like robot, with similar initial
competences and meta-competences, could also develop mathematical
knowledge and understanding, acquiring what Kant called synthetic,
non-empirical knowledge.
<p>
I attempt to characterise the design task
and some ways of making progress, in part by analysing transitions
in child or animal intelligence from empirical learning to being
able to "work things out". This may turn out to include a very
general phenomenon involved in so-called "U-shaped" learning,
including the language learning that evolved later. Current
techniques in AI/Robotics are nowhere near this. A long term
collaborative project investigating the evolution and development of
such competences may contribute to robot design, to developmental
psychology, to mathematics education and to philosophy of
mathematics. There is still much to do.
<p>
Slightly revised version of parts of previous presentations on
closely related topics. See <a href="#toddler">below.</a>

</blockquote>
<p>
<hr/>
<a name="cas1009"></a>
<a name="talk78"></a>
<a name="everything"></a>
<h3><b>
Talk 78:
Computing:
The Science of Nearly Everything. (<a href="sloman-cas-10-04.pdf">PDF</a>)
<blockquote>
<small>
I.e. not just:
<ul>
<li> useful skills of various kinds,
<li> useful and/or entertaining applications,
<li> formal properties of computations
<li> hardware/software engineering.
</ul>
<p>
But also:
<ul>
<li> Powerful and deep new concepts and models
<li> able to illuminate many other disciplines,
<li> including studies of mind and life
<br>
(partly by raising questions never asked before).
</ul>
</small>
</blockquote>
</b></h3>

Early draft presented at
<a href="http://cas2010.eventbrite.com">Computing At School
(CAS) meeting/</a>, Microsoft Research, Cambridge, 27-28 April 2010.
<br>
Revised for
the <a href="http://www.computingatschool.org.uk/index.php?p=joining">2010
CAS Teacher Conference, Birmingham, 9th July 2010
</a>
<p>
Poster: Computing The Science of Nearly Everything
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/posters/as-cas-2010-poster.pdf">(PDF)</a>.
&nbsp;&nbsp;
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/posters/as-cas-2010-poster.ppt">(PPT - using OpenOffice).</a>
<p>
<b>NOTE:</b>
<br>
Some examples of relatively unconventional kinds of programming
(including "thinky" programming),
that could be explored by young learners, are presented here:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/examples">http://www.cs.bham.ac.uk/research/projects/poplog/examples</a>
<br>
See also Talk 87 above:
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#talk87">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#talk87</a>
<br>
Talk 87: What does AI have to do with Biology?
<p>
<b>NOTE:</b> Alan Bundy organised a seminar series at
the University of Edinburgh, on a related
theme, between 2006 and 2009.
Details:
<br>
<a href="http://www.inf.ed.ac.uk/research/programmes/comp-think/previous.html">http://www.inf.ed.ac.uk/research/programmes/comp-think/previous.html</a>
<p>
<b>Abstract</b>
<p>
Topics for possible discussion within CAS
<blockquote>
1. Do we want to broaden the scope of CAS to include:
teaching about the ways in which computing ideas and programming
experience can
illuminate other disciplines,
especially understanding natural intelligence, in humans and other
species?
<br>
[Including the nature of mind and consciousness.]
<p>
2. How do those goals affect the choice of computing/programming
concepts, techniques and principles that are relevant?
<p>
3. What are good ways to do that?
E.g. what sorts of languages and tools help and what sorts of
learning/teaching
activities?
<p>
4. Which children should learn about this?
Contrast
<br>
-- Offering specialised versions for learners interested in biology,
psychology, economics, linguistics,
philosophy, mathematics.
<br>
-- Offering a study of computation as part of a general science
syllabus.
<p>
5. Is there any scope for that within current syllabus structures,
and if not,
what can be done about making space?
</blockquote>
Why <b>nearly</b> everything?
<p>
<ul>
<li>
It is now out of date for basic education to focus on the three Rs
<li>
We need to think in terms of five Rs as key to any up to date
educational system:
<br>
Reading, Writing, Arithmetic, Programming
</ul>
<p>
<b>RELATED MATERIAL</b>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/~axs/courses/alevel-ai.html">Draft
GCE A-level syllabus for AI/Cognitive science</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/examples">Examples of 'thinky' introductory programming materials.</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/tutorials">Some
first draft experimental pod-casts on AI programming.
</a>
<br>
(Early versions with some technical problems caused by compression.)
</ul>

<p>
<hr/>
<a name="talk77"></a>
<a name="heritage"></a>
<h3><b>
Talk 77:
How to do
AI-inspired biology, as a change from biology-inspired AI.
<br>
<small>
Some thoughts about the past and future of AI as science and
philosophy
</small>
<br>
<a href="sloman-ai-heritage.pdf">Available HERE (PDF).</a>
</b></h3>
Invited talk at:
<blockquote>
<a href="http://stellar.mit.edu/S/project/aiheritage/materials.html">Workshop on AI Heritage, MIT, June 11-12, 2009</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
To be added
<p>
(Includes some personal reflections 1969-onwards.)

</blockquote>
<p>
<p>
<hr/>
<a name="talk76"></a>
<a name="theorylab"></a>
<h3><b>
Talk 76:
title
The history, nature,
and significance
of virtual machinery
<br>
<a href="theory-virtual.pdf">Available HERE (PDF).</a>
</b></h3>
Talk at:
<blockquote>
Theory lab lunch, School of computer science, Tues 23rd March 2010.

</blockquote>
<p>
<b>Abstract</b>
<blockquote>
Trying to get even computer scientists to take the ideas seriously.

<p>
<b>Related (more recent) presentations:</b>
<ul>
<li>
<a href="#talk86">
Talk 86: Supervenience and Causation in Virtual Machinery
</a>
<li>
<a href="#talk84">Talk 84: Using virtual machinery to bridge the "explanatory gap"
<br>
  Or: Helping Darwin: How to Think About Evolution of Consciousness
<br>
  Or: How could evolution (or anything else) get ghosts into
machines?
</a>
<li>
<a href="#talk85">
Talk 85: Daniel Dennett on Virtual Machines
</a>
</ul>

</blockquote>
<p>
<hr/>

<a name="talk75"></a>
<a name="dag09"></a>

<h3><b>
Talk 75:
Possibilities between form and function
<br>
Or between shape and affordances.
<br>
<a href="sloman-dagstuhl09.pdf">Available HERE (PDF).</a>
</b></h3>
Also available at Slideshare.net (flash format):
<br>
<a href="http://www.slideshare.net/asloman/possibilities-between-form-and-function-or-between-shape-and-affordances">http://www.slideshare.net/asloman/possibilities-between-form-and-function-or-between-shape-and-affordances</a>

<p>
Invited talk at:
<blockquote>
Dagstuhl Seminar: "From Form to Function" Oct 18-23, 2009
<a href="http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=09431">http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=09431</a>
<br>
A precursor talk is <a href="#dag08">here.</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
I discuss the need for an intelligent system, whether it is a robot,
or some sort of digital companion equipped with a vision system, to
include in its ontology a range of concepts that appear not to have
been noticed by most researchers in robotics, vision, and human
psychology. These are concepts that lie between (a) concepts of
"form", concerned with spatially located objects, object parts,
features, and relationships and (b) concepts of affordances and
functions, concerned with how things in the environment make
possible or constrain actions that are possible for a perceiver and
which can support or hinder the goals of the perceiver.
<p>
Those intermediate concepts are concerned with processes that *are*
occurring and processes that *can* occur, and the causal
relationships between physical structures/forms/configurations and
the possibilities for and constraints on such processes,
independently of whether they are processes involving anyone's
actions or goals.
<p>
These intermediate concepts relate motions and constraints on motion
to both geometric and topological structures in the environment and
the kinds of 'stuff' of which things are composed, since, for
example, rigid, flexible, and fluid stuffs support and constrain
different sorts of motions.
<p>
They underlie affordance concepts. Attempts to study affordances
without taking account of the intermediate concepts are bound to
prove shallow and inadequate.
<p>
<small>
A longer abstract is here
 <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/between-form-and-function.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/between-form-and-function.html</a>
</small>
<br>

</blockquote>
<p>

<hr/>
<a name="talk74a"></a>
<a name="inside"></a>
<h3><b>
Talk 74a: For Workshop: Inside and Outside of Computers and Minds
<br>
 Why robots interacting intelligently with a complex 3-D environment
will need qualia and how they can have them.
</b></h3>
<b>Filename:</b> <a href="inside-outside.pdf">inside-outside.pdf
(PDF)</a>
<br>
Date installed: 12 Mar 2010
<p>
<blockquote>
Presented Wed 10th
March 2010 at the Senate House in the Inside Outside workshop
<br>
<a href="http://graham.web-stu.dcs.qmul.ac.uk/insideOutside.xhtml">http://graham.web-stu.dcs.qmul.ac.uk/insideOutside.xhtml</a>
<p>
This is a modified version of the talk below.
</blockquote>

<hr/>
<a name="talk74"></a>
<a name="cons09"></a>
<h3><b>
Talk 74: Why the "hard" problem of consciousness is easy
and the "easy" problem hard.
<br>
(And how to make progress)
<br>
<small>
(Slides subject to revision)
</small>
<br>
<a href="consciousness-sem.pdf">Available HERE (PDF).</a>
</b></h3>
(Last changed 9 Jan 2010: added mechanisms for change detection.)
<br>
Also available on slideshare
<a href="http://www.slideshare.net/asloman/why-the-hard-problem-of-consciousness-is-easy-and-the-easy-problem-hard-and-how-to-make-progress">http://www.slideshare.net/asloman/why-the-hard-problem-of-consciousness-is-easy-and-the-easy-problem-hard-and-how-to-make-progress</a>
<br>
With other presentations
<a
href="http://www.slideshare.net/asloman/">http://www.slideshare.net/asloman/</a>.

<p>
Talk at:
<blockquote>
Language and Cognition Seminar, School of Psychology, 6 Nov 2009
<p>
<small>
(This is a sequel to <a href="#mos09">Talk 73 below, presented at
Metaphysics of Science 2009</a> on "Virtual Machines and the
Metaphysics of Science".)
<p>
I have a closely related tutorial paper on this topic destined for
<i>Int. Journal of Machine Consciousness</i>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#906">http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#906</a>
<br>
Phenomenal and Access Consciousness and the
"Hard" Problem: A View from the Designer Stance
</small>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
The "hard" problem of consciousness can be shown to be a non-problem
because it is formulated using a seriously defective concept
(the concept of "phenomenal consciousness"
defined so as to rule out cognitive functionality and causal
powers).
<p>
So the hard problem is an example of a well known type of
philosophical problem that needs to be dissolved (fairly easily)
rather than solved.
For other examples, and a brief introduction to conceptual analysis,
see
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/varieties-of-atheism.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/varieties-of-atheism.html</a>
<p>
In contrast, the so-called "easy" problem requires detailed analysis
of very complex and subtle features of perceptual processes,
introspective processes and other mental processes, sometimes
labelled "access consciousness": these have cognitive functions, but
their complexity (especially the way details change as the
environment changes or the perceiver moves) is considerable and very
hard to characterise.
<p>
"Access consciousness" is complex also because it takes many
different forms, since what individuals are conscious of and what
uses being conscious of things can be put to, can vary hugely, from
simple life forms, through many other animals and human infants, to
sophisticated adult humans,
<p>
Finding ways of modelling these aspects of consciousness, and
explaining how they arise out of physical mechanisms, requires major
advances in the science of information processing systems --
including computer science and neuroscience.
<p>
There are empirical facts about introspection that have generated
theories of consciousness but some of the empirical facts go
unnoticed by philosophers.
<p>
The notion of a virtual machine is introduced briefly and
illustrated using Conway's "Game of life" and other examples of
virtual machinery that explain how contents of consciousness can
have causal powers and can have intentionality (be able to refer to
other things).
<p>
The beginnings of a research program are presented, showing how more
examples can be collected and how notions of virtual machinery may
need to be developed to cope with all the phenomena.
</blockquote>
<p>
<hr/>
<p>
<a name="talk73"></a>
<a name="mos09"></a>
<h3><b>
Talk 73: Virtual Machines and the Metaphysics of Science
<br>
(Expanded version of presentation at:
    <a href="http://www.bristol.ac.uk/metaphysicsofscience/MoS_09/MoS_09_Programme.htm">Metaphysics of
Science'09</a>)
<br>
Available <a href="mos09-slides.pdf">here (PDF)</a>
<br>
Also available at slideshare.net (flash format)
<br>
<a href="http://www.slideshare.net/asloman/virtual-machines-and-the-metaphysics-of-science">http://www.slideshare.net/asloman/virtual-machines-and-the-metaphysics-of-science</a>
</b></h3>

<p>
<b>Related presentations:</b>
<ul>
<li>
<a href="#talk86">
Talk 86: Supervenience and Causation in Virtual Machinery
</a>
<li>
<a href="#talk84">Talk 84: Using virtual machinery to bridge the "explanatory gap"
<br>
  Or: Helping Darwin: How to Think About Evolution of Consciousness
<br>
  Or: How could evolution (or anything else) get ghosts into
machines?
</a>
<li>
<a href="#talk85">
Talk 85: Daniel Dennett on Virtual Machines
</a>
<li>
<a href="#talk76">Talk 76: The history, nature, and significance of virtual
machinery</a> (Aimed at computer scientists.)
</ul>
<p>
<b>Abstract</b>
<blockquote>
Philosophers regularly use complex (running) virtual machines (not
virtual realities) composed of enduring interacting non-physical
subsystems (e.g. operating systems, word-processors, email systems,
web browsers, and many more). These VMs can be subdivided into
different kinds with different types of functions, e.g.
"specific-function VMs" and "platform VMs" (including language VMs,
and operating system VMs) that provide support for a variety of
different (possibly concurrent) "higher level" VMs, with different
functions.
<p>
Yet, almost all ignore (or misdescribe) these VMs when discussing
functionalism, supervenience, multiple realisation, reductionism,
emergence, and causation.
<p>
Such VMs depend on many hardware and software
designs that interact in very complex ways to maintain a network
of causal relationships between physical and virtual entities
and processes.
<p>
I'll try to explain this, and show how VMs are
important for philosophy, in part because evolution long ago
developed far more sophisticated systems of virtual machinery
(e.g. running on brains and their surroundings) than human
engineers so far. Most are still not understood.
<p>
This partly accounts for the apparent intractability of several
philosophical problems.
<p>
E.g. running VM subsystems can be disconnected from input-output
interactions for extended periods, and some can have more
complexity than the available input/output bandwidth can reveal.
<p>
Moreover, despite the advantages of VMs for self-monitoring and
self control, they can also lead to self-deception.
<p>
<b>SEE ALSO:</b>
<br>
A longer abstract (and a workshop paper) here
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#vms">http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#vms</a>
<p>
For an application of these ideas to old philosophical problems of
consciousness see
<a href="#talk74">
Talk 74: Why the "hard" problem of consciousness is easy
and the "easy" problem hard.
(And how to make progress)
</a>
<p>
For an attempt to show how Darwin could have used these ideas to
provide answers to critics who claimed that evolution by natural
selection could not produce consciousness see:
<br>
<a href="#talk80">
Talk 80:
Helping Darwin:
How to Think About
Evolution of Consciousness --
Or  "How could evolution get ghosts into machines?"
</a>
<p>
For an attempt to specify a (very large and ambitious)
multi-disciplinary research project related to this see
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/genome-architecture-project.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/genome-architecture-project.html</a>
<br>
A Possible Genome To Architecture Project (GenToA)
<br>
[The Meta-Genome Project?]
<br>
How can a genome specify an information processing architecture
that grows itself guided by interaction with the environment?
</blockquote>
<p>
Some early ideas about this were in
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/crp/chap6.html">Chapter 6</a>
of
<b>The Computer Revolution in Philosophy: Philosophy
Science and Models of Mind</b>
(1978)
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/crp/">http://www.cs.bham.ac.uk/research/projects/cogaff/crp/</a>
<p>
For a lot of related material see Steve Burbeck's web site
<a href="http://evolutionofcomputing.org/Multicellular/Emergence.html">http://evolutionofcomputing.org/Multicellular/Emergence.html</a>
</blockquote>
<p>
<hr/>
<a name="talk72"></a>
<a name="unconf09"></a>
<a name="ncsl"></a>
<h3><b>
Talk 72:
Some thoughts and demos, on ways of using
computing for deep education on many topics.
<br>
<small>
As a change from teaching:
<ul>
<li>
 "useful" skills (of various kinds),
<li>
 uses of computing,
<li>
 computer science
<li>
 computer/software engineering.
</ul>
<a href="sloman-cas-unconf.pdf">Incomplete draft available HERE
(PDF).</a>
</small>
</b></h3>
<a href="http://www.slideshare.net/asloman/some-thoughts-and-demos-on-ways-of-using-computing-for-deep-education-on-many-topics">Also
on Slideshare in flash format.</a>
<p>
Invited talk at:
<blockquote>
Opensource Schools Unconference: NCSL Nottingham 20th July 2009
<br>
<a href="http://opensourceschools.org.uk/unconference09">http://opensourceschools.org.uk/unconference09</a>
</blockquote>
<p>
<p>
The theoretical ideas, using Vygotsky's notion of a "Zone of
Proximal Development" (ZPD), among other ideas, are illustrated
using teaching methods based on
<a href="http://en.wikipedia.org/wiki/POP-11">Pop-11</a>
and the Poplog AI programming environment, some illustrated here:
<a href="http://www.cs.bham.ac.uk/research/projects/poplog/freepoplog.html#teaching">http://www.cs.bham.ac.uk/research/projects/poplog/freepoplog.html#teaching</a>
<p>
<hr/>
<p>

<p>
<a name="talk71"></a>
<a name="cogsci09"></a>

<h3><b>
Talk 71: What Cognitive Scientists Need to Know about Virtual Machines.
<br>
(Presented at CogSci'09).
<br>
Alternative title: Virtual Machines and the Metaphysics of Science
(To be presented at
    <a href="http://www.bristol.ac.uk/metaphysicsofscience/MoS_09/MoS_09_Programme.htm">Metaphysics of
Science'09</a>)
<br>
<a href="cogsci09-slides.pdf">Available HERE (PDF).</a>
</b></h3>
<br>Revised version <a href="#mos09">presented at Metaphysics of Science Conference, Sept 2009</a>
<p>
Presented at
<blockquote>
<a href="http://cognitivesciencesociety.org/conference2009/">Cognitive Science
Conference 2009</a> CogSci'09, Amsterdam,
31st July 2009
<p>
There is an older presentation related to this <a href="#wpe08">here</a>
<br>
`Virtual Machines in Philosophy, Engineering & Biology" (presented at WPE 2008).
<br>
A later version aimed at computer scientists is
<a href="#talk76">Talk 76: The history, nature, and significance of virtual
machinery</a>.
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
Many psychologists, philosophers, neuroscientists and others interact with a variety
of man-made virtual machines (VMs) every day without reflecting on what that implies
about options open to biological evolution, and the implications for relations
between mind and body. This tutorial position paper introduces some of the roles
different sorts of VMs, contrasting Abstract VMs (AVMs) which are merely mathematical
objects that do nothing, and <i>running</i> instances (RVMs) which interact with
other things and have parts that interact causally. We can also distinguish single
function, specialised VMs (SVMs), e.g. a running chess game or word processor, from
"platform" VMs (PVMs), e.g. operating systems which provide support for changing
collections of RVMs. (There was no space in the paper to distinguish two sorts of
platform VMs, namely operating systems that can support actual concurrent interacting
processes, and language run-time VMs which can support different sorts of
functionality, though each instance of the language run-time VM (e.g. a Lisp VM, a
Prolog VM) may not support multiple processes.
<p>
The different sorts of RVMs play important but different roles in engineering
designs, including "vertical separation of concerns" and suggests that biological
evolution "discovered" problems that require VMs for their solution long before we
did. Some of the resulting biological VMs have generated philosophical puzzles
relating to consciousness, mind-body relations, and causation. Some new ways of
thinking about these are outlined, based on attending to some of the unnoticed
complexity involved in making artificial VMs possible.
<p>
The paper also discusses some of the implications for philosophical and cognitive
theories about mind-brain supervenience and some options for design of cognitive
architectures with self-monitoring and self-control, along with warnings about a kind
self-deception arising out of use of RVMs.
<p>
The 6 page conference paper (very compressed) is available <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#vms">here</a>.

</blockquote>
<p>
<hr/>
<p>
<a name="maggiefest"></a>
<a name="maggie"></a>
<a name="lifemind"></a>
<a href="maggiefest-aaron.pdf">
<h3><b>
Talk 70: What Has Life Got To Do With Mind? Or vice versa?
</a> (PDF)
<br>
(Thoughts inspired by discussions with Margaret Boden.)
</b></h3>
Presented at a seminar on Margaret Boden's work, Sussex University,
22 May, 2009.
<br>
Includes some reminiscences about Cognitive Science/AI at Sussex from 1965, and
a discussion of whether mind requires life, or life requires mind (defined as
information processing, or informed control).

<p>
<hr/>
<p>
<a name="talk69"></a>
<a name="fet09"></a>
<a name="fet'09"></a>
<h3><b>
Talk 69: Future Human-Like Robots: Requirements vs. Designs
<br>
<small>
Understand problems before you try to solve them
<br>
(Using iterated implementation if necessary)
</small>
<br>
<a href="sloman-fet09-robot.pdf">Available HERE (PDF).</a>
</b></h3>
Invited talk at:
<blockquote>
<a href="http://ec.europa.eu/information_society/events/cf/item-display.cfm?id=2176">Session on 'The Ultimate Robot'</a>
part of
<a href="http://ec.europa.eu/information_society/events/fet/2009/">FET'09 in Prague, April 2009.</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
I am not trying to build a robot:
I am trying to understand what problems evolution solved, how it
solved them and whether the problems can be solved on computer-based
systems.
<p>
One way of doing that is trying to build things, to find out what's
wrong with our theories and what the problems are. But it is also
necessary tp keep looking at products of evolution to compare them
with what you have achieved so far.
<p>
Moreover, many of the problems come from the structure of the
environment (e.g. the kinds of processes that do occur, that can
occur, that can be produced or prevented, and the varieties of
information that can be obtained by perceiving and acting in the
environment). Most AI/Robotics/Cognitive Science/ don't study the
environment enough.
<p>
<b>Related talks</b>
<ul>
<li>
<a href="#toddler">
Talk 67: A New Approach to Philosophy of Mathematics:
<br>
Design a young explorer, able to discover "toddler theorems"
<br>
(Or: "The Naive Mathematics Manifesto").
</a>
<p>
<li>
<a href="#prague09">
Ontologies for baby animals and robots.
<br>
From "baby stuff" to the world of adult science: Developmental AI
from a Kantian viewpoint.
</a>
<p>
<li>
<a href="#emotions">
Talk 28: Do intelligent machines, natural or artificial, really need emotions?
<br>
Revised: 14 Jan 2014
</a>
</ul>

</blockquote>
<p>
<hr/>
<p>
<a name="talk68"></a>
<a name="babystuff"></a>
<a name="brown"></a>
<a name="prague09"></a>
<a name="mm09"></a>
<h3><b>
Talk 68: Ontologies for baby animals and robots
<br>
<small>
From "baby stuff" to
the world of adult science:
Developmental AI from a Kantian viewpoint.
</small>
<p>
Latest version, presented at Brown University, on 10th June 2009
<a href="sloman-brown-slides.pdf">Available HERE (PDF).</a>
<br>
<small>
Last modified: 27 May 2010
</small>
</b></h3>
<p>
Older version (presented in Prague)
<a href="sloman-prague-09-slides.pdf">available HERE (PDF).</a>
<br>
Presented at
<blockquote>
<a href="http://dream.inf.ed.ac.uk/events/wmm-2009/">Workshop on Matching and
Meaning</a>,
at
<a href="http://www.aisb.org.uk/convention/aisb09/">AISB'09 Edinburgh 9th April 2009.</a>
<br>
at
<a href="http://cmp.felk.cvut.cz/cmp/events/colloquium-2009.04.23/">
Spring 2009 Pattern Recognition and Computer Vision Colloquium</a>
<br>
April 23, 2009
Czech Technical University,
<a href="http://cmp.felk.cvut.cz/">Center for Machine Perception</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
In contrast with ontology developers concerned with a symbolic or
digital environment (e.g. the internet), I draw attention to some
features of our 3-D spatio-temporal environment that challenge young
humans and other intelligent animals and will also challenge future
robots. Evolution provides most animals with an ontology that suffices
for life, whereas some animals, including humans, also have
mechanisms
for <i>substantive</i> ontology extension based on results of interacting
with the environment. Future human-like robots will also need this.
<p>
Since pre-verbal human children and many intelligent non-human animals,
including hunting mammals, nest-building birds and primates can
interact, often creatively, with complex structures and processes in a
3-D environment, that suggests (a) that they use ontologies that include
kinds of material (stuff), kinds of structure, kinds of relationship,
kinds of process (some of which are process-fragments composed of
bits of stuff changing their properties, structures or
relationships), and kinds of causal interaction and (b) since they
don't use a human communicative language they must use information
encoded in some form that existed prior to human communicative languages
both in our evolutionary history and in individual development. Since
evolution could not have anticipated the ontologies required for all
human cultures, including advanced scientific cultures, individuals must
have ways of achieving substantive ontology extension.
<p>
The research reported here aims mainly to develop <i>requirements</i> for
explanatory designs. The attempt to develop forms of representation, mechanisms
and architectures that meet those requirements will be a long term research
project.
</blockquote>
<p>
<hr/>
<p>
<a name="talk67"></a>
<a name="toddler"></a>
<a name="toddlers"></a>
<a name="york09"></a>
<h3><b>
Talk 67: This talk has taken several forms using slightly different
titles.
<blockquote>
Talk 67a:
Why (and how) did biological evolution produce mathematicians?
<br>
Available
<a href="sloman-toddler1.pdf">in PDF A4 Landscape Format</a>
<br>
</b>
<small>
(Title used for presentation at University of Birmingham
mathematics graduate conference 1st June 2009).
</small>
<p>
<a href="http://portal.lsri.nottingham.ac.uk/Seminars/Lists/Events/DispForm.aspx?ID=128">Presented at Nottingham LSRI Tuesday 2nd Feb 2010</a>
<br>
If learning mathematics requires a teacher, where did
the first teachers come from?
<br>
<a href="sloman-math-nottingham.pdf">Slides for the talk (PDF,
messy)</a>
<br>
<small>
<a href="mms://resources.lsri.nottingham.ac.uk/Seminar_Archive/AaronSolman_020210.wmv
">Video of the presentation at Nottingham LSRI 2nd Feb 2010.</a>
<br>
(Includes Zeyn Saigol's refutation of my rubber-band star theorem.)
</small>
<br>
Also available as a (submitted) workshop paper
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/10.html#1001">here.</a>
(Comments welcome).
<p>
<b>
Alternative title: A New Approach to Philosophy of Mathematics:
<br>
Design a young explorer, able to discover "toddler theorems"
<br>
(Or: "The Naive Mathematics Manifesto").
</blockquote>
</b></h3>
<p>
<small>
Installed 16 Dec 2008 (Updated 24 Dec 2008; 30 Jan 2009; 15 Apr
2009, 7 May 2009, 25 May 2010)
</small>
<p>
<blockquote>
Invited talk at Mathematics Graduate conference, June 2009
<p>
Invited talk at York CS department Wed 6th May 2009,
(combined with part of talk on
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/gc/">UKCRC Grand Challenge
5</a>)
<br>
Previously presented at
CISA seminar, Informatics, Edinburgh, Wed 8th April 2009.
<br>
At a joint meeting of the Language and Cognition
Seminar and the Vision Club,
<br>School of Psychology, University
of Birmingham, Friday
12th
December 2008
<a name="sussex08"></a>
<p>
<b>Presentation at Sussex University</b>
<br>
An earlier version of the above talk on development of mathematical
competences was given at University of Sussex, Tuesday 9th December
2008
<blockquote>
The PDF slides for the Sussex presentation are
<a href="sussex-math-orig.pdf">here.</a>
<br>
The presentation at Sussex, including part of the discussion,
was recorded
<br>
on video by Nick Hockings and he kindly made the resulting
<br>
video available online (in three resolutions).
<p>
That is temporarily
unavailable, but the medium resolution version is available
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/#sussex08">here.</a>

<p>
A link will be added here when Nick has found a new location.

<p>
Michael Brooks, a journalist who was present at the Sussex
presentation wrote a report for the New Scientist
 <a href="http://www.newscientist.com/article/mg20126971.800-rise-of-the-robogeeks.html">here</a>.
<br>
Unfortunately someone very silly at New Scientist gave it a totally
inappropriate headline
<br>
and misrepresented my claims as being to make a mathematical robot,
as
opposed to understanding
<br>
human mathematical competences and their
biological origins.
<br>
(I don't think
it was Michael Brooks as he seemed to understand what I was saying.)
</blockquote>
<P>
NOTE:
The slides were much revised between the successive presentations.
<br>
Some versions start with a fairly detailed example experimental
domain,
<br>
concerned with shapes that can and cannot be made with a rubber band
and pins.
<br>
Later versions start with an introductory overview on the evolution
of cognition.
<p>
<b>Previous versions</b>
<br>
The talks above build on and overlap with earlier presentations:
<small>
<p>
<ul>
<li>
Could a Child Robot Grow Up To be A Mathematician
And Philosopher?
<br>
Talk at University of Liverpool, 21st Jan 2008
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks#math-robot">http://www.cs.bham.ac.uk/research/projects/cogaff/talks#math-robot</a>
<p>
<li>
Could a Baby Robot Grow up to be a Mathematician
and Philosopher?
<br>
Presented at 7th International Conference on Mathematical Knowledge
Management (MKM'08)
<br>
University of Birmingham, 29 Jul 2008
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#mkm08">http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#mkm08</a>
<br>
Conference paper available online:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0802">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0802</a>
<br>
 Kantian Philosophy of Mathematics and Young Robots
<p>
A related, much longer, journal paper is
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0807">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0807</a>
<br>
The Well-Designed Young Mathematician,
In
<i>Artificial Intelligence</i>
(December 2008)
<br>
Official site: <a href="http://dx.doi.org/10.1016/j.artint.2008.09.004">http://dx.doi.org/10.1016/j.artint.2008.09.004</a>
</ul>
</small>
There are also connections with the ideas on learning and development in the
work of Piaget and Karmiloff-Smith, and the examples of "toddler theorems"
presented in:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/toddler-theorems.html</a>
</blockquote>
<b>Abstract</b>
<blockquote>

<b>Main theses</b>
<ul>
<li>
Humans (and perhaps other species) can acquire various kinds of
information about the environment <i>empirically</i> then develop a
new <i>derivation</i> of the information giving it a wholly or
partially non-empirical status -- and a kind of necessity.
<p>
<li>
The forms of representation, perceptual and other mechanisms, and
information-processing architecture that make the second step
possible evolved to meet requirements imposed by complex and
changing environments, including other intelligent individuals.
<p>
<small>
I'll try to show how this is important for the ability to
produce creative solutions to novel problems, without having to do
statistical learning/testing.
</small>
<p>
<li>
The competences required for this are not all present at birth:
they have to develop in layers (Chappell &
Sloman 2007)[*].
<p>
<li>
Those biological competences provide the basis of the ability to do
mathematics, and some of that ability exists unrecognized even in
toddlers.
<p>
<small>
I'll introduce the notion of a "toddler theorem" and give
examples.
</small>
<p>
<li>
Understanding the biological origins of mathematical competences
provides support for Kant's philosophy of mathematics, wrongly
thought to have been refuted by discovery that physical space is
non-Euclidean.
</ul>

<small>
[*]
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0609">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0609</a>
<br>Natural and artificial meta-configured altricial
information-processing systems, IJUC 2007
</small>
</blockquote>
<p>
<hr/>
<p>
<a name="talk66"></a>
<a name="wpe08"></a>
<h3><b>
Talk 66: Virtual Machines in Philosophy, Engineering & Biology (at WPE 2008)
<br>
<a href="wpe-08.pdf">Available in PDF format (A4 Landscape).</a>
</b></h3>
A version (using 'flash') is also available on
<a href="http://www.slideshare.net/asloman/slideshows">my 'slideshare.net'
space.</a>

<small>
<a href="#cogsci09">A more recent version of this</a>
was presented at CogSci'09 (31 July 2009) "What cognitive scientists
need to know about virtual machines".
<br>
A later version aimed at computer scientists is
<a href="#talk76">Talk 76: The history, nature, and significance of virtual
machinery</a>.
</small>

<blockquote>
Presented 11th November 2008 at <a
href="http://www.illigal.uiuc.edu/web/wpe/program/">The Workshop on
Philosophy and Engineering</a> (WPE 2008), 10-12 November 2008,
Royal Academy of Engineering, London.
<p>
<small>
Longer version available above in
<a href="#talk64">Talk 64 on virtual machines.</a>
<p>
A 6 page paper on this, accepted for CogSci'09 (Amsterdam, July-Aug
2009) is available here:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#vms">
"What Cognitive Scientists Need to Know about Virtual Machines"
</a>

</small>
</blockquote>
<p>
<hr/>
<p>
<a name="talk65"></a>
<a name="oldbabystuff"></a>
<h3><b>
Talk 65: Superseded talk on: Assembling bits of stuff and bits of process,
<br>
in a baby robot's world
<br>
<small>
A Kantian approach to robotics and developmental psychology.
</small>
</b></h3>
This is now superseded by <a href="#babystuff"><b>a newer version presented in May 2009.</b></a>
<br>
<a href="baby-stuff.pdf">Old version Available HERE (PDF).</a>
<blockquote>
</blockquote>
<p>
Originally intended as talk at:
<blockquote>
Kickoff workshop for
<a href="http://www.cs.bham.ac.uk/research/projects/cogx/">the CogX project</a>
(29 September to 3rd October, 2008, Portoroz, Slovenia)
<br>
But insufficient time was available to present the material.
<p>
Later slides, extending the material can be found in
<a href="#talk67">Talk 67</a> on toddler theorems, and
<a href="#talk68">Talk 68</a> on ontologies for baby animals and
robots.
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
These slides are based on the observation that current machine
perceptual abilities and machine manipulative abilities are extremely
limited compared with what humans and many other animals can do.
<p>
There are mobile robots that are impressive as engineering products,
e.g.
<a href="http://www.bostondynamics.com/content/sec.php?section=BigDog">BigDog -- the Boston dynamics robot</a>
and some other mobile robots that are able to keep moving in fairly
rough terrain, including in some cases moving up stairs or over very
irregular obstacles.
<p>
However, they all seem to lack any understanding of what they are doing,
or the ability to achieve a specific goal despite changing obstacles,
and then adopt another goal.
<small>
For more detailed examples of missing capabilities see these web sites
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/challenge.pdf">http://www.cs.bham.ac.uk/research/projects/cogaff/challenge.pdf</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/photos/crane">http://www.cs.bham.ac.uk/research/projects/cosy/photos/crane</a>
</ul>
</small>
<p>
As far as I know, none of the existing robots that manipulate objects
can perceive what is possible in a situation when it is not happening,
and reason about what the result would be if something were to happen.

<p>
Neither can they reason about why something is not possible.

<p>
I.e. they lack the abilities underlying the perception of positive and
negative affordances.
<p>

They cannot wonder why an action failed, or what would have happened
if..., or notice that their action might have failed if so and so had
occurred part way through, etc., or realise that some information was
available that they did not notice when they could have used it.

</blockquote>
<p>
<hr/>
<p>
<a name="talk64"></a>
<a name="virt"></a>
<h3><b>
Talk 64: Why virtual machines really matter -- for several disciplines
<br>
(Or, Why philosophers need to be robot designers)
<br>
<a href="bio-information.pdf">Available HERE (PDF) (A4 landscape).</a>
</b></h3>
Also available compressed for printing:
<a href="bio-information-2x2.pdf">4 pages per A4 sheet</a>
<p>
A more recent version of this, aimed mainly at philosophers, is
<a href="#mos09">Talk 73: Virtual Machines and the Metaphysics of
Science</a>.
<p>
A much shorter version was presented at
<a href="http://www.illigal.uiuc.edu/web/wpe/program/">The
2008 Workshop on Philosophy and Engineering</a>.
<br>
(10-12 Nov 2008, Royal Academy of Engineering, London).
The slides for that are <a href="#wpe08">here.</a>
Abstract
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/wpe-abstract-sloman.pdf">here.</a>
<p>
Previously presented at:
<ul>
<li>
Mind as
Machine, Continuing Education Weekend
Course, with Margaret Boden, Oxford 1-2 Nov 2008
<br>
<small>
(No link available: they remove past courses from their web site for
some reason.)
</small>
<blockquote>
I gave two presentations for which the slides are available below,
as follows
<ul>
<li>
<b>Talk A Saturday 1st November</b>
<br>
<a href="#virt">
Why virtual machines really matter -- for several disciplines</a>
<br>
  (Or, Why philosophers need to be robot designers)
<p>
<small>
A <a href="#wpe08">much shorter version</a> was presented
at the
<a href="http://www.illigal.uiuc.edu/web/wpe/program/">Workshop on Philosophy and
Engineering (WPE)</a>
London 10-12 November 2008, also on slideshare.net.
</small>
<p>
<li>
<b>Talk B Sunday 2nd November</b>
<br>
<a href="#glang">Evolution of minds and languages.</a>
<br>
What evolved first and develops first in children:
<br>
 Languages for communicating, or languages for thinking (Generalised
Languages: GLs)
</ul>
</blockquote>
<p>
<li>
<a href="http://thegreatdebate.org.uk/UnnoticedConnections.html">Newcastle 'Great Debate'</a>
21st Oct 2008
<p>
<li>
School of Computer Science (open) Seminar 16th Oct 2008.
<br>
University of Birmingham.
</ul>

This is a revised, extended version of parts of previous
presentations on virtual machines, information, and architectures,
including

<ul>
<li>
<a href="#talk51">
Talk 51: Why robot designers need to be philosophers -- and vice versa
<br>
Presentation at University of Bielefeld on 10th October 2007
</a>
<li>
<a href="#inf">Talk 26: WHAT ARE INFORMATION-PROCESSING MACHINES?
WHAT ARE INFORMATION-PROCESSING VIRTUAL MACHINES?
</a>
<li>
<a href="#talk12">Talk 12: SUPERVENIENCE AND IMPLEMENTATION</a>

<p>
For an introduction to biological virtual machines that grow
themselves in layers as a result of interacting with the environment
see
<a href="wonac/metaconfig.pdf">these draft slides.</a>

</ul>
<p>
<b>Abstract</b>
<blockquote>
One of the most important ideas (for engineering, biology, neuroscience,
psychology, social sciences and philosophy) to emerge from the
development of computing has gone largely unnoticed, even by many
computer scientists, namely the idea of a running virtual machine (VM)
that
acquires, manipulates, stores and uses information to make things
happen.
<p>
The idea of a VM as a mathematical abstraction is widely
discussed, e.g. a Turing machine, the Java virtual machine, the Pentium
virtual machine, the von Neumann virtual machine. These are abstract
specifications whose relationships can be discussed in terms of mappings
between them. E.g. a von Neumann VM can be implemented on a
Universal Turing Machine. An abstract VM can be analysed
and talked about, but, like a mathematical proof, or a large number, it
does not {\bf do} anything. The processes discussed in relation to
abstract
VMs do not occur in time: they are mathematical
descriptions of processes that can be mapped onto descriptions of other
processes. In contrast a physical machine can consume, transform,
transmit, and apply energy, and can produce changes in matter. It can
make things happen. Physical machines (PMs) also
have abstract mathematical
specifications that can be analysed, discussed, and used to make
predictions, but which, like all mathematical objects cannot do
anything.
<p>
But just as instances of designs for PMs can do things
(e.g. the engine in your car does things), so can instances of designs
for VMs do things: several interacting VM
instances do things when you read or send email, browse the internet,
type text into a word processor, use a spreadsheet, etc. But those
running VMs, the active instances of abstract VMs, cannot be observed
by opening up and peering into or measuring
the physical mechanisms in your computer.
<p>
My claim is that long before humans discovered the importance of active
virtual machines (AVMs), long before humans even existed, biological
evolution produced many types of AVM, and thereby solved many hard
design problems, and that understanding this is important (a) for
understanding how many biological organisms work and how they develop
and evolve, (b) for understanding relationships between mind and brain,
(c) for understanding the sources and solutions of several old
philosophical problems, (d) for major advances in neuroscience, (e) for
a full understanding of the variety of social, political and economic
phenomena, and (e) for the design of intelligent machines of the future.
In particular, we need to understand that the word "virtual" does not
imply that AVMs are unreal or that they lack causal powers, as some
philosophers have assumed. Poverty, religious intolerance and economic
recessions can occur in socio-economic virtual machines and can clearly
cause things to happen, good and bad. The virtual machines running on
brains, computers and computer networks also have causal powers. Some
virtual machines even have desires, preferences, values, plans and
intentions, that result in behaviours. Some of them get philosophically
confused when trying to understand themselves, for reasons that will be
explained. Most attempts to get intelligence into machines ignore these
issues.
</blockquote>
<p>
<hr/>
<p>
<li>
<a name="mkm08"></a>
<a name="talk63"></a>
<h3><b>
Talk 63: Kantian Philosophy of Mathematics and Young Robots
<br>
Could a baby robot grow up to be
a Mathematician and Philosopher?
</b></h3>
See also
<a href="#toddlers">
Talk 67: A New Approach to Philosophy of Mathematics:
Design a young explorer, able to discover "toddler theorems"
</a>
<br>
<small>
(This starts with more examples.)
</small>
<p>

<b>Available <a href="sloman-mkm08.pdf">in PDF format.</a></b>
<br>
A version (using 'flash') is also available on
<a href="http://www.slideshare.net/asloman/slideshows">my 'slideshare.net'
space.</a>

<blockquote>
Talk
at
7th International Conference on Mathematical Knowledge Management
Birmingham, UK, 28-30 July 2008
<br>
<a href="http://events.cs.bham.ac.uk/cicm08/mkm08/">http://events.cs.bham.ac.uk/cicm08/mkm08/</a>
<br>
University of Birmingham, 29 Jul 2008
<p>
Proceedings paper online here
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0802">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0802</a>
<br>
Kantian Philosophy of Mathematics and Young Robots
</blockquote>
        <b>ABSTRACT:</b>
<blockquote>
A child, or young human-like robot of the future, needs to develop an
information-processing architecture, forms of representation, and
mechanisms to support perceiving, manipulating, and thinking about the
world, especially perceiving and thinking about actual and possible
structures and processes in a 3-D environment. The mechanisms for
extending those representations and mechanisms, are also the core
mechanisms required for developing mathematical competences, especially
geometric and topological reasoning competences. Understanding both the
natural processes and the requirements for future human-like robots
requires AI designers to develop new forms of representation and
mechanisms for geometric and topological reasoning to explain a child's
(or robot's) development of understanding of affordances, and the
proto-affordances that underlie them. A suitable multi-functional
self-extending architecture will enable those competences to be
developed. Within such a machine, human-like mathematical learning will
be possible. It is argued that this can support Kant's philosophy of
mathematics, as against Humean philosophies. It also exposes serious
limitations in studies of mathematical development by psychologists.
<p>
See also
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#talk56">Talk 56</a>
and
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0807">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0807</a>
<br> The Well-Designed Young Mathematician
<br/
(To appear in <i>Artificial Intelligence</i>, December 2008.)

</blockquote>
</blockquote>
<p>

<hr/>
<p>
<a name="talk62"></a>
<a name="aaai08"></a>
<h3><b>
Talk 62: Varieties of Meta-cognition in Natural and Artificial Systems
<br>
<small>
Some pressures on design-space
from niche-space
</small>
<br>
<a href="sloman-aaai08-ws07.pdf">Available HERE (PDF)</a>
</b></h3>

Invited talk at
                <a href="http://www.sis.uncc.edu/~anraja/Metareasoning/">Workshop on
                MetaReasoning: Thinking about Thinking</a>
                at <a href="http://www.aaai.org/Conferences/AAAI/aaai08.php">AAAI'08,</a>
                <br>
                Washington, 13-14 July 2008.
            <P>
            The paper for the proceedings is available at
            <br> <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/08.html#805">http://www.cs.bham.ac.uk/research/projects/cogaff/08.html#805</a>
<br>
and
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0802">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0802</a>


<b>ABSTRACT:</b>
<blockquote>
Some AI researchers aim to make useful machines,
including robots. Others aim to understand general principles of
information-processing machines whether natural or artificial, often
with special emphasis on humans and human-like systems: They primarily
address scientific and philosophical questions rather than practical
goals. However, the tasks required to pursue scientific and engineering
goals overlap considerably, since both involve building working systems
to test ideas and demonstrate results, and the conceptual frameworks and
development tools needed for both overlap. This paper, partly based on
requirements analysis in the CoSy robotics project, surveys varieties
of meta-cognition and draws attention to some types that appear to play
a role in intelligent biological individuals (e.g. humans) and which
could also help with practical engineering goals, but seem not to have
been noticed by most researchers in the field. There are
important implications for architectures and representations.
</blockquote>

<p>
<hr/>
<p>
<a name="talk61"></a>
<a name="biosem"></a>
<h3><b>
Talk 61: Evolution, development and modelling of architectures for intelligent organisms and robots.
<br>
<a href="bio-sem-08.pdf">Available HERE (PDF)</a>
</b></h3>
<blockquote>
Talk for Graduate School Seminar series,
Biosciences, University of Birmingham,
on 24th June 2008.
</blockquote>
<p>

<hr/>
<p>
<a name="talk60"></a>
<h3><b>
Talk 60: Requirements for a Human-like Information Processing Architecture that Builds Itself
by Interacting with a Rich Environment
<br>
Available
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/ucs2008.html">
in HTML format
</a>
and
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/ucs-2008-online.pdf">
in PDF format
</a>
</b></h3>
<blockquote>
Given on 9th June, at
<a href="http://events.cs.bham.ac.uk/cci-env08/">Birmingham
Informatics CRN Workshop on Complexity and Critical Infrastructures
- Environment focus.
</a>
<br>
and earlier (May 13th 2008) at UIUC Complexity conference
on
    <a href="http://www.howhy.com/ucs2008/">
    Understanding Complex Systems
</a>
</blockquote>
<p>
<hr/>
<p>
<a name="talk59"></a>
<a name="dagstuhl08"></a>
<a name="dag08"></a>
<h3><b>
Talk 59: Understanding the Functions of Animal Vision What Are We Trying To Do:
<br>
How Do Logic And Probability
Fit Into The Bigger Picture?
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/dag08/dagstuhl-slides.pdf">Available HERE (PDF)</a>
<small>
Warning: there seems to be an out of date version on citeseer.
</small>
</b></h3>

Invited talk at:
<blockquote>
<a href="http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=08091">Dagstuhl Seminar No. 08091, 24.02.2008-29.02.2008</a>
<br>
Logic and Probability for Scene Interpretation.
Schloss
<br>
Dagstuhl, Feb 25th 2008
<p>
<b>NOTE:</b> a sequel to this talk is available
<a href="#dag09">here.</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/dag08/">http://www.cs.bham.ac.uk/research/projects/cogaff/dag08/</a>
</blockquote>
<p>
<hr/>
<p>
<a name="talk58"></a>
<a name="aisb08"></a>
<h3>
<b>
Talk 58: What designers of artificial companions need to understand about biological ones.
<br>
<a href="aisb08-public.pdf">Expanded slides available HERE (PDF)</a>
</b>
</h3>
<blockquote>
Invited Presentation at
<a href="http://www.aisb.org.uk/convention/aisb08/invited.html#pubLect">Public Session of AISB'08,</a>
<br>
3rd April 2008, Aberdeen, Scotland
</blockquote>
<p>
<b>
Abstract
</b>
<br>
The talk aims to:
<ul>
<li>
Present some examples (using videos) of biological competences in
children and other animals.

<li> Discuss some of the requirements for artificial companions
(ACs).
<li> Distinguish relatively easy (Type 1) goals and much
harder, but more important, (Type 2) goals for designers of ACs
goals.
<li> Assert that current techniques will not lead to
achieving the hard goals.
<li> Suggest ways of moving towards
achieving the hard goals, by looking more closely at features of how
the competences develop in humans, and their architectural and
representational requirements.
<li> In particular there is a lot of
knowledge about the space and structures and processes in space that
a young child develops (some of it shared with some other animals)
that forms part of the basis of a lot of later learning.
<li> No AI
systems are anywhere near the competences of young children.
<li>
Trying to go directly to systems with adult competences, especially
statistics based systems, will produce systems that are either very
restricted, or very brittle and unreliable (or both).
</ul>

<p>
<hr/>
<p>
<a name="talk57"></a>
<a name="seeposs"></a>
<h3><b>
Talk 57: Seeing Possibilities: A new view of Empty Space
<br>
<a href="seeing-poss.pdf">Available HERE (PDF)</a>
</b></h3>
<p>
<blockquote>
Talk at: Intelligent Robotics Lab Seminar, Birmingham, 22nd
Jan 2008
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
A short history of AI vision research, introducing 'Generalised
Gibsonianism (GG)', which allows for 'Proto-affordances' and use of
vision in planning, reasoning and problem solving, based on seeing
and manipulating possibilities.
Closely related to
<a href="#talk56">Talk 56.</a>
</blockquote>
<p>
<hr/>
<p>
<a name="talk56"></a>
<a name="math-robot"></a>
<h3><b>
Talk 56: Could a Child Robot Grow Up To be A Mathematician And Philosopher?
<br>
<a href="robot-mathematician.pdf">Available HERE (PDF)</a>
</b></h3>
Invited talk at:
<blockquote>
<a href="http://www.liv.ac.uk/philosophy/mathsandscience/">Thinking about Mathematics and Science Seminar,</a>
University of
Liverpool. Monday 21 January 2008.
<p>
Some old problems going back to Immanuel Kant (and earlier) about
the nature of mathematical knowledge can be addressed in a new
way by asking (a) what sorts of developmental changes in a human
child make it possible for the child to become a mathematician,
and (b) how this could replicated in a robot that develops through
exploring the world, including its own exploration of the world.
<p>
This is relevant not only to philosophy of mathematics,
developmental psychology, and robotics, but also to a future
mathematical education strategy based on much deeper ideas about
what a mathematical learner is than are available to current
educators. How many educators could design and implement a learner?


<p>
The slides have been substantially expanded since the talk, partly
in the light of comments and criticisms received. This process is
likely to continue. There are partial overlaps with several other
talks here.
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
<a href="http://www.cs.bham.ac.uk/~axs/liv.html">The original
abstract is here.</a>
<p>
A conference paper summarising some of the issues is here
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0802">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0802</a>
<br>
Kantian Philosophy of Mathematics and Young Robots
<p>
See also
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#talk67">Talk 67</a>
</blockquote>
</blockquote>
<p>
<hr/>
<p>
<a name="talk55"></a>
<h3><b>
Talk 55: Why Some Machines May Need Qualia and How They Can Have Them: Including a Demanding New Turing Test for Robot Philosophers
<br>
<a href="sloman-aaai07-consc.pdf">Available HERE (PDF)</a>
</b></h3>
Invited talk at:
<blockquote>
Symposium on
<a href="http://www.consciousness.it/CAI/CAI.htm"> AI and
Consciousness: Theoretical Foundations and Current Approaches
</a>
<br>
at
        <a href="http://www.aaai.org/Symposia/Fall/fss07symposia.php#fs01">
AAAI Fall Symposium,
Washington, 9-11 November 2007
</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
See online paper
http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0705
</blockquote>
<p>
<hr/>
<p>
<a name="talk54"></a>
<a name="devrep"></a>
<h3><b>
Talk 54: Diversity of Developmental Trajectories
 in Natural and
 Artificial Intelligence
<br>
<a href="sloman-aaai07-devrep.pdf">Available HERE (PDF)</a>
</b></h3>
Invited talk at:
<blockquote>
Symposium on
<a href="http://yertle.isi.edu/~clayton/aaai-fss07/">
Computational Approaches to Representation Change
During Learning and Development
</a> at AAAI Fall Symposium, Washington November 2007
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
See the full paper
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0704">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0704</a>
</blockquote>
<p>
<hr/>
<p>
<a name="talk53"></a>
<a name="oii"></a>
<h3><b>
Talk 53: Requirements for Digital Companions and their implications:
It's harder than you think
<br>
<a href="sloman-oii-slides.pdf">Available HERE (PDF)</a>
</b></h3>
<p>
Invited talk at:
<blockquote>
<a href="http://www.oii.ox.ac.uk/">University of Oxford Internet Institute,</a>
26 Oct 2007
<br>
Workshop on
Artificial Companions in Society: Perspectives on the Present and
Future
Oxford 25th--26th October, 2007
<br>
Organised by <a href="http://www.companions-project.org/">The
Companions Project</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
For the position paper see (revised version, published in
2010 in a book based on the workshop):
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#oii">http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#oii</a>
<br>
An early draft of the chapter is here:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#711">http://www.cs.bham.ac.uk/research/projects/cogaff/07.html#711</a>

</blockquote>
<p>
<hr/>
<p>
<a name="talk52"></a>
<a name="glang"></a>
<a name="glang-ai"></a>

<h3><b>
<font color="blue">
Please see the latest presentation of these ideas above <a href="#talk111">Talk111</a>
</font>
<br>
Talk 52: Evolution of minds and languages.
<br>
What evolved first and develops first in children:
<div style="margin-left:15px; margin-top:0px; margin-bottom:0px;">
 Languages for communicating, or
<br>
 languages for thinking (Generalised Languages: GLs)?
</div>
(Partly superseded by <a href="#talk111">Talk 111 on language and vision,
above.</a>)
<br>
Available in PDF format:
<a href="glang-evo-ai1.pdf">Reorganised 21 Mar 2014</a>
<br>
Also available
<a href="glang-evo-ai1-2x2.pdf">four slides per page (2x2 PDF)) </a>
</b></h3>
A revised version (using 'flash') is also available on
<a href="http://www.slideshare.net/asloman/slideshows">my 'slideshare.net'
space.</a>

<blockquote>
Originally for Birmingham Language and Cognition seminar, School of Psychology,
Oct 2007
<br>
Also presented at
<a href="http://www.conted.ox.ac.uk/courses/details.php?id=O08P107PHR">Mind as
Machine, Continuing Education Weekend
Course</a> Oxford 1-2 Nov 2008
</blockquote>

<p>
<b>Abstract</b>
<blockquote>
Investigating the evolution of cognition requires an understanding
of how to design working cognitive systems since there is very
little direct evidence (no fossilized behaviours or thoughts).
<p>
That claim is illustrated in relation to theories about the
evolution of language. Almost everyone seems to have got things
badly wrong by assuming that language must have started as primitive
communication between individuals that gradually got more complex,
and then later somehow got absorbed into cognitive systems.
<p>
An alternative theory is presented here, namely that generalised
languages (GLs) supporting (a) structural variability, (b)
compositional semantics (generalised to include both diagrammatic
syntaxes and contextual influences on semantics at every level) and
(c) manipulability for reasoning, evolved <i>first</i> for various
kinds of 'thinking', i.e. internal information processing. This is
inconsistent with many theories of the evolution of language. It is
also inconsistent with Dennett's account of the evolution of
consciousness in
<i>Content and Consciousness</i> (1969).
<p>
See the slides for more detail.
<p>
A earlier presentation in the School of Computer Science, in March
2007 is closely related to this:
<blockquote>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0702">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0702</a>
(PDF)
<br>
What is human language?
How might it have evolved?
</blockquote>
This work based on collaboration with Jackie Chappell. See also
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0703">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0703</a>
<br>
'Computational cognitive epigenetics'
<br>
A. Sloman and J.Chappell (BBS 2007)
</blockquote>
<p>
<hr/>
<p>
<a name="talk51"></a>
<h3><b>
Talk 51: Why robot designers need to be philosophers -- and vice versa
<br>
Available
<a href="bielefeld07.pdf">
in PDF format</a>
</b></h3>
Presentation at University of Bielefeld on 10th October 2007
<blockquote>
Short talk at the
<a href="http://www.cor-lab.de/eng/symposium.php">
Inauguration ceremony of the "Research Institute for Cognition and
Robotics - CoR-Lab"
</a>
<blockquote>
<small>
This is an expanded version of the slides. Part of the argument is
that control of complex systems, including complex robots, and
animals, can be usefully mediated by virtual machines.
<p>
Where such a virtual machine also acquires and uses information
about itself this can be useful, but it can also lead to the machine
becoming philosophical and getting confused.
<p>
A much expanded version of these slides is in
<a href="#talk64">Talk 64: Why virtual machines really matter -- for several disciplines</a>
</small>
</blockquote>
</blockquote>
<p>
<hr/>
<p>
<a name="talk50"></a>
<a name="mofm-07"></a>
<h3><b>
Talk 50: Understanding causation in robots, animals and children:
Hume's way and Kant's way.
<br>
<small>
(Includes some methodological background and biological
conjectures.)
</small>
</b></h3>
<b>
Available here, in PDF format, with videos
<small>
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/conferences/mofm-paris-07/sloman">http://www.cs.bham.ac.uk/research/projects/cosy/conferences/mofm-paris-07/sloman</a>
<li>
<a href="sloman-mofm-paris.pdf">PDF slides.</a>
</ul>
</small>
</b>
Presentation at
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/conferences/mofm-paris-07/">
CoSy
MeetingOfMinds Workshop,
</a>
Paris, Sept 2007
<p>
<hr/>
<p>
<a name="talk49"></a>
<a name="models"></a>
<h3><b>
Talk 49: Why symbol-grounding is both impossible and unnecessary,
    and why theory-tethering is more powerful anyway.
<br>
(Introduction to key ideas of semantic models,
implicit definitions and symbol tethering through theory tethering.)
<br>
Available in <a href="models.pdf">PDF Format</a>
</b></h3>
Also available on
<a href="http://www.slideshare.net/asloman/slideshows">'slideshare.net'</a>
(possibly an older version)
<br>
Date Added: 23 Sep 2007
<br>
Revised: 30 Nov 2007, 16 Jun 2008, 7 Jan 2010
<p>
This is a revised, clarified and expanded version
of a <i>part</i> of <a href="#talk14">Talk 14, on Symbol Grounding
vs Symbol Tethering</a>.
<p>
Revised after presentation at the University of Sussex 27 Nov
2007, and University of Birmingham 29 Nov 2007
<p>
Also listed as COSY-PR-0705 on
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0705">CoSy web site.</a>
<p>
<b>Abstract</b>
<blockquote>
This is, like <a href="#talk14">Talk 14</a>, an attack on concept
empiricism, including its recently revived version, "symbol
grounding theory".
<p>
The idea of an axiom system having some models is explained more
fully than in previous presentations, showing how the structure of a
theory can give some semantic content to undefined symbols in that
theory, making it unnecessary for <i>all</i> meanings to be derived
bottom up from (grounded in) sensory experience, or sensory-motor
contingencies. Although symbols need not be grounded, since they are
mostly defined by the theory in which they are used, the theory does
need to be "tethered", if is capable of being used for predicting
and explaining things that happen, or making plans for acting in the
real world. These ideas were quite well developed by 20th Century
philosophers of science, and I now both attempt to generalise those
ideas to be applicable to theories expressed using non-logical
representations (e.g. maps, diagrams, working models, etc.) and
begin to show how they can be used in explaining how a baby or a
robot, can develop new concepts that have some semantic content but
are not definable in terms of previously understood concepts. There
is still much work to be done, but what needs to be done to explain
how intelligent robots might work, and how humans and other
intelligent animals learn about the environment, is very different
from most of what is going on in robotics and in child and animal
psychology.
<p>
The addition of new explanatory hypotheses is abduction. Normally
abduction uses pre-existing symbols. The simultaneous introduction
of new symbols and new axioms (ontology-extending abduction)
generates a very difficult problem of controlling search.
<p>
<a href="http://www.cs.bham.ac.uk/events/seminars/seminar_details.html?seminar_id=449">Advertised
abstract for Birmingham talk.</a>
<p>
See also this discussion on
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/whats-information.html">What's
information?</a>, and the ideas about virtual machine functionalism,
<a href="#inf">here.</a>
</blockquote>
<p>
<hr/>
<p>
<a name="enf07"></a>
<a name="talk48"></a>
<h3><b>
Talk 48: Machines in the ghost
<br>
Available in
<a href="sloman-enf07-slides.pdf">PDF format.</a>
</b></h3>

<blockquote>
Invited talk at
<a href="http://www.indin2007.org/enf/">ENF'2007, Emulating the
Mind</a>
<br>
1st international Engineering and Neuro-Psychoanalysis Forum
<br>
Vienna July 2007
<p>
The full paper is available
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0702">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0702</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
This paper summarises a subset of the ideas I have been working on over
the last 35 years or so, about relations between the study of natural
minds and the design of artificial minds, and the requirements for both
sorts of minds.
<p>
The key idea is that natural minds are information-processing machines
produced by evolution. We still do not have a good understanding of
what the problems were that evolution had to solve, nor what the
solutions were: e.g. we do not know how many different kinds of
information processing system evolution produced, nor what they are
used for -- even in ourselves.
<p>
What sort of information-processing machine a human mind is requires
much detailed investigation of the many kinds of things minds can <i>do</i>.
<p>
It is not clear whether producing artificial minds with
similar powers will require new kinds of computing machinery or merely
much faster and bigger computers than we have now. Having been
studying the problems of visual perception for many years I don't
believe that any model proposed so far, whether based on
conventional computation, neural computation, or anything else is
capable of explaining the phenomena of human visual perception,
including what it achieves, how fast it achieves it, how it develops
and how many non-visual tasks the visual system is used for (e.g.
doing mathematics).<a href="#challenges">[*]</a>
<p>
Insofar as some sorts of psychotherapy (including psychoanalysis)
are analogous to run-time debugging of a virtual machine, in order
to do them well, we need to understand the architecture of the
machine well enough to know what sorts of bugs can develop and which
ones can be removed, or have their impact reduced, and how.
<p>
Otherwise treatment will be a hit-and-miss affair.
<p>
This requires understanding how minds work when they don't
need therapy -- a distant goal.
<br>
<br>
<a name="challenges">[*]</a>
<small>
Some challenges for vision researchers are here:
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/challenge.pdf">http://www.cs.bham.ac.uk/research/projects/cogaff/challenge.pdf</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/photos/crane/">http://www.cs.bham.ac.uk/research/projects/cosy/photos/crane/</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/challenge-penrose.pdf">http://www.cs.bham.ac.uk/research/projects/cogaff/challenge-penrose.pdf</a>
<li>
See also <a href="#compmod07">this presentation at a
computational modelling workshop</a> May-June 2007.
</ul>
============
</small>
</blockquote>
<p>
<hr/>
<p>
<a name="wonac"></a>
<a name="talk47"></a>
<a name="wonac07"></a>
<h3><b>
Talk 47: Causal competences in animals and machines
<br>
<small>
(Including Humean and Kantian causal understanding.)
</small>
</b></h3>
Invited talks by Jackie Chappell and Aaron Sloman at WONAC'07:
The NSF/EU-funded Workshop on Natural and Artificial Cognition
<br>
Pembroke College, Oxford, 24th-26th June 2007
<br>
<a href="http://www2.cs.arizona.edu/projects/wonac/">www2.cs.arizona.edu/projects/wonac/</a>


<blockquote>
<b>
Presentations by both of us, along with abstracts,
and also a post-workshop presentation on varieties of
causal competence <a href="wonac"> available in PDF format.</a></b>

<a name="slomanwonac"></a>
<ol>
<small>
<li>
<b>Aaron Sloman</b>:
    <br>
    Evolution of two ways
    of understanding causation:
    Humean and Kantian.
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/sloman-wonac-slides.pdf">(PDF)</a>,
<a href="wonac/sloman-abstract.html">Abstract(HTML)</a>

<p>
<a name="chappellwonac"></a>
<li>
<b>Jackie Chappell</b>:
<br>
Understanding causation: the practicalities
-- <a href=" http://www.cs.bham.ac.uk/~jmc/chappell-wonac-slides-screen.pdf">
Screen version with hyperlinks (PDF)</a>
 <a href="wonac/chappell-abstract.html">Abstract
(HTML)</a>
<blockquote>
<a href=" http://www.cs.bham.ac.uk/~jmc/chappell-wonac-slides-print.pdf">
Print version without hyperlinks (PDF)</a>
</blockquote>
<p>
<a name="causal"></a>
<li>
<b>Causal competences of many kinds</b>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/causal-competences.pdf">(PDF)</a>
<br>
An incomplete draft paper written after the workshop:
</small>
</ol>
</blockquote>
<p>
<hr>
<p>
<a name="talk46"></a>
<a name="compmod07"></a>
<h3><b>
Talk 46: Architectural and representational requirements for seeing processes
and affordances.
<br>
Expanded version of presentation
<a href="sloman-compmod07-slides.pdf">Available HERE (PDF)</a>
</b></h3>
<p>
Invited talk at:
<blockquote>
<a href="http://comp-psych.bham.ac.uk/workshop.htm"> BBSRC funded
Workshop on
</a>
<blockquote>
Closing the gap between neurophysiology and behaviour:
A computational modelling approach
<br>
<small>
University of Birmingham, United Kingdom
<br>
May 31st-June 2nd 2007
</small>
</blockquote>
A paper for the proceedings is online
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0801">here (PDF).</a>
</blockquote>
<b>Abstract</b>
<blockquote>
Over several decades I have been trying, as a philosopher-designer, to
understand requirements for a robot to have human-like visual
competences, and have written several papers pointing out what some of
those requirements are and how far all working models known to me are
from satisfying them. This included a paper in 1989 proposing replacing
'modular' architectures with 'labyrinthine' architectures, reflecting
the varieties of interconnectivity between visual subsystems and other
subsystems (e.g. action control subsystems, auditory subsystems).
<p>
One of the recurring themes has been the relationship between structure
and process. For instance, doing school Euclidean geometry involves
seeing how processes of construction can produce new structures from old
ones in proving theorems, such as pythagoras' theorem. Likewise
understanding how an old-fashioned clock works involves seeing causal
connections and constraints related to possible processes that can occur
in the mechanism. In contrast performing many actions involves producing
processes (e.g. grasping), seeing those processes, and using visual
servoing to control the fine details. This need not be done consciously,
as in posture control, and many other skilled performances. Some
processes transform structures discretely, e.g. by changing the topology
of something (adding a new line to a diagram, separating two parts of an
object) others continuously (e.g. painting a wall or blowing up a
balloon).
<p>
Another theme that has been evident for many decades is the fact that
percepts can involve hierarchical structure, although not all the
structures should be thought of as loop-free trees, e.g. a bicycle
doesn't fit that model even though to a first approximation most animals
and plants do (e.g. decomposition into parts that are decomposed into
parts, etc.) Less obviously, perception (as I showed in chapter 9 of The
Computer Revolution in Philosophy) can involve layered ontologies, where
one sub-ontology might consist entirely of 2-D image structures and
processes, whereas another includes 3-D spatial structures and
processes, and another kinds of 'stuff' of which objects are made and
their properties (e.g. rigidity, elasticity, solubility, thermal
conductivity, etc.), to which can be added mental states and processes,
e.g. seeing a person as happy or sad, or as intently watching a crawling
insect. The use of multiple ontologies is even more obvious when what is
seen is text, or sheet music, perceived using different geometric,
syntactic, and semantic ontologies.
<p>
What did not strike me until 2005 when I was working on an EU-funded
robot project (CoSy) is what follows from the combination of the two
themes (a) the content of what is seen is often processes and
process-related affordances, and (b) the content of what is seen
involves both hierarchical structure and multiple ontologies. What
follows is a set of requirements for a visual system that makes
current working models seem even further from what we need in order to
understand human and animal vision, and also in order to produce working
models for scientific or engineering purposes.
<p>
One way to make progress may be to start by relating human vision to the
many evolutionary precursors, including vision in other animals. If
newer systems did not replace older ones, but built on them, that
suggests that many research questions need to be rephrased to assume
that many different kinds of visual processing are going on
concurrently, especially when a process is perceived that involves
different levels of abstraction perceived concurrently, e.g. continuous
physical and geometric changes relating parts of visible surfaces and
spaces at the lowest level, discrete changes, including topological and
causal changes at a higher level, and in some cases intentional actions,
successes, failures, near misses, etc. at a still more abstract level.
The different levels use different ontologies, different forms of
representation, and probably different mechanism, yet they are all
interconnected, and all in partial registration with the optic array
(not with retinal images, since perceived processes survive saccades).
<p>
The slides include a speculation that achieving all this
functionality at the speeds displayed in human (and animal) vision
may require new kinds of information-processing architectures,
mechanisms and forms of representation,
perhaps based on complex, interacting, self-extending,
networks of multi-stable mutually-constraining dynamical systems --
some of which change continuously, some discontinuously.
<p>
See also these challenges for vision researchers listed below
<a href="#challenges">[*]</a>
</blockquote>
<p>
<hr>
<p>
<a name="talk45"></a>
<a name="pac07"></a>
<h3><b>
Talk 45 (Poster): Consciousness in a Multi-layered Multi-functional Labyrinthine Mind
<br>
<a href="sloman-pac-07-poster.pdf">A4 slides available HERE (PDF)</a>
</b></h3>
<p>
This was a poster presentation at
<blockquote>
<a href="http://www.bris.ac.uk/philosophy/department/events/PAC_conference/index.html/Conference.htm">PAC-07 Conference, 1-3 July 2007, Bristol,</a>
on
<blockquote>
Perception, Action and Consciousness confronting the dual-route
(dorsal/ventral) theory of visual perception and the enactivist view
of consciousness.
</blockquote>
</blockquote>
<b>Abstract</b>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/consciousness-abstract.html">available
online (HTML)</a>
<p>
<hr>
<p>
<a name="talk44"></a>
<a name="cospal07"></a>
<h3><b>
Talk 44: Some requirements for human-like visual systems,
including seeing processes, structures, possibilities, affordances,
causation and impossible objects.
<br>
<a href="sloman-cospal-slides.pdf">Available HERE (PDF)</a>
</b></h3>
Invited talk at
<blockquote>
<a href="http://www.cospal.org/Workshop.htm">COSPAL Workshop Aalborg,</a>
14th June 2007 on
<blockquote>
Cognitive Systems:
Perception, Action, Learning
</blockquote>

</blockquote>
<p>
<hr>
<p>
<h3><b>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0702">
Talk 43: COSY-PR-0702: What is human language? How might it have evolved?</a>
</b></h3>
Aaron Sloman
<br>
Slides for a seminar presented in Birmingham on 5th Mar 2007
<br>Follow link for abstract and PDF
<p>

<hr>
<p>
<a name="talk42"></a>
<h3><b>
<a href="building-roadmaps-sloman.pdf">building-roadmaps-sloman.pdf (PDF)</a>
<br>
Previously at:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0701">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0701</a>
<br>
Also available (using flash format) on slideshare.net
<br>
<a href="http://www.slideshare.net/asloman/how-to-build-a-research-roadmap">http://www.slideshare.net/asloman/how-to-build-a-research-roadmap</a>
<br>
Talk 42: COSY-PR-0701: What's a Research Roadmap For? Why do we need one? How can we produce one? (PDF)
</b></h3>
Aaron Sloman
<br>
This is a much expanded version of a presentation at the euCognition
Research Roadmap discussion in Munich on 12 Jan 2007.
<br>For more on the
Research Roadmap project see:
<br>
<a href="http://www.eucognition.org/wiki/index.php?title=Research_Roadmap">http://www.eucognition.org/wiki/index.php?title=Research_Roadmap</a>
<br>Follow link for abstract and PDF
<p>


<hr>
<p>
<h3><b>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0604">
Talk 41: COSY-PR-0604: Evolution of ontology-extension:
<br>How to explain internal and external behaviour in organisms,
including processes that develop new behaviours. (PDF)
</a>
</b></h3>
Aaron Sloman, with much help from Jackie Chappell
<br>
In collaboration with members of the EU CoSy Robotic Project
<br>
Presented to combined Biosciences and AINC seminar, University of
Birmingham, 9th Oct 2006, and in Edinburgh 7th Dec 2006.
<br>Follow link for abstract and PDF
<P>

<hr>
<p>
<h3><b>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0603">
Talk 40 (Poster): COSY-PR-0603: Putting the Pieces of AI Together Again
(PDF)
</a>
</b></h3>
Poster for Member's Poster Session: AAAI'06, Boston, July 2006.
<br>Follow link for abstract and PDF
<p>
<hr>
<a name="talk39"></a>
<p>
<h3><b>
<a href="assc10-poster.pdf">FILE: assc10-poster.pdf</a>
Talk 39 (Poster): COSY-PR-0602: How an animal or robot with 3-D manipulation skills experiences the world
(PDF)
</a>
</b></h3>
Poster for ASSC10, Oxford June 2006.

<blockquote>
Poster for <a href="http://www.assc10.org.uk/">10th Conference</a>
of the Association for the
Scientific Study of Consciousness
<a href="http://assc.caltech.edu/">(ASSC).</a>
<br>
Also available at ASSC
<a href="http://eprints.assc.caltech.edu/">e-prints web site</a> as
<a href="http://eprints.assc.caltech.edu/112/">eprint 112</a>
</blockquote>
I was ill and did not manage to present my poster at ASSC10,
Oxford June 2006. This is a PDF slide presentation of the main
points.
<br>
<b>Abstract:</b>
<blockquote>
This presentation elaborates on
<blockquote>
'The substratum of this experience is the mastery of a
technique' (Wittgenstein)
</blockquote>
I try to show, with illustrative videos, that many 'techniques' are implicitly
involved in ordinary experiences -- and that the complexities grow as a child
develops, extending its ontology and therefore the variety of affordances it can
experience and use. I point out that there are two interpretations of
sensorimotor contingencies, one intrasomatic (relating only the contents of
sensory and motor signals at various levels of abstraction) the other
extrasomatic (amodal, objective), referring to an environment that exists
independently of whether and how it is experienced or acted on, and that the
latter provides computational advantages in some cases, supporting a Kantian
rather than a Humean view of knowledge and concepts. This also suggests a
re-interpretation of mirror neurons as 'abstraction neurons'.
<p>
What we are conscious of in the environment depends on the ontology we have
available. A child whose ontology does not include the notion of boundary, or
the notion of alignment of boundaries may not be able to replace a cut-out
wooden picture in its recess, even if he knows which recess it should go in.
Careful observation of children at various stages shows transitions that involve
extensions of the available ontology, which must go along with development of
suitable forms of representation and mechanisms for manipulating them, and an
architecture that combines them all. Thus the substratum of the more
sophisticated child's experience is mastery of many 'techniques', not just one
as implied by Wittgenstein (who probably did not intend that). It is suggested
that there are considerable differences between precocial species whose
competences and architecture are mostly genetically determined and altricial
species that develop most of their own competences e.g. through playful
exploration, driven by meta-level bootstrapping mechanisms.
<p>
Only when I started working in detail on requirements for a human-like robot
able to manipulate 3-D objects using vision and an arm with gripper did I notice
what should have been obvious long before, namely that structured objects have
'multi-strand' relationships not expressible simply as R(x, y), because the
relation between x and y involves many relations between parts of x and parts of
y. <blockquote> For a more detailed presentation of the resulting theory see
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0505">
COSY-PR-0505: A (Possibly) New Theory of Vision (PDF)
</a>
</blockquote>
<p>
Hence, motion of such structured objects involves 'multi-strand' (concurrent)
processes. That is, many relationships change in parallel -- e.g. faces, edges,
corners of one block may all be changing their relationships to faces edges and
corners of another (and things get more complex when objects are flexible, e.g.
your hand peeling a banana or a sweater being put on a child).
<p>
Thus seeing what you are doing in such cases can have a kind of complexity that
appears not to have been noticed previously because of too much focus on simpler
visual tasks like recognition and tracking.
<p>
I'll show why we need to postulate mechanisms in which concurrent processes at
different levels of abstraction, in <i>partial</i> registration with the optic
array (NOT the retina, since saccades, etc., occur frequently) are represented.
<p>
Nothing in AI comes close to modelling this, and it seems likely that it will be
hard to explain in terms of known neural mechanisms. If the opportunity arises
I'll try to explain some of the implications for human development,
understanding of causation, and computational modelling, and spell out
requirements to be addressed in future interdisciplinary research, explaining
deep connections with Gibson's notion of affordance, and its generalisation to
'vicarious affordances'.
<p>
The evolution of grasping devices that move independently of eyes (i.e. hands
instead of mouth or beak) had profound implications -- undermining claims about
sensory-motor contingencies -- also suggesting that mirror neurons should have
been called 'abstraction neurons'.
<p>
Some of the ideas are also sketched here:
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0601">COSY-DP-0601
'Orthogonal Competences Acquired by Altricial Species'</a>
<p>
A critique of common assumptions about 'sensorimotor contingencies' is
presented, including making a distinction between
somatic (internal) and exosomatic (external) ontologies.
Too many people expect too much to come from the
somatic (intrasomatic) variety -- including knowledge of sensorimotor
contingencies, a notion criticised in
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0603">http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0603</a>
<p>
Requirements for 'fully deliberative' systems are analysed in
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/fully-deliberative.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/fully-deliberative.html</a>
</blockquote>


<p>
<hr>
<p>
<a name="talk38"></a>
<h3><b>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0601">
Talk 38 (Poster): COSY-PR-0601: Acquiring Orthogonal Recombinable Competences(PDF)
</a>
</b></h3>
Poster for COGSYS II Conference, Nijmegen, April 2006
<br>Follow link for abstract and PDF

<p>
<hr>
<P>
<a name="talk37"></a>
<a name="ki2006"></a>
<h3><b>
Talk 37: FUNDAMENTAL QUESTIONS - THE SECOND DECADE OF AI
<br>
Towards Architectures for Human-like Machines <a
href="sloman-ki2006.pdf">Available HERE (PDF)</a>
<br>
<small>
(Overlaps with several previous talks)
<br>
A version of the slide presentation (using 'flash') is also available on
<a href="http://www.slideshare.net/asloman/slideshows">my 'slideshare.net'
space.</a>
</small>
</b></h3>
This is an expanded version of the invited presentation at the
<blockquote>
Symposium on 50 years of AI, at the KI2006 Conference,
Bremen, Germany, June 17th 2006
<br>
<small>
Video recordings of the symposium talks and discussion are available at :
<br>
<a href="http://bscc.spatial-cognition.de/node/14">http://bscc.spatial-cognition.de/node/14</a>
<br>
The video recording of my lecture is also available on this site:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/movies/#ki2006">http://www.cs.bham.ac.uk/research/projects/cogaff/movies/#ki2006</a>

<h3><b>Abstract:</b>
<small>
An extended abstract for the talk is at
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/ki2006-abstract.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/ki2006-abstract.html</a>
<br>
Also at:
<br>
<a href="http://doi.org/10.1007/978-3-540-69912-5_33">http://doi.org/10.1007/978-3-540-69912-5_33</a>
</small>
</h3>
</blockquote>
<p>
<hr/>
<p>
<a name="causation"></a>
<a name="talk36"></a>
<h3><b>
Talk 36: TWO VIEWS OF CHILD AS SCIENTIST: HUMEAN AND KANTIAN
</b></h3>
<a href="child-as-scientist.pdf">child-as-scientist.pdf</a>
<br>
Presentation to Language and Cognition Seminar,
School of Psychology, University of Birmingham. October 14th 2005
<br>
Aaron Sloman

<blockquote>

  The current emphasis on causation as
  correlational/statistical, i.e. Humean, as in Bayesian
  nets, ignores a deeper notion of causation as
  structure-based and deterministic, i.e. Kantian. The
  history of science involves wherever possible moving from
  Humean to Kantian causation, and that's what young
  children and some other animals seem to do. Where
  structure-based understanding is not achievable we fall
  back on Humean causation as a last resort. But
  structure-based understanding is not something unitary:
  it has to be learnt about over and over again in
  connection with many different kinds of physical matter,
  physical structure, physical process, and likewise
  structures and processes of more abstract kinds, e.g. in
  functional relations, in social processes, in number
  theory, in computational virtual machines and in mental
  processes. This talk is mainly about causal understanding
  of the physical/geometrical world of a young child (or
  chimp, or crow ?), which I suspect provides a basis for
  much else.

<p>
  This talk overlaps with presentation
  <a href="#pr0505">COSY-PR-0505 (PDF)</a> on vision, and also
 with a paper discussing
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/orthogonal-competences/">'Orthogonal re-combinable competences'.</a>
</blockquote>

<hr>
<a name="talk35"></a>
<h3><b>
Talk 35: COSY-PR-0505: A (POSSIBLY?) NEW THEORY OF VISION
</b></h3>
<b>
<a href="new-vision-slides.pdf">new-vision-slides.pdf (PDF)</a>
</b>
Combining several old theories
<br>
Generating many new problems and research tasks.
<p>
<b>Installed:</b> October 2005
<br>
<b>Last Updated:</b> 17 Feb 2007
<blockquote>
Seminar in School of Computer Science University of Birmingham 13th October 2005,
<br>
Imperial College London on 25th October 2005,
<br>
Aston University on 28th October 2005,
<br>
Osnabr&uuml;ck, Germany 16th November 2005
<br>
(Closely related to presentations on affordances, ontologies,
causation,
<a href="#talk36">child as scientist,</a> and later presentations on vision.)
</blockquote>
<b>Abstract:</b>
<blockquote>
The key idea is that whereas I previously thought (like many others) that vision
involved concurrently analysing and interpreting <i>structures</i>
at different levels of abstraction, using different ontologies at the different
levels (as explained in the summary of the Popeye program in
<a href= "http://www.cs.bham.ac.uk/research/cogaff/crp/#chap9">Chapter
9</a>
of <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/crp/">'The
Computer Revolution in Philosophy'</a> (1978)) it is now clear that
that was an oversimplification, and vision should be seen as
involving analysis and interpretation not just of <b>structures</b>
but also <b>processes</b> at different levels concurrently, which
sometimes implies running several <b>simulations</b> concurrently at
different levels of abstraction, using different ontologies -- in
partial registration with sensory data were appropriate, and
sometimes also motor signals.
<p>
The talk explains what this means,
what it does not mean, presents some of the evidence, summarises
some of the implications, and points to some of the (many) unsolved
problems, including unsolved problems about how this could be
implemented either on computers or in brains. The presentation
briefly lists some of the many precursors of the theory, but does
not go into detail.
<p>
The slides will go on being revised and extended
in the light of comments and criticisms. It soon became clear that
the topic is much broader than vision, but I have left the title.
One of the implications concerns our understanding of causation, and
our learning about causation, discussed in the next presentation.
There are also implications regarding visual/spatial reasoning. The
work of Rick Grush reported in BBS 2004 is very closely related to
some of the ideas presented here.
<br>
See
<a href="http://mind.ucsd.edu/papers/intro-emulation/intro-em.pdf">http://mind.ucsd.edu/papers/intro-emulation/intro-em.pdf</a>
<p>
The theory is also very closely related to theories about the development of
mathematical competences presented <a href="#toddler">above</a>, and also
presentations on perception of affordances and proto-affordances <a href="#dagstuhl08">here.</a>
</blockquote>
<p>
<hr>
<P>
<a name="bled-04">
<a name="talk34">
<h3><b>
Talk 34: TUTORIAL ON INTEGRATION AT EC COGNITIVE SYSTEMS 'KICKOFF' CONFERENCE,
<br> (Bled, Slovenia, 28-30 October 2004)
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/presentations/bled-04.pdf">Available HERE (PDF)</a>
</b></h3>
Aaron Sloman
<br>
<b>Abstract</b>
<br>
The EC Cognitive Systems KickOff Conference was organised by
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/">the CoSy
project</a> on behalf of the EC Cognitive Systems Initiative. Additional
presentations and videos are available at the
<a href="http://www.cognitivesystems.org">official CoSy web site</a>
in the
<a href="http://cogvis.fri.uni-lj.si/events/CogSysKickOff/">events section.</a>
The main theme of the Cosy Project is integration of many kinds of
functionality, normally studied separately. This tutorial presentation
attempted to explain what integration implies with some examples. This
was one of 8 tutorial presentations in two parallel streams on the
second day of the conference. More recent work on the topic of
integration can
be
found at the
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/">Birmingham CoSy papers web
site.</a>
<br>
(Overlaps with several previous talks)

<p>
<hr>
<p>
<a name="ijcai-05"></a>
<P>
<h3><b>
Talk 33: THE ALTRICIAL-PRECOCIAL SPECTRUM FOR ROBOTS
</b></h3>
Talk at IJCAI-05 5th Aug 2005 (Chappell and Sloman), based on
<a href="http://www.cs.bham.ac.uk/research/cogaff/05#200503">this paper</a>
in the conference proceedings.
<br>
<a href="chappell-sloman-ijcai-slides.pdf">Slides Available
HERE (PDF)</a>
<br>
(Overlaps with several previous talks)
<br>
<UL>
<li>
<b>Warning</b>: this pdf file includes two separate pdf files produced
by the two speakers in different formats, so the style changes part way
through. For the second part the viewing window will have to be expanded
if it does not automatically adjust to accommodate the last 14 slides.
</UL>
The presentation at the conference included a number of movies.
<p>
The <a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/">Birmingham
CoSy Web Site</a> includes several sequels to this paper. See also
<a href="#wonac07">talks on understanding of causation in animals and machines at WONAC 2007.</a>
<p>
<hr>
<p>
<a name="rse-05"> </a>
<h3><b>
Talk 32: ROYAL SOCIETY OF EDINBURGH MEETING: Artificial Intelligence: In
your Life Today
<br>
<a href="rse-05.pdf">Available HERE (PDF)</a>
<br>
(Overlaps with several previous talks)
</b></h3>
Talk at RSE 5th Aug, Co-located with IJCAI-05, Edinburgh.
<b>
Event Web Site is
<a href="http://www.aisb.org.uk/publicunderstanding/rse05/index.shtml">here</a>
</b>
<P>
<hr>
<p>
<a name="humarch"> </a>
<h3><b>
Talk 31: ARCHITECTURES FOR HUMAN-LIKE MACHINES
</b></h3>
Talk at Goldsmiths 19th Jan 2005
<UL>
<li>
<a href="goldsmiths.pdf">Available HERE (PDF)</a>
<br>
(Overlaps with several previous talks)
</UL>
<h3><b>
Abstract:
</b></h3>
<blockquote>
Much discussion of the nature of human minds is based on prejudice or
fear of one sort or another -- sometimes arising out of 'turf wars'
between disciplines, sometimes out of dislike of certain theories of
what we are, sometimes out of religious concerns, sometimes out of
ignorance of what has already been learnt in various disciplines,
sometimes out of over-reliance on common sense and introspection, or
what seems 'obviously' true. But one thing is clear to all: minds are
active, changing entities: you change as you read this abstract and you
can decide whether to continue reading it or stop here. I.e. minds are
active machines of some kind. So I propose that we investigate, in a
dispassionate way, the variety of design options for working systems
capable of doing things that minds can do, whether in humans or other
animals, in infants or adults, in normal or brain-damaged people, in
biological or artificial minds. We can try to understand the trade-offs
between different ways in which complete systems may be assembled that
can survive and possibly reproduce in a complex and changing environment
(including other minds.) This can lead to a new science of mind in which
the rough-hewn concepts of ordinary language (including garden-gate
gossip and poetry) are shown not to be wrong or useless, but merely
stepping stones to a richer, deeper, collection of ways of thinking
about what sorts of machines we are, and might be. This will also help
to shed new light on the recent (confused) fashion for thinking that
emotions are 'essential' for intelligence. It should also help us to
understand how the concerns of different disciplines, e.g. biology,
neuroscience, psychology, linguistics, philosophy, etc. relate to
different layers of virtual machines operating at several different
levels of abstraction, as also happens in computing systems.
<p>
Other talks in this directory elaborate further on some of the themes
presented.
</blockquote>
<P>
<hr>
<P>
<a name="meanings"> </a>
<a name="talk30"> </a>
<h3><b>
Talk 30: VARIETIES OF MEANING
</b></h3>
Talk to Language and Cognition seminar, the University of Birmingham,
5th Nov 2004
<P>
Available here

<UL>
<li>
<a href="meaning-types-slides.pdf">in PDF format</a>
</UL>
This talk explains why 'symbol tethering' (which treats most of meaning
as determined by structure, with experience and action helping to reduce
indeterminacy) is more useful for explicit forms of representation
and theorising than 'symbol grounding' (which treats all meaning as
coming 'bottom-up' from experience of instances, and which is just
another variant on the old philosophical theory 'concept empiricism'
defended by empiricist philosophers such as Locke, Berkeley and Hume,
and refuted around 1781 by Kant.
<P>
NOTE: following a suggestion from Jackie Chappell, I now use the phrase
'symbol tethering' instead of 'symbol attachment'.
<P>
Since writing this I have discovered another attack on concept
empiricism on the web page of
<a href="http://www.pitt.edu/~machery/">Edouard Machery</a>.
See
<a href="http://www.pitt.edu/~machery/papers/Concept%20Empiricism_Machery_%2006_05.pdf">Concept Empiricism: Taking a Hard Look at the Facts.</a>
<P>
This talk overlaps in part with
<a href="#models"> Talk 49</a> and
<a href="#grounding"> Talk 14</a>
<P>

The talk was originally entitled 'Varieties of meaning in perceptual
processes' but I did not manage to get to the perceptual processes part,
being developed
<a href="http://www.cs.bham.ac.uk/research/cogaff/sloman-vis-affordances.pdf">in this paper.</a>

<P>
These slides are likely to be updated when I have time to complete the
planned section on varieties of meaning in perceptual mechanisms.

<P>
<hr>
<p>
<a name="talk29"></a>
<a name="gcold"></a>
<h3><b>
<a href="http://www.cs.bham.ac.uk/research/cogaff/gc#gcoverview">
Talk 29: UKCRC GRAND CHALLENGE 5: 'ARCHITECTURE OF BRAIN AND MIND'
</a>
</b></h3>
Overview presentation at Grand Challenges Conference April 2004
(Also at Edinburgh University in November 2004).
<P>

<hr>
<P>
<a name="talk28"></a>
<a name="cafe04"></a>
<a name="emotions"></a>
<h3><b>
Talk 28: DO INTELLIGENT MACHINES, NATURAL OR ARTIFICIAL, REALLY NEED EMOTIONS?
<br>
<small>
Revised: 14 Jan 2014
</small>
</b></h3>
<UL>
<li>
<a href="sloman-emotions-intelligence.pdf">sloman-emotions-intelligence.pdf (PDF New
FileName, revised contents, 2014)</a>
<br>
Also on
<a href="http://www.slideshare.net/asloman/do-machines-natural-or-artificial-really-need-emotions-presentation">Slideshare.net</a>
<p>
<li>
<a href="cafe-emotions-machines.pdf">cafe-emotions-machines-2008.pdf old version (previous name)</a>
<p>
<small>
Talk originally given to
<a href="http://www.birminghamcafe.org/">Cafe
Scientifique & Culturel Birmingham,</a>
7th May 2004
<br>Announced at
    <a href="http://www.birminghamcafe.org/view.html?eid=11">http://www.birminghamcafe.org/view.html?eid=11</a>
<P>
Revised version presented on 24th June 2005 in Utrecht at
<br>
<a href="http://www.nwo.nl/nwohome.nsf/pages/NWOP_6C2EN4">
The 3rd multi-disciplinary symposium organized by the NWO Cognition
Programme:
How rational are we?
</a>
<p>
Also presented several other times/places.
</small>
</UL>
<h3><b>Abstract</b></h3>
Since the publication of the book "Descartes' Error" in 1994 by Antonio
Damasio, a well-known neuroscientist, it has become very fashionable to
claim that emotions are necessary for intelligence. I think the claim is
confused and the arguments presented for it fallacious.
<P>
Part of the problem is that many of the words we use for describing
human mental states and processes (including 'emotion' and
'intelligence') are far too ill-defined to be useful in scientific
theories. Nevertheless there are many people who LIKE the idea that
emotions, often thought of as inherently irrational, are required for
higher forms of intelligence, the suggestion being that rationality is
not all it's cracked up to be. But wishful thinking is not a good basis
for advancing scientific understanding.
<blockquote>
<small>
Another manifestation of wishful thinking is people attributing to me
opinions that are the opposite of what I have written in things they
claim to have read.
</small>
</blockquote>
<P>
So I propose that we investigate, in a dispassionate way, the variety of
design options for minds, whether in animals (including humans) or
machines, and try to understand the trade-offs between different ways of
assembling systems that survive in a complex and changing environment.
This can lead to a new science of mind in which the rough-hewn concepts
of ordinary language (including garden-gate gossip and poetry) are shown
not to be wrong or useless, but merely stepping stones to a richer,
deeper, collection of ways of thinking about what sorts of machines we
are, and might be.
<P>
For more on this see
    <a href="http://www.cs.bham.ac.uk/research/cogaff/">http://www.cs.bham.ac.uk/research/cogaff/</a>
<P>
<blockquote>
<P>
This overlaps considerably with
<UL>
<li>
<a href="http://www.cs.bham.ac.uk/research/cogaff/04.html#200403">Invited talk for AAAI04 Symposium on emotions</a>
<li>
<a href="#talk3"> Talk 3</a>,
<li>
<a href="#talk24"> Talk 24 </a> and others.
</UL>
See also:
<pre>
    Beyond shallow models of emotion, in
    <i>Cognitive Processing: International Quarterly of Cognitive Science,</i>
    Vol 2, No 1, pp. 177-198, 2001
    <a href="http://www.cs.bham.ac.uk/research/projects/cogaff/00-02.html#74">http://www.cs.bham.ac.uk/research/projects/cogaff/00-02.html#74</a>
    and this review/comment:
    <a href="http://www.ce3c.com/emotion/?p=106">http://www.ce3c.com/emotion/?p=106</a>
</pre>
</blockquote>
<P>

<hr>
<P>
<a name="vis">
<a name="talk27">
<h3><b>
Talk 27: REQUIREMENTS FOR VISUAL/SPATIAL REASONING
</b></h3>
Talk to language and cognition seminar, Birmingham, Oct 2003
<br>
Available in two formats using Postscript and PDF here:
<UL>
<li>    <a href="vis-psych.pdf">PDF version</a>
<li>    <a href="vis-psych.ps"> Postscript version</a>
</UL>
<h3><b>Abstract</b></h3>
<P>
<blockquote>
This is yet another set of slides about the role of vision and
spatial understanding in reasoning, but with especial emphasis on
affordances and the fact that since the possibilities for
action and the affordances are different at different spatial scales,
and in different contexts, our understanding of space will have
different components concerned with those different scales and contexts.
<P>
What is it that an 18 month old child has not yet grasped when he cannot
see how to join
two parts of a toy train, despite having excellent vision and many
motor skills? And what changes soon after when he has learnt how to do
it.
<P>
This overlaps considerably with

<a href="#visreason"> Talk 7</a> and
<a href="#humanvision"> Talk 21 on Human Vision </a>
<P>
See also these
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0506">More recent slides on
Two views of child as scientist:
Humean and Kantian</a>
(October 2005).
</blockquote>
<P>
<hr>
<a name="inf"> </a>
<a name="talk26"> </a>
<P>
<h3>
TALK 26: WHAT ARE INFORMATION-PROCESSING MACHINES?
<br>WHAT ARE INFORMATION-PROCESSING <I>VIRTUAL</I> MACHINES?
<br> Notes from a workshop on models of consciousness, Sept 2003, and a
presentation in York, Feb 2004 -- updated from time to time since then
e.g. for talk in Birmingham 16 Oct 2008.
</h3>
The slides are available in two formats:
<UL>
<li>    <a href="information.pdf">PDF version</a>
<li>    <a href="information.ps"> Postscript version</a>
</UL>
<h3><b>Abstract</b></h3>
<P>
<blockquote>
For many years, like many other scientists, engineers and philosophers,
I have been writing and talking about "information-processing" systems,
mechanisms, architectures, models and explanations, e.g.:

<UL>
<li>
My 1978 book
<I>The Computer Revolution in Philosophy</I>
now online here:
<a href="http://www.cs.bham.ac.uk/research/cogaff/crp/">http://www.cs.bham.ac.uk/research/cogaff/crp/</a>
(especially chapter 10).
<P>
<li>
A. Sloman, (1993)
The mind as a control system, in
<I>Philosophy and the Cognitive Sciences</I>,
Cambridge University Press,
Eds. C. Hookway & D. Peterson,
pp. 69--110.
<br>
Online here:
<a href="http://www.cs.bham.ac.uk/research/cogaff/">http://www.cs.bham.ac.uk/research/cogaff/</a>
</UL>
Since the word "information" and the phrase "information-processing"
are both widely used in the sense in which I was using
them, I presumed that I did not need to explain what I meant.
Alas I was naively mistaken:
<P>
<UL>
<li>
Not everyone agrees with many things now often taken as obvious, for
instance that all organisms process information.
<li>
Some people think that "information-processing" refers to the
manipulation of bit patterns in computers.
<li>
Not everyone believes information can cause things to happen.
<li>
Some people think that talk of "information-processing" involves
unfounded assumptions about the use of representations.
<li>
There is much confusion about what "computation" means, what its
relation to information is, and whether organisms in general or brains
in particular do it or need to do it.
<li>
Some of the confusion is caused by conceptual unclarity about virtual
machines, and blindness to their ubiquity.
</UL>

The conceptual confusions related to these notions lead to spurious
debates, often at cross-purposes, because people do not recognize the
unclarity in their concepts and the differences between their usages and
those of other disputants. I found evidence for this at two recent
workshops I attended, both of which were in other ways excellent: the
<a href="http://aslab.disam.etsii.upm.es/public/events/moc/">Models of
Consciousness Workshop</a> in Birmingham and
<a href="http://www.iac03.com/">The UK Foresight Interaction
workshop.</a> in Bristol, both held in the first week of
September 2003.
<P>
What I heard in that week, often heard in previous discussions, finally
provoked me to bring together a collection of points in "tutorial" mode.
Hence these slides, developing a number of claims, including these:
<UL>
<li>
"Information" (in the sense that refers to meaning or content, not the
Shannon information-theoretic sense) is theoretical notion which, like
"energy" cannot be explicitly defined in terms of unproblematic
pre-theoretical concepts.
<li>
These, like all theoretical concepts, are partly defined by a web of
relationships to other concepts in a theory or collection of related
theories -- and as the theories change the concepts change.
<li>
Biological organisms all process information in that sense, but they
vary in the variety of things they can do with information, the forms in
which they encode it, the mechanisms used and the architectures in which
the information is manipulated.
<li>
Computers are best thought of as just another type of information
processor (when they are working -- not when switched off!),
which have more in common with some aspects of natural
information processing than with others.
<li>
Many of the processes occur in virtual machines rather than in physical
machines, though they are all (ultimately) implemented in virtual
machines, some biological, some social, some artificial.
<li>
The same physical computer can, at different times, instantiate
different information processors (e.g. when running different operating
systems, different programs with), whereas in biological organisms there
is much closer coupling between the physical design and many of the
types of information processing that go on (e.g. in cell-repair,
digestion, low-level motor control, hormonal control, immune system
processes).
<li>
Nevertheless, in humans, and many other animals, the same physical
system can run very different virtual machines concerned with
perceiving, thinking about, explaining, predicting and interacting with
a physical, biological, social, political, etc. environment. E.g.
despite much that is in common between virtual machines in a typical
human adult and a typical 5 year old child, there are also many
differences, produced by decades of learning, and cultural absorption,
which may also lead to great differences between adult virtual machines,
e.g. in a ballet dancer, a composer of symphonies, a jazz musician, a
brick-layer, a philosopher and a quantum physicist.
<li>
Most people who discuss issues relevant to natural or artificial
information processing systems do not have enough knowledge of what
virtual machines are, how they are implemented in lower level virtual or
physical machines, or how virtual machine events can be causes. Software
engineers understand these matters and use them in their work every day,
but this is <I>craft</I> knowledge and they do not articulate it
explicitly in a manner than clarifies the philosophical issues.
<li>
As a philosophical software engineer I have tried to explain things in a
way that will, I hope, clarify some debates in philosophy, AI, cognitive
science, psychology, neuroscience, and biology.
</UL>
This is work in progress. Comments and criticisms welcome.
<a href="#inf">The presentation</a>
will be updated/improved from time to time. These slides are closely
related to
<a href="#models">presentation attacking the notion of 'symbol
grounding' and proposing 'symbol tethering' instead</a>.
(There are also <a href="#grounding"> older slides
the slides attacking the notion of 'symbol
grounding' (Talk 14)</a>.)
<p>
I also have some online notes on
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/whats-information.html">
What is information? Meaning? Semantic content?</a>
<br>
Now a book-chapter:
<blockquote>
<small>
What's information, for an organism or intelligent machine?
     How can a machine or organism mean?, in
<br>
Information and Computation,
 Eds. G. Dodig-Crnkovic and M. Burgin,
World Scientific, New Jersey,
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#905">http://www.cs.bham.ac.uk/research/projects/cogaff/09.html#905</a>
</small>
</blockquote>

<p>
See also
<a href="#super">Talk 12: Supervenience and Implementation.</a>
</blockquote>
<P>
<hr>
<p>
<a name="assc7"> </a>
<a name="talk25"> </a>
<h3>
Talk 25: ARCHITECTURE-BASED PHILOSOPHY OF MIND (ASSC7 Version)
<br>
What kind of virtual machine is capable of human consciousness?
</h3>
<br>
Originally presented as an invited talk at ECAP03 Glasgow 28th March
2003 (see Talk 23), then at University of Notre Dame in April 2003, then
revised and reorganised for invited talk at ASSC7 May-June 2003
<br>
    <a href="http://www.cs.memphis.edu/~assc7/">http://www.cs.memphis.edu/~assc7/</a>
<P>
<b>
DRAFT INCOMPLETE SET OF SLIDES (3 Jun 2003).
</b>
<br>
Available in two formats using Postscript and PDF here:
<UL>
<li>    <a href="assc7-slides.pdf">PDF version</a>
<li>    <a href="assc7-slides.ps">
Postscript version</a>
</UL>
And in a version for printing two slides per page (if you insist!):
<UL>
<li>    <a href="assc7-slides.2page.pdf">PDF version (2-up)</a>
</UL>

<h3><b>Abstract</b></h3>
<blockquote>
Most people think that because they
experience and talk about consciousness they have a clear understanding
of what they mean by the noun "consciousness". This is just one of many
forms of self-deception to be expected in a sufficiently rich
architecture with reflective capabilities that provide some access to
internal states and processes, but which could not possibly have
<I>complete</I> self-knowledge. This talk will approach the topic of
understanding what a mind is from the standpoint of a philosophical
information-engineer designing minds of various kinds.
<P>
A key idea is that besides physical machines that manipulate matter and
energy there are virtual machines that manipulate information, including
control information. A running virtual machine (for instance a running
instance of the Java virtual machine) is not just a mathematical
abstraction (like the generic Java virtual machine). A running virtual
machine includes processes and events that can interact causally with
one another, with the underlying physical machine, and with the
environment. People rely on the causal powers of such virtual machines
when they use the internet, use word processors or spelling checkers, or
use aeroplanes with automatic landing systems. So they are not
epiphenomenal.
<P>
Such a virtual machine may be only very indirectly related to the
underlying physical machine and in particular there need not be any
simple correlations between virtual machine structures and processes and
physical structures and processes. This can explain some of the alleged
mystery in the connections between mental entities and processes and
brain entities and processes.
<P>
We'll see how some designs for sophisticated information-processing
virtual machines are likely to produce systems that will discover in
themselves the very phenomena that first led philosophers to talk about
sensory qualia and other aspects of consciousness. This can serve to
introduce a new form of conceptual analysis that builds important
bridges between philosophy, psychology, neuroscience, biology, and
engineering. For instance, qualia can be accounted for as internally
referenced virtual machine entities, which are described using
internally developed causally-indexical predicates that are inherently
incommunicable between different individuals.
<P>
All this depends crucially on the concept of a <b>virtual machine</b>
which despite being virtual has causal powers.
<P>
Papers and
talks providing background to the presentation can be found here:
<br>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/">http://www.cs.bham.ac.uk/research/cogaff/</a>

<P>

For more information on the Association for the Scientific Study of
Science, see
<a href="http://assc.caltech.edu/">http://assc.caltech.edu/</a>
</blockquote>
<P>
<hr>
<p>
<a name="talk24"> </a>
<h3>
Talk 24: VARIETIES OF AFFECT AND LEARNING IN A COMPLETE HUMAN-LIKE
ARCHITECTURE
</h3>
<br>
Presented at
<a href="http://www.isle.org/symposia/cogarch/">
Stanford Symposium on Advances in Cognitive Architectures</a>
March 22-23 2003.
<br>
Also presented at University of Notre Dame, 3th April
2003.
This overlaps with
<a href="#talk3">Talk 3</a>
<br>
Available in two formats using Postscript and PDF here:
<UL>
<li>    <a href="stanford-arch-slides.pdf">PDF version</a>
<li>    <a href="stanford-arch-slides.ps"> Postscript version</a>
</UL>
<h3><b>Abstract</b></h3>
<P>
<blockquote>
Recent research on different layers in an integrated architecture, using
differing forms of representation, different types of mechanisms, and
different information, to provide different functional capabilities,
suggests a way of thinking about classes of possible architectures (the
<EM>CogAff schema</EM>), tentatively proposed as a framework for comparing and
contrasting designs for complete systems. An exceptionally rich special
case of the schema, <EM>H-Cogaff</EM>, incorporating diverse concurrently active
components, layered not only centrally but also in its perceptual and
action mechanisms, seems to accommodate many features of human mental
functioning, explaining how our minds relate to many different aspects of
our biological niche.
<P>
This architecture allows for more varieties of
learning and development than are normally considered, and also for more
varieties of affective states, including different kinds of pleasures,
pains, motives, evaluations, preferences, attitudes, moods, and emotions,
differing according to which portions of the architecture are involved,
what their effects are within that and other portions of the architecture,
what sorts of information they are concerned with, and how they effect
external behaviour. These ideas have implications both for applications of
AI (e.g. in digital entertainments, or in the design of learning
environments), and for scientific theories about human minds and brains.
<P>
<a href="http://www.cs.bham.ac.uk/~axs/fig/your.mind.gif">Here's a sketch of H-Cogaff</a>
<P>
For more on these ideas see these talks
<a href="http://www.cs.bham.ac.uk/research/cogaff/talks/">http://www.cs.bham.ac.uk/research/cogaff/talks/</a>
<br>
And the
<a href="http://www.cs.bham.ac.uk/~axs/cogaff.html">Cognition and Affect project</a>
papers
<a href="http://www.cs.bham.ac.uk/research/cogaff/">http://www.cs.bham.ac.uk/research/cogaff/</a>
<br>
<a
href="http://www.cs.bham.ac.uk/research/cogaff/0-INDEX00-02.html#74">A
relevant
paper</a>
<P>
</blockquote>
<P>
<hr>
<p>
<a name="talk23"> </a>
<h3>
Talk 23: ARCHITECTURE-BASED PHILOSOPHY OF MIND (ECAP03 Version)
<br>
What kind of virtual machine is capable of human consciousness?
</h3>
<br>
Presented at
<a href="http://www.gla.ac.uk/departments/philosophy/ECAP/">ECAP03 Glasgow 28th March 2003.</a>
<br>
Modified version also presented at University of Notre Dame, 4th April
2003. Presented in a different way at ASSC7, in
<a href="#talk25"> Talk 25 below. </a>
<blockquote>
Available in two formats using Postscript and PDF here:
<UL>
<li>    <a href="ecap03-slides.pdf">PDF version</a>
<li>    <a href="ecap03-slides.ps">
Postscript version</a>
</UL>
</blockquote>
<P>
<h3><b>Abstract</b></h3>
<blockquote>
Most people think that because they experience and talk about
consciousness they have a clear understanding of what they mean by the
noun "consciousness". This is just one of many forms of self-deception
to be expected in a sufficiently rich architecture with reflective
capabilities that provide some access to internal states and processes,
but which could not possibly have complete self-knowledge. This talk
will approach the topic of understanding what a mind is from the
standpoint of a philosophical information-engineer designing minds of
various kinds.
<P>
We'll see how some designs are likely to produce systems that will
discover in themselves the very phenomena that first led philosophers to
talk about sensory qualia and other aspects of consciousness. This can
serve to introduce a new form of conceptual analysis that builds
important bridges between philosophy, psychology, neuroscience, biology,
and engineering. It depends crucially on the concept of a <em>virtual
machine</em> which despite being virtual has causal powers.  Papers and
talks providing background to the presentation can be found here:
<br>
    <a href="http://www.cs.bham.ac.uk/research/cogaff/">http://www.cs.bham.ac.uk/research/cogaff/</a>

</blockquote>
<P>
<hr>
<p>
<a name="turing"> </a>
<a name="talk22"> </a>
<h3>
Talk 22: THE IRRELEVANCE OF TURING MACHINES TO ARTIFICIAL INTELLIGENCE
</h3>
<br>
Presented at School of Computer Science theory seminar, Birmingham,
Friday 28th Feb 2003, and at University of Nevada Reno, 20 March 2003
<br>
Available in two formats using Postscript and PDF here:
<UL>
<li>    <a href="turing-irrel-slides.pdf">PDF version</a>
<li>    <a href="turing-irrel-slides.ps">Postscript version</a>
</UL>
<h3><b>Abstract</b></h3>
<blockquote>
The claim that the development of computers and of AI depended
on the notion of a Turing machine is criticised. Computers were the
inevitable result of convergence of two strands of technology with a
very long history: machines for automating various physical processes
and machines for performing abstract operations on abstract entities,
e.g. doing numerical calculations or playing games.
<P>
Some of the implications of combining these technologies, so that
machines could operate on their own instructions, were evident to
Babbage and Lovelace, in the 19th century. Although important advances
were made using mechanical technology (e.g. punched cards in Jacquard
looms and in Hollerith machines used for manipulating census information
in the USA) it was only the development of new electronic technology in
the 20th century that made the Babbage/Lovelace dream a reality. Turing
machines were a useful abstraction for investigating abstract
mathematical problems, but they were not needed for the development of
computing as we know it.
<P>
Various aspects of these developments are analysed, along
with their relevance to AI (which will use whatever
information-processing technology turns up, whether computer-like or
not). I'll discuss some similarities between computers viewed as
described above and animal brains. This comparison depends on a number
of distinctions: between energy requirements and information
requirements of machines, between physical structure and virtual machine
structure, between ballistic and online control, between internal and
external operations, and between various kinds of autonomy and
self-awareness. In passing, I defend Chomsky's claim that humans have
infinite competence (e.g. linguistic, mathematical competence) despite
performance limitations. Likewise virtual machines in computers.
<P>
These engineering ideas, which owe nothing to Turing machines, or the
mathematical theory of computation, are all intuitively familiar to
software engineers, though rarely made fully explicit. The ideas are
important both for the scientific task of understanding, modelling or
replicating human or animal intelligence and for the engineering
applications of AI, as well as other applications of computers.
I think Turing himself understood all this.
<P>
The talk is partly based on this paper:
<P>
<blockquote>
A. Sloman, 'The irrelevance of Turing machines to AI' in
Matthias Scheutz, Ed.,
<I>Computationalism: New Directions</I>
MIT Press, 2002. (Also online at
<a href="http://www.cs.bham.ac.uk/research/cogaff/">http://www.cs.bham.ac.uk/research/cogaff/</a>),
</blockquote>
</blockquote>
<P>
<hr>
<p>
<a name="humanvision"> </a>
<a name="talk21"> </a>
<h3>
Talk 21: HUMAN VISION --- A MULTI-LAYERED MULTI-FUNCTIONAL SYSTEM
</h3>
<br>
This was a presentation at a symposium of the British Machine Vision
Association <a href="http://www.bmva.ac.uk/">http://www.bmva.ac.uk/</a>
on
<I>
Reverse Engineering: the Human Vision System
Biologically inspired Computer Vision Approaches
</I>
held in London on 29 January 2003.
<br>
Available in two formats using Postscript and PDF here
(large files because of images included):
<UL>
<li>    <a href="bmva03.vision.slides.pdf">PDF version</a>
<br>
(about 0.45 MB)
<li>    <a href="bmva03.vision.slides.ps">Postscript version</a>
<br> (Warning: size of postscript version is over 4Mbytes.)
</UL>
See also slides for
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0505">A (possibly) new theory of vision (October 2005)</a>
<br>
<h3><b>Abstract</b></h3>
<blockquote>
I try to show how a full account of human vision will have to analyse it
as a multi-functional system doing very different kinds of processing in
parallel, serving different kinds of purposes. These include various
kinds of processing that we share with animals that evolved much
earlier. In particular there are processes linked to purely reactive
mechanisms such as posture control and saccadic triggers, processes
providing "chunks" at different levels of abstraction both in the 2-D
and 3-D domains, processes providing "parsed" descriptions of complex
multi-component structures (e.g. seeing a pair of scissors, reading a
sentence), processes categorising types of motion (e.g. watching a
swaying branch before jumping onto it, or an approaching predator),
processes recognising very abstract functional and causal properties and
relations (support, pushing, constraining), processes concerned with
detecting various sorts of mental states in other information processors
(predators, prey, and conspecifics in social species), and processes
concerned with categorising things that don't exist but could exist,
e.g. seeing possibilities for action, possible effects of various
changes, and other visual "affordances" (generalising J.J.Gibson).
<P>
Most research on vision, whether in AI, psychology, or
neuroscience tends to be very narrowly focused on particular tasks
requiring particular forms of representation and particular algorithms.
<P>
The multi-functional viewpoint presents a framework for trying to bring
different research programmes together, posing new, very demanding
constraints because of the great difficulty of designing such complex
systems in an integrated fashion.
<br>
More detailed presentations are in papers in
<a href="http://www.cs.bham.ac.uk/research/cogaff/">the CogAff
directory</a>. Some of the other talks listed here are also relevant.
</blockquote>
<P>
<hr>
<p>
<a name="robots"> </a>
<a name="talk20"> </a>
<h3>
Talk 20: WHEN WILL REAL ROBOTS BE AS CLEVER
 AS THE ONES IN THE MOVIES?
</h3>
<br>
This was originally a presentation at the 2003 Conference of the
<a href="http://www.ase.org.uk">
Association for Science Education
(ASE)</a>
held at
<a href="http://www.bham.ac.uk/">The University of Birmingham</a>
3rd-5th January 2003}
<br>
Also given as an open lecture in the
<a href="http://www.bham.ac.uk/physics/">School of Physics and Astronomy,
Birmingham</a>
12th Feb 2003, and at the Theoretical Physics Colloquium,
<a href="http://www.damtp.cam.ac.uk/">Department of Applied Mathematics and Theoretical
Physics</a>,
Cambridge
University.
<br>
Available in two formats using Postscript and PDF here (large files
because of images included):
<UL>
<li>    <a href="ase03-slides.pdf">PDF version</a>
<li>    <a href="ase03-slides.ps">Postscript version</a>
<br>
(about 2.6Mbytes)
</UL>
<h3><b>Abstract</b></h3>
<blockquote>
During the second half of the 20th Century, many Artificial Intelligence
researchers made wildly over-optimistic claims about how soon it would
be possible to build machines with human-like intelligence. Some even
predicted super-human intelligent machines, which might be a wonderful
achievement or a disaster, depending on your viewpoint. But we are still
nowhere near machines with the general intelligence of a child, or a
chimpanzee, or even a squirrel, although many machines easily outperform
humans in very narrowly defined tasks, such as playing certain board
games, checking mathematical proofs, solving some mathematical problems,
solving various design problems, and some factory assembly-line tasks.
<P>
This talk attempts to explain why, despite enormous advances in
materials science, mechanical and electronic engineering, software
engineering and computer power, current robots (and intelligent software
systems) are still so limited. The main reason is our failure to
understand what the problems are: what collection of capabilities needs
to be replicated. We need to understand human and animal minds far
better than we do. This requires much deeper understanding of processes
such as perception, learning, problem-solving, self-awareness,
motivation and self-control. We also need to extend our understanding of
possible architectures for information-processing virtual machines. I
shall outline some of the less obvious problems, such as problems in
characterising the tasks of visual perception, and sketch some ideas for
architectures that will be needed to combine a wide variety of human
capabilities. This has many implications for the scientific study of
humans, and also practical implications, for instance in the teaching of
mathematics. It also has profound implications for philosophy of mind.
</blockquote>
<P>
<hr>
<p>
<a name="symmetry"> </a>
<a name="talk19"> </a>
<h3>
Talk 19: TOWARDS HUMAN-MACHINE SYMMETRY
</h3>
<br>
A talk on how to get more intelligence into user interfaces, thereby
reducing the asymmetry between humans and machines. For
second year AI and CS students at Birmingham. December 2002.
<br>
Available in three formats using Postscript and PDF here:
<UL>
<li>    <a href="human-machine-symmetry.pdf">PDF version</a>
<li>    <a href="human-machine-symmetry.ps">Postscript version</a>
<li>    <a href="human-machine-symmetry.2page.ps">Postscript version
printing two slides per page</a>
</UL>
<h3><b>Abstract</b></h3>
<blockquote>
This is a first draft of a talk on interface design that I expect to go
on improving over time. It is in part motivated by hearing many talks on
interface design that fail to pay any attention to questions about the
kinds of information processing mechanisms that humans use when
interacting with machines (or with one another). This often leads to bad
designs.
</blockquote>
<P>
<hr>
<p>
<a name="science"> </a>
<a name="talk18"> </a>
<h3>
Talk 18: WHAT IS SCIENCE? (CAN THERE BE A SCIENCE OF MIND?)
</h3>
Presented at the launch of Cafe Scientifique for Birmingham, at the
Midlands Arts Centre, Birmingham, 25th October 2002. The slides were
expanded after the meeting.
<br>
Available in two formats using Postscript and PDF here:
<UL>
<li>    <a href="whatis-science.pdf">PDF version</a>
<li>    <a href="whatis-science.ps">Postscript version</a>
</UL>
<h3><b>Abstract</b></h3>
<blockquote>
This presentation gives an introduction to philosophy of science, though
a rather idiosyncratic one, stressing science as the search for powerful
new ontologies rather than merely laws. You can't express a law unless
you have an ontology including the items referred to in the law (e.g.
pressure, volume, temperature). The talk raises a number of questions
about the aims and methods of science, about the differences between the
physical sciences and the science of information-processing
systems (e.g.
organisms, minds, computers), whether there is a unique truth or final
answers to be found by science, whether scientists ever
prove anything (no -- at most they show that some theory is better
than any currently available rival theory), and why science does not
require faith (though obstinacy can be useful). The slides end with a
section on whether a science of mind is possible, answering yes, and
explaining how.
<p>
See also presentations on virtual machines, e.g. <a href="#wpe08">my
talk at WPE 2008.</a>
</blockquote>
<P>
<hr>
<p>
<a name="talk17"> </a>
<h3>
Talk 17: AI And The Study Of Mind (Early British AI)
</h3>
Presented at a symposium organised by the
<a href="http://www.bcs.org/sg/ccs/">
Computer Conservation Society</a>
at
the Science Museum, London on 11th October 2002.
<br>
<a href="http://www.aiai.ed.ac.uk/events/ccs2002/">CCS Symposium:
Artificial Intelligence
Recollections of the pioneers
</a>
<p>
My presentation is now available in two versions: original and updated (Dec 2016
-- slight reformatting and a few new items added)
<UL>
<li>
Updated PDF version (2016):
<a href="SlomanEarlyBritishAI-CCS.pdf">SlomanEarlyBritishAI-CCS.pdf</a>
<li>
Original PDF version (2002)
<a href="SlomanEarlyBritishAI-CCS-orig.pdf">SlomanEarlyBritishAI-CCS-orig.pdf</a>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;(Previously bcs02.slides.pdf)
<br>
(Postscript)
<a href="SlomanEarlyBritishAI-CCS-orig.ps">2002 Postscript version</a>
<br>
Previously bcs02.slides.ps
</UL>
The slides, expanded after the symposium, present some autobiographical
notes and summarise briefly the history of AI as the new science
explaining what minds are and how they work.
<P>
A more detailed record of the meeting with slides of other speakers can
be found here, along with pictures:
<a href="http://www.aiai.ed.ac.uk/events/ccs2002">/http://www.aiai.ed.ac.uk/events/ccs2002/</a>
<P>

<hr>
<P>
<a name="wgw02"> </a>
<a name="talk16"> </a>
<h3>
Talk 16: MORE THINGS THAN ARE DREAMT OF
IN YOUR BIOLOGY:
Information processing
in biologically-inspired robots.
<br>
By Aaron Sloman and Ron Chrisley
</h3>
Presented at
<a href="http://www.ecs.soton.ac.uk/~rid/wgw02/home.html">EPSRC/BBSRC International Workshop</a>
on
Biologically-Inspired Robotics:
The Legacy of W. Grey Walter
14-16 August 2002, HP Bristol Labs, UK
<br>
Available in two formats using Postscript and PDF here:
<UL>
<li>    <a href="wgw02.slides.pdf">PDF version</a>
<li>    <a href="wgw02.slides.ps">Postscript version</a>
</UL>
<h3><b>Abstract</b></h3>
<blockquote>
This paper is concerned with some methodological and philosophical problems
related both to the long-term objective of building human-like robots (like
those 'in the movies') and short- and medium-term objectives of building
robots with capabilities of more or less intelligent animals.  In particular, we
claim that organisms are information-processing machines, and thus
information-processing concepts will be essential for designing
biologically-inspired robots. However identifying relevant concepts is
non trivial since what an information processor is doing cannot in
general be determined simply by observing it. A phenomenon that we label
'ontological blindness' often gets in the way.
We give some examples to
illustrate this difficulty.
Having a general framework
for describing and comparing agent architectures may help. We present
the CogAff schema as a first draft framework that can be used to help
overcome some kinds of ontological blindness by directing research
questions.
</blockquote>
The full paper is at the
<a href="http://www.cs.bham.ac.uk/research/cogaff/">Cognition and Affect web site.</a>
<P>
<hr>
<P>
<a name="designmind"> </a>
<a name="talk15"> </a>
<h3>
Talk 15: CAN WE DESIGN A MIND?
</h3>
Keynote talk presented at
<a href="http://www.arch.usyd.EDU.AU/kcdc/conferences/aid02">
AI in Design Conference: AID02</a>
Cambridge, UK, 15th July 2002.
<br>
Available in two formats using Postscript and PDF here:
<UL>
<li>    <a href="aid02.slides.pdf">PDF version</a>
<li>    <a href="aid02.slides.ps">Postscript version</a>
</UL>
(Still undergoing revision. Last changed 17 Jul 2002. Comments welcome.)
<h3><b>Abstract</b></h3>
<blockquote>
Evolution, the great designer, has produced minds of many kinds,
including minds of human infants, toddlers, teenagers, and minds
of bonobos, squirrels, lambs, lions, termites and fleas. All these
minds are information processing machines. They are virtual
machines implemented in physical machines. Many of them are of
wondrous complexity and sophistication. Some people argue that
they are all inherently unintelligible: just a randomly generated,
highly tangled mess of mechanisms that happen to work, i.e. they
keep the genes going from generation to generation.
<P>
I attempt to sketch and defend an alternative view: namely that
there is a space of possible designs for minds, with an
intelligible structure, and features of this space constrained
what evolution could produce. The CogAff architecture schema
gives a first approximation to the structure of that space of
possible (evolvable) agent architectures. H-CogAff is a special
case that (to a first approximation) seems to explain many human
capabilities.
<p>
By understanding the structure of that space, and the trade-offs between
different special cases within it, we can begin to understand some of
the more complex biological minds by seeing how they fit into that
space. Doing this properly for any type of organism (e.g. humans)
requires understanding the <I>affordances</I> that the environment
presents to those organisms -- a difficult task, since in part
understanding the affordances requires us to understand the organism at
the design level, e.g. understanding its perceptual capabilities.

<p>
This investigation of alternative sets of requirements and the space of
possible designs should also enable us to understand the possibilities
for artificial minds of various kinds, also fitting into that space of
designs. And we may even be able to design and build some simple types
in the near future, even if human-like systems are a long way off.
<P>
(This talk is closely related to several of the previous talks, e.g. on
emotions, on consciousness, on perception, on architectures.)
<p>
<small>
There's a brief report on some this work by Michael Brooks, in the
NewScientist on 25th Feb 2009
<br>
<a href="http://www.newscientist.com/article/mg20126971.800-rise-of-the-robogeeks.html">http://www.newscientist.com/article/mg20126971.800-rise-of-the-robogeeks.html</a>
<br>
Unfortunately it emphasises the engineering potential more than the
scientific and philosophical goals -- due to space limitations, I
understand.
</small>
</blockquote>
<P>
<hr>
<P>
<a name="grounding"> </a>
<a name="talk14"> </a>
<h3>
Talk 14: Getting meaning off the ground: symbol grounding vs symbol
attachment/tethering
</h3>
This talk was presented first at Birmingham on Monday 11th March 2002
then in a much revised form at MIT Media Lab on Friday 15th March 2002.
<p>
A revised version of a subset of the presentation was produced in
September-November 2007
<a href="#talk49">Talk 49: on model-based semantics and why theory
tethering is better than symbol grounding.</a> For most people that
will be a better introduction to this topic.
<P>
Available in four formats using PDF and Postscript
(which may need to be
inverted) here:
<UL>
<li>    <a href="grounding.slides.pdf">PDF version</a>
<li>    <a href="grounding.slides.ps">Postscript version</a>
<li>    <a href="grounding.slides.2page.pdf">PDF version
printing two slides per page</a>
<li>    <a href="grounding.slides.2page.ps">Postscript version
printing two slides per page</a>
</UL>
<b>
Note added 23 Aug 2005
</b>
Jackie Chappell persuaded me that instead of the phrase
'Symbol Attachment' I should use 'Symbol Tethering'. That is
explained more clearly in <a href="#talk49">Talk 49.</a>
<p>
<b>Abstract</b>
<blockquote>
This presentation attacks concept empiricism, the theory that all
concepts are abstracted from experience of instances or defined in
terms of concepts previously understood, recently re-invented and
called "symbol-grounding" theory. The attack is closely related to
the philosopher Kant's attack on concept empiricism, when he argued
that concepts are required in order to have experience, and
therefore not all concepts can be derived from experience. Within
this framework we explain how a person blind from birth can
understand colour concepts, for example.
<p>
<a href="#meanings">A newer talk</a> on 'Varieties of Meaning' presents
additional arguments and explains some of the ideas in more detail.
<p>
Several other presentations here (e.g. the presentation on
<a href="#inf">information processing virtual machines</a>) are also
relevant.
<p>
A related discussion paper (HTML) asks how a learner presented with
a 2-D display of a rotating Necker cube could
<br>
develop the 3-D ontology as providing the best way to see what's
going on.
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/nature-nurture-cube.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/nature-nurture-cube.html</a>
<br>
(including pointers to some online rotating cubes!).
<p>
A simpler example of continuously moving linear objects projected
onto a 2-D discrete array:
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/simplicity-ontology.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/simplicity-ontology.html</a>
<p>
Related discussion papers and presentations on the CoSy robot project
web site include
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0601">
Orthogonal Recombinable Competences Acquired by Altricial Species
       (Blankets, string, and plywood) (HTML)
</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#dp0604">
Sensorimotor vs objective contingencies (HTML)
</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0609">
Natural and artificial meta-configured altricial information-processing
systems (PDF)
</a>
<br>
(A journal paper, with Biologist Jackie Chappell, to appear in IJUC).
<li>
<a
href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0604">
'Ontology extension' in evolution and in development, in animals and
       machines (PDF presentation)
</a>
<li>
And the euCognition wiki, with opposing papers on symbol grounding here:
<a href="http://www.eucognition.org/wiki/index.php?title=Cognition_Briefings">
Symbol tethering: the myth of symbol grounding (HTML)
</a>
</ul>
<p>
Two papers written a few years before Harnad's symbol grounding paper
presented a draft version of a theory explaining how a machine can
use symbols to refer to things in a way that does not require causal
connection with those things. Both papers presuppose an understanding of
the way a formal system can determine a set of Tarskian models.
<ul>
<li>
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/81-95.html#4">
What enables a machine to understand? (IJCAI 1985)
</a>
<li>
<a
href="http://www.cs.bham.ac.uk/research/projects/cogaff/81-95.html#5">
Reference without causal links (ECAI 1986)
</a>
</ul>
</blockquote>
<P>
<hr>
<P>
<a name="aiandphil"> </a>
<a name="talk13"> </a>
<h3>
Talk 13: Artificial Intelligence and Philosophy
<br>
(Out of date. See Talk 109)
<br>
<small>
(New version <a href="#talk109">Talk 109</a>)
</small>
</h3>
This was a lecture to first year AI students at Birmingham, Dec 11th
2001, on AI and Philosophy, explaining how AI relates to philosophy and
in some ways improves on philosophy. It was repeated December 2002,
December 2003, October 2004, October 2005, each time changing a little.
It introduces ideas about ontology, architectures, virtual machines and
how these can help transform some old philosophical debates.
<P>
Old version available in PDF here:
<UL>
<li>    <a href="ai-and-phil.pdf">PDF version (out of date)</a>
<p>
A version (using 'flash') is also available on
<a href="http://www.slideshare.net/asloman/slideshows">my 'slideshare.net'
space.</a>

There are related introductory talks on this web site:

<li>
<a href="#talk10">
Talk 10: WHAT IS ARTIFICIAL INTELLIGENCE?
</a>
<br>
Talk prepared for applicants interested in AI.
<p>
<li>
<a href="#talk11">
Talk 11: ARTIFICIAL INTELLIGENCE DEVELOPMENT ENVIRONMENTS
</a>
<br>
A talk on AI languages and tools and why they are special, for
AI students at Birmingham.
<P>
<li>
<a href="#talk18">
Talk 18: What Is Science? (Can There Be A Science Of Mind?)
</a>
<br>
Presented at the launch of Cafe Scientifique for Birmingham, at the
Midlands Arts Centre, Birmingham, 25th October 2002
<p>

<li>
<a href="#emotions">
Talk 28: DO INTELLIGENT MACHINES, NATURAL OR ARTIFICIAL, REALLY NEED EMOTIONS?
</a>
<br> Talk to Cafe Scientifique & Culturel Birmingham, 7th May 2004
(and various other places since then).
<p>
<hr>
Many of the other talks are about relationships between AI and
philosophy, psychology and/or biology.
</UL>

<P>
<hr>
<P>
<a name="super"> </a>
<a name="talk12"> </a>
<h3>
Talk 12: Supervenience and Implementation
</h3>
Talk presented at the University of Birmingham, in September
2000, then at the University of Nottingham in November
2001.
<br>Revised October 2003, October 2007.
<P>
Available in two formats using Postscript and PDF here:
<UL>
<li>    <a href="virtual.slides.pdf">PDF version</a>
<li>    <a href="virtual.slides.ps">Postscript version</a>
</UL>
<h3><b>
Abstract
</b></h3>
<blockquote>
The slides introduce some problems about the relations between
virtual machines and physical machines. I attempt to show
how the philosophers' notion of "supervenience" is related to the
engineer's concept of "implementation", and the computer scientist's
notion of "virtual machine". This is closely related to very old
philosophical problems about the relationship between mind and matter
(or mind and brain).
<p>
Virtual machines are "fully grounded" in physical machines without
being identical with or in other ways reducible to them.
<P>
One popular way of trying to understand virtual machines makes use of a
common notion of 'functionalism'. This is often explained in terms of a
virtual machine that has a state-transition table. This notion is
criticised as inadequate and compared with a more sophisticated notion
of a virtual machine that has multiple states of different sorts
changing and interacting concurrently on different time-scales: Virtual
Machine Functionalism (implicitly taken for granted by software
engineers, but unfamiliar to many philosophers and others who discuss
functionalism).
<P>
Multi-component virtual machines are ubiquitous in our common sense
ontology, though we don't normally notice, e.g. when we talk about
social, political, and economic processes. Some philosophers
argue that virtual machine events are purely "epiphenomenal" and
therefore cannot have any effects.
<P>
A rebuttal of this view requires a satisfactory analysis of the concept
of "cause" -- one of the hardest unsolved problems in philosophy. A
partial analysis is sketched, and shown to accommodate parallel
causation in hierarchies of virtual machines. This allows mental causes
to be effective in producing effects. This should be no surprise to
software engineers and computer scientists who frequently build virtual
machines precisely because they can have desired effects. Philosophers
with no knowledge of computing often find this very hard to understand.
A corollary is that the training of philosophers needs to be improved,
and probably the training of psychologists also.
<br>
See also <a href="#talk5">Talk 5 (IJCAI Tutorial on Philosophy,
2001)</a>, and
<a href="#inf">Talk 26 on Information-processing virtual
machines.</a>
</blockquote>
<P>
<hr>
<P>
<a name="aidev"> </a>
<a name="talk11"> </a>
<h3>
Talk 11: Artificial Intelligence development environments
</h3>
This was a lecture to first year AI students at Birmingham, Dec 4th
2001, on how AI programming is both like and unlike
other forms of software engineering and how this influences design of
AI languages and development environments. Since then it has been
presented several times, with minor revisions.
<P>
Available in three formats using Postscript and PDF here:
<UL>
<li>    <a href="setools-ailanguages.pdf">PDF version</a>
<li>    <a href="setools-ailanguages.ps">Postscript version</a>
<li>    <a href="setools-ailanguages.2page.ps">Postscript version
printing two slides per page</a>
</UL>
<P>

<hr>
<P>
<a name="whatsai"> </a>
<a name="talk10"> </a>
<h3>
Talk 10: What is Artificial Intelligence?
</h3>
A talk prepared for students who have applied for our Artificial
Intelligence degree course, explaining what AI is, distinguishing AI as
science and AI as engineering, and summarising some of the sub-fields of
AI.
<P>
The slides are available in Postscript and PDF here:
<UL>
<li><a
href="whatsai.openday.pdf">PDF version</a>
<li><a
href="whatsai.openday.ps">Postscript version</a>
</UL>
<P>
See also
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/aiforschools.html">http://www.cs.bham.ac.uk/research/projects/cogaff/misc/aiforschools.html</a>
<P>
<hr>
<P>
<a name="talk9"> </a>
<h3>
Talk 9: Varieties of Consciousness
</h3>
Presented at Oxford University Consciousness Society, 24th Oct 2001
A modified version was presented to the CS/AI School seminar, Birmingham
on 8th Nov 2001.
<P>
Many of the other talks overlap with this.
<a href="#talk23"> Talk 23 </a> is a followup to this, as is
<a href="#talk25"> Talk 25 </a>.
<P>
The slides are available in Postscript and PDF here:
<UL>
<li><a href="oxford.consciousness.slides.ps">Postscript version</a>
<li><a href="oxford.consciousness.slides.pdf">PDF version</a>
<li>
<a href="
http://www.cs.bham.ac.uk/research/projects/cogaff/talks/consciousness-slides-contents.txt">Table of
contents (plain text)</a>
<li><a href="oxford.consciousness.slides.twopage.ps">Postscript version
for printing two slides per page</a>
</UL>
<P>
If reading the files using a postscript viewer, such as "gv" you may
need to change the orientation (e.g. to seascape).
<P>
<hr>
<P>
<a name="visarch"> </a>
<a name="talk8"> </a>
<h3>
Talk 8: Evolvable, Biologically Plausible Visual Architectures
</h3>
Presented at BMVC01 (British Machine Vision Conference, Sept 2001).
<P>
The slides are available in Postscript and PDF here:
<UL>
<li><a href="bmvc01.slides.ps">Postscript version</a>
<li><a href="bmvc01.slides.pdf">PDF version</a>
<li><a href="birm.vision.slides.2page.pdf">PDF version for printing
2 slides per page</a>
<br>
(Recent Version prepared for UG lecture, Nov 2005)
</UL>
See also slides for
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0505">A (possibly) new theory of vision (October 2005)</a>
<h3><b>Abstract:</b></h3>
<blockquote>
Much work in AI is fragmented, partly because the subject is so huge
that it is difficult for anyone to think about all of it. Even within
sub-fields, such as language, reasoning, and vision, there is
fragmentation, as the sub-sub-fields are rich enough to keep people
busy all their lives. However, there is a risk that results of isolated
research will be unsuitable for future integration, e.g. in models of
complete organisms, or human like robots. This paper offers an
architectural framework
for thinking about the many components of visual systems and how they
relate to the whole organism or machine. The viewpoint is biologically
inspired, using conjectured evolutionary history as a guide to some of
the features of the architecture. It may also be useful both for
modelling animal vision and designing robots with similar capabilities.
</blockquote>

<P>
If reading the files using a postscript viewer, such as "gv" you may
need to change the orientation (e.g. to seascape).
<P>

<hr>
<P>
<a name="visreason"> </a>
<a name="talk7"> </a>
<h3>
Talk 7: When is seeing (possibly in your mind's eye) better than
deducing, for reasoning?
</h3>
Presented at CS & AI Theory seminar, Birmingham, Sept 2001
<br>
Also at BCS/SGAI meeting, City University London, March 2006
<br>
The slides are available in Postscript and PDF here:
<UL>
<li><a href="vis.sem.01.ps">Postscript version</a>
<li><a href="vis.sem.01.pdf">PDF version</a>
</UL>
See also these
<a
href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#pr0506">More
recent slides on
Two views of child as scientist: Humean and Kantian</a>
(October 2005).
<P>
If reading the files using a postscript viewer, such as "gv" you may
need to change the orientation (e.g. to seascape).
<P>
<hr>
<P>
<a name="nokia"> </a>
<a name="talk6"> </a>
<h3>
Talk 6: Invited Talk on architectures for human-like agents, presented to one day conference at Nokia
Research Centre, Helsinki, on 8th June 2001
</h3>
The slides are available in Postscript and PDF here:
<UL>
<li><a href="nokia.ps">Postscript version</a>
<li><a href="nokia.pdf">PDF version</a>
</UL>
<blockquote>
<small>
These slides were revised in August 2006, partly taking into account
ideas from two recent papers with Jackie Chappell
<p>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0502">
 COSY-TR-0502: The Altricial-Precocial Spectrum for Robots
</a>
<br>
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/#tr0609">
COSY-TR-0609: Altricial Self-organising Information-processing systems
</a>
</p>
</small>
</blockquote>
<P>
<hr/>
<p>
<a name="ijcaitut"> </a>
<a name="talk5"> </a>
<h3>
Talk 5: TUTORIAL ON <b>Philosophical foundations: Some key questions</b>
Presented at IJCAI01 Seattle 5th Aug 2001
</h3>
Information about this tutorial, presented jointly with Matthias
Scheutz, can be found, along with Postscript and PDF versions of the
slides for the tutorial (also in the tutorial booklet) here:
<a href="http://www.cs.bham.ac.uk/~axs/ijcai01">http://www.cs.bham.ac.uk/~axs/ijcai01</a>
<P>
<hr>
<P>
<hr/>
<a name="talk4a"></a>
<a name="free"></a>
<h3><b>
Talk 4a: Debate on This house believes that robots will have free will
<br>
<a href="freewill-debate.pdf">Available HERE (PDF)</a>
<br>
(Added: 24 Aug 2007, after rediscovering my slides!)
</b></h3>
A version (using 'flash') is also available on
<a href="http://www.slideshare.net/asloman/slideshows">my 'slideshare.net'
space.</a>
<p>
<blockquote>
<a href="http://www.dcs.napier.ac.uk/~mac/AI.html">An International AI Symposium in memory of Sidney Michaelson</a>
was organised by the British Computer Society, Edinburgh Branch, on
7th April 2001.
<br>
<a href="http://www.dcs.napier.ac.uk/~mac/ifaces.htm">Reviewed here (with
pictures).</a>
</blockquote>
<p>
<b>Abstract</b>
<blockquote>
The event ended with a debate on the motion:
<br>
"This house believes that robots will have free will"
<br>
The review states:
<blockquote>
<small>
The formal part of the proceedings concluded with a debate. Getting
this off the ground was no mean task. Can you imagine getting a
bunch of academics to agree what they will debate and who will
propose and oppose the motion? The email trail this exercise
generated, including debating the voting strategy, became a marathon
in itself. However, we achieved agreement, and Harold Thimbleby,
Chris Huyck and Yorick Wilks spoke for, and Mike Brady, Aaron Sloman
and Mike Burton spoke against the motion
<b>"This house believes that robots will have free will".</b>
The debate was chaired by Ian Ritchie
(recent past president of BCS) who skilfully kept the speakers to
time. A vote was taken before and after the debate. Before, the Ayes
had a big majority, but at the final count outcome was evens: a good
way to end.
<br>
A <a href="debate-2001-edin.jpg"> picture of the opposing team is
here.</a>
</small>
</blockquote>
Two more serious papers on this topic are here
<ul>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/misc/four-kinds-freewill.html">
Four Concepts of Freewill: Two of them incoherent</a>
<li>
<a href="http://www.cs.bham.ac.uk/research/projects/cogaff/81-95.html#8">
"How to dispose of the free will issue" </a>
</blockquote>

</ul>
</blockquote>
<p>
<hr>
<P>
<a name="aibacs"> </a>
<a name="talk4"> </a>
<h3>
Talk 4: HOW TO UNDERSTAND NATURAL MINDS OF MANY KINDS.
</h3>
This invited talk was presented at a workshop on
<b>
Adaptive and interactive behaviour of animals and computational systems
(AIBACS):
</b>
organised by EPSRC and BBSRC at Cosener's House, Abingdon, on
28-29th March 2001.
<P>
The slides are available in Postscript and PDF here:
<P>
<UL>
<li><a href="aibacs.slides.ps">Postscript version</a>
<li><a href="aibacs.slides.pdf">PDF version</a>
</UL>
<P>
If reading the files using a postscript viewer, such as "gv" you may
need to set the page size to A3.
<P>
<hr>
<P>
<a name="affectcogaff"> </a>
<a name="talk3"> </a>
<h3>
Talk 3: VARIETIES OF AFFECT AND THE CogAff ARCHITECTURE SCHEMA
</h3>
This talk was presented in
<a href="http://www.cs.ukc.ac.uk/people/staff/cgj/research/aisb2001/aisb2001.html">the
symposium on Emotion, cognition, and affective computing,</a> at the
<a href="http://www.dai.ed.ac.uk/~simonco/conferences/AISB01">AISB
2001 conference</a> held at the University of York, March 2001.
<P>
A revised version was presented at University College London
on 19th Jun 2002 (Gatsby Centre and Institute for Cognitive
Neuroscience).
<br>
This overlaps with
<a href="#talk24">talk 24</a>
<P>
The slides are available in Postscript and PDF here:
<P>
<h3><b>
New version (June 2002)
</b></h3>
<UL>
<li><a href="gatsby.slides.ps">Postscript version</a>
<li><a href="gatsby.slides.pdf">PDF version</a>
</UL>
<h3><b>
Old version (April 2001)
</b></h3>
<UL>
<li><a href="aisb01.slides.ps">Postscript version</a>
<li><a href="aisb01.slides.pdf">PDF version</a>
</UL>
<P>
<h3><b>
Abstract
</b></h3>
<blockquote>
In the last decade and a half, there has been a steadily growing amount
of work on affect in general and emotion in particular, in empirical
psychology, cognitive science and AI, both for scientific purposes and
for the purpose of designing synthetic characters, e.g. in games and
entertainments.
<P>
Such work understandably starts from concepts of ordinary language (e.g.
"emotion", "feeling", "mood", etc.). However, these concepts can
be deceptive: the words appear to have clear meanings but are used in
very imprecise and systematically ambiguous ways. This is often because
people use explicit or implicit pre-scientific theories about mental
states and process which are incomplete or vague. Some of the confusion
arises because different thinkers address different subsets of the
phenomena.
<P>
More sophisticated theories can provide a basis for deeper and
more precise concepts, as has happened in physics and chemistry
following the development of new theories of the architecture of matter
which led to revisions of our previous concepts of various kinds of
substances and various kinds of processes involving those substances.
<P>
In the Cognition and Affect project we have been exploring the benefits
of developing architecture-based concepts of mind. We start by defining
a space of architectures generated by the CogAff architecture schema,
which covers a variety of information-processing architectures,
including, we think, architectures for insects, many kinds of animals,
humans at different stages of development, and possible future robots.
<P>
In this framework we can produce specifications of architectures for
complete agents (of various kinds) and then find out what sorts of
states and processes are supported by those architectures. Thus for each
type of architecture there is a collection of "mental concepts"
relevant to organisms or machines that have that sort of architecture.
<P>
Thus we investigate a space of architectures linked to a space of
possible types of minds, and for some of those minds we find analogues
of familiar human concepts, including, for example, "emotion",
"consciousness", "motivation", "learning", "understanding", etc.
<P>
We have identified a special type of architecture H-Cogaff, a
particularly rich instance of the CogAff architecture schema,
conjectured as a model of normal adult human minds. The
architecture-based concepts that H-Cogaff supports provide a framework
for defining with greater precision than previously a host of mental
concepts, including affective concepts, such as "emotion", "attitude",
"mood", "pleasure" etc. These map more or less loosely onto various
pre-theoretical versions of those concepts.
<P>
For instance H-Cogaff allows us to define at least three distinct
varieties of emotions; primary, secondary and tertiary emotions,
involving different layers of the architecture which we believe evolved
at different times. We can also distinguish different kinds of learning,
different forms of perception, different sorts of control of behaviour,
all supported within the same architecture.
<P>
A different architecture, supporting a different range of mental
concepts might be appropriate for exploring affective states of other
animals, for instance insects, reptiles, or other mammals. Human infants
probably have a much reduced version of the architecture which includes
self-bootstrapping mechanisms that lead to the adult form.
<P>
Various kinds of brain damage can be distinguished within the H-Cogaff
architecture. We show that some popular arguments based on evidence from
brain damage purporting to show that emotions are needed for
intelligence are fallacious because they don't allow for the possibility
of common control mechanisms underlying both tertiary emotions and
intelligent control of thought processes. Likewise we show that the
widely discussed theory of William James which requires all emotions to
involve experience of somatic states fails to take account of emotions
that involve only loss of high level control of mental processes without
anything like experience of bodily states.
<P>
We have software tools for building and exploring working models of
these architectures, but so far model construction is at a very early
stage.
<P>
Further details can be found here
    <a href="http://www.cs.bham.ac.uk/research/cogaff/">http://www.cs.bham.ac.uk/research/cogaff/</a>
</blockquote>
<P>
<hr>
<P>
<a name="talk2"> </a>
<a name="simagent"> </a>
<h3>
Talk 2: SIMAGENT: TOOLS FOR DESIGNING MINDS
<br>
A toolkit for philosophers and engineers
</h3>
<P>
The slides are available in Postscript and PDF here:
<P>
<h3><b>
Revised version March 2007
</b></h3>
<UL>
<li><a href="simagent-slides.pdf">simagent-slides.pdf</a>
<li><a href="simagent-slides-2up.pdf">simagent-slides-2up.pdf</a> (PDF 2-up version)
<br>
&nbsp;&nbsp;&nbsp;&nbsp; (links not clickable in 2-up version)
</UL>
The toolkit is also described here in more detail.
<a href="http://www.cs.bham.ac.uk/research/poplog/packages/simagent.html">
http://www.cs.bham.ac.uk/research/poplog/packages/simagent.html</a>
<br>
Movie demonstrations of the toolkit are available here
<a href="http://www.cs.bham.ac.uk/research/poplog/figs/">http://www.cs.bham.ac.uk/research/poplog/figs/</a>

<P>
The slides are modified versions of slides used for talks at
a Seminar in Newcastle University in September 2000, at talks in
Birmingham during October and December 2000, Oxford University in
January 2001, IRST (Trento) in 2001,
Birmingham in 2003 to 2007,  and York University in Feb
2004.
<h3><b>
Abstract
</b></h3>

<P>
<blockquote>
The SimAgent toolkit, developed in this school since about 1994
(initially in collaboration with DERA) and used for a number of
different projects here and elsewhere, is designed to support both
teaching and exploratory research on multi-component architectures for
both artificial agents (software agents, robots, etc.) and also models
of natural agents. Unlike many other toolkits (e.g. toolkits associated
with SOAR, ACT-R, PRS) it does not impose a commitment to a particular
class of architectures but allows rapid-prototyping of novel
architectures for agents with sensors and effectors of various sorts
(real or simulated) and many different kinds of internal modules doing
different sorts of processing, e.g. perception, learning,
problem-solving, generating new motives, producing emotional states,
reactive control, deliberative control, self-monitoring and
meta-management, and linguistic processing.
<P>
The toolkit supports exploration of architectures with many sorts of
processes running concurrently, and interacting in unplanned ways.
<P>
One of the things that makes this possible is the use of a powerful,
interactive, multi-paradigm extendable language,
<a href="http://www.cs.bham.ac.uk/research/poplog/primer/START.html">Pop-11</a>
(similar in
power and generality to Common Lisp, though different in its details).
This has made it possible to combine within the same package support for
different styles of programming for different sub-tasks, e.g.
procedural, functional, rule-based, object oriented (with multiple
inheritance and generic functions), and event-driven programming, as
well as allowing modules to be edited and recompiled while the system
is running, which supports both incremental development and testing and
also self-modifying architectures.
<P>
A collaborative project between Birmingham and Nottingham is producing
extensions to support distributed agents using the HLA (High Level
Architecture) platform.
<P>
The talk will give an overview of the aims of the toolkit, show some
simple demonstrations, explain how some of it works, and provide
information for anyone who wishes to try using it.
<P>
The talk may be useful to students considering projects requiring
complex agent architectures.
</blockquote>
<P>

FURTHER INFORMATION
<UL>
<li>
<a href="http://www.cs.bham.ac.uk/research/poplog/packages/simagent.html">
http://www.cs.bham.ac.uk/research/poplog/packages/simagent.html</a>
        SimAgent Overview

<li>
    Aaron Sloman & Brian Logan (1999)
    Building cognitively rich agents using the Sim_agent toolkit, in
    <I>Communications of the Association for Computing Machinery,</I>
        42, 3, pp. 71--77, March
<li>
    <a href="http://www.nd.edu/%7Eairolab/simworld/index.html">http://www.nd.edu/%7Eairolab/simworld/index.html</a>
        The SimWorld package built on SimAgent by Matthias Scheutz
        at the University of Notre Dame.

<li>
    <a href="http://www.cs.bham.ac.uk/research/poplog/figs/simagent/">http://www.cs.bham.ac.uk/research/poplog/figs/simagent/</a>
        Some movie-demos.
</UL>
<P>
<hr>
<P>

<a name="evolvable"> </a>
<a name="talk1"> </a>
<h3>
Talk 1: VARIETIES OF EVOLVABLE MINDS
<br>
OR
<br>
How to think about architectures for human-like
<br>
and other agents
<br>
OR
<br>
How to Turn Philosophers of Mind
into Engineers
</h3>
This talk was presented in Oxford on 22nd Jan 2001 in the seminar series
of the
<a href="http://www.cogneuro.ox.ac.uk/">McDonnell-Pew Centre for Cognitive Neuroscience</a>
<P>
The slides are available in Postscript and PDF here:
<P>
<UL>
<li><a href="oxford.ps">Postscript version</a>
<li><a href="oxford.pdf">PDF version</a>
</UL>
<P>
Also presented at the University of Surrey 7 Feb 2001, and in a modified
form at a "consultation" between christian scientists and AI researchers
at Windsor Castle, Feb 14-16, 2001.
<P>
The slides are modified versions of slides used for talks at ESSLLI in
August 2000, at a Seminar in Newcastle University in
September 2000, at a seminar in Nottingham University November 2000.
<P>
<hr/>
<p>
<h3><b>
<a href="#contentslist">
BACK TO LIST OF CONTENTS AND POINTERS TO COSY TALKS
</a>
</b></h3>

<P>
<a name="others"> </a>
<hr>
<h3><b>
OTHER COLLECTIONS OF SLIDES
</b></h3>

<a name="ibm02"></a>
<h3><b>
Slides for IBM Symposium March 2002:
<br>
Architectures and the spaces they inhabit
</b></h3>

Two invited talks were given at a workshop followed by a conference
on architectures for common sense, at IBM T.J. Watson Research
Centre, New York on 13th and 14th March 2002. The slides have been
collected into a single long file.
<p>
The other main speakers at the Conference were John McCarthy and
Marvin Minsky.
<P>
The slides attempt to explain (in outline) what an architecture is, what
virtual machine functionalism is, what architecture-based concepts are,
what the CogAff architecture schema is, what is in the H-Cogaff
(Human-Cogaff) architecture, how this relates to different sorts of
emotions and other mental phenomena, how architectures evolve or
develop, trajectories in design space and niche space, and what some of
the very hard unanswered questions are.
<UL>
<li>
<a href="http://www.cs.bham.ac.uk/research/cogaff/ibm02/slides.ibm02.pdf">PDF format</a>
<li>
<a
href="http://www.cs.bham.ac.uk/research/cogaff/ibm02/slides.ibm02.ps">Postscript
format</a>
</UL>
<a name="gc5"></a>
<P>
<h3><b>
UK Grand Challenge Project Proposal 2002
</b></h3>
Papers and slides prepared for the workshop in November 2002
<br>
<a href="http://www.cs.bham.ac.uk/research/cogaff/gc">http://www.cs.bham.ac.uk/research/cogaff/gc</a>
<P>
And a more detailed specification:
<br>
<a href="http://www.cs.bham.ac.uk/research/cogaff/manip/">http://www.cs.bham.ac.uk/research/cogaff/manip/</a>
<P>
<a name="darpa02"></a>
<h3><b>
Presentation at DARPA Cognitive Systems Workshop Nov 2002
<br>
How to Think About Cognitive Systems: Requirements and Designs
<br>
</b></h3>
<a href="http://www.cs.bham.ac.uk/research/cogaff/darpa02/">http://www.cs.bham.ac.uk/research/cogaff/darpa02/</a>
<P>
<hr>
<P>
<b>WARNING:</b>
<br>
Any of my pdf slides found at any other location are likely to be out of date.
<br>
I try to keep the versions on slideshare.net up to date, but sometimes forget to
<br>
upload a new version.
<hr>
<P>
<a name="notes"> </a>
<h3><b>
NOTES and related references.
</b></h3>
NOTE: Both Postscript and PDF versions of slides should have several
coloured slides. If the colours in the postscript version don't show up
when you read it in netscape, try saving the file and reading it with
"gv". (This is probably a problem only on 8-bit displays). The colours
are not crucial: they merely help a little.
<P>
<hr>
<P>
Further papers on the topics addressed in the slides can be found in the
Cognition and Affect Project directory
<a href="http://www.cs.bham.ac.uk/research/cogaff/">http://www.cs.bham.ac.uk/research/cogaff/</a>
<P>
Comments and criticisms welcome.
<P>
Our Software tools are available free of charge with full sources in the
Free Poplog directory:
<a href="http://www.cs.bham.ac.uk/research/poplog/freepoplog.html">http://www.cs.bham.ac.uk/research/poplog/freepoplog.html</a>
<hr>
<P>
<a name="ack"> </a>
<h3>
ACKNOWLEDGEMENTS
</h3>
<br>
Some of this work arises out of, or was done as part of, a project
funded by the Leverhulme Trust on
<blockquote>
<b>
    Evolvable virtual information processing architectures
    for human-like minds (Oct 1999 -- June 2003)
</b>
</blockquote>
described
<a href="http://www.cs.bham.ac.uk/~axs/lev/">here</a>.
<P>
The ideas are being developed further in the context of the EC-Funded
<a href="http://www.cs.bham.ac.uk/research/projects/cosy/">CoSy project</a>
which aims to improve our understanding of design possibilities for
natural and artificial cognitive systems integrating many different
sorts of capabilities.
CoSy papers
and presentations are <a href="http://www.cs.bham.ac.uk/research/projects/cosy/papers/">here.</a>
<hr>
<a rel="license" href="http://creativecommons.org/licenses/by/2.5/">
    <img alt="Creative Commons License"
        src="http://creativecommons.org/images/public/somerights20.png"/>
</a>
<br>
This work is licensed under a
    <a rel="license" href="http://creativecommons.org/licenses/by/2.5/">Creative Commons Attribution 2.5
License</a>.
<br>
If you use or comment on our
ideas please include a URL if possible, so that readers
can see the original (or the latest version thereof).
</p>
<hr>
<b>
<small>
Last updated: 29 Nov 2009; 7 Jan 2010; 21 Jan 2010; 18 Feb 2010; 8 Mar 2010; 12 Mar 2010;
28 Mar 2010; 13 May 2010; 19 May 2010; 23 Jul 2010; 27 Jul 2010; 8 Aug 2010; 15 Aug 2010;
24 Sep 2010; 26 Sep 2010; 30 Sep 2010; 24 Dec 2010; 16 Jan 2011; 23 Feb 2011; 27 Feb 2011;
5 Apr 2011; 26 Aug 2011; 30 Aug 2011; 16 Sep 2011; 15 Nov 2011; 1 Feb 2012; 21 Sep 2012;
1 Dec 2012; 4 Dec 2012; 1 Jan 2013; 24 Jan 2013; 3 Mar 2013; 20 May 2013; 5 Jan 2014;
14 Jan 2014; ... 14 Aug 2014; ... 12 Oct 2014; ... 21 May 2016; 29 Jul 2017; 3
Oct 2017
</small>
</b>

<br>
Maintained by
<a href="http://www.cs.bham.ac.uk/~axs/">Aaron Sloman</a>
<br>
<a href="http://www.cs.bham.ac.uk/">School of Computer Science</a>
<br>
<a href="http://www.bham.ac.uk/">The University of Birmingham</a>

</BODY>
</HTML>
